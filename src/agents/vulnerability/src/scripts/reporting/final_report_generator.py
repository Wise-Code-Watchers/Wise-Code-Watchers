"""
最终报告生成器 - 生成代码审计的最终结论和JSON报告
"""

import json
import os
from datetime import datetime
from typing import Any, Dict, List, Optional

from langchain_core.messages import SystemMessage, HumanMessage
from langchain_openai import ChatOpenAI


def generate_final_report_prompt(
    pr_data: Dict[str, Any],
    feature_risk_plan: Dict[str, Any],
    todolist: Dict[str, Any],
    execution_results: Dict[str, Any]
) -> str:
    """生成最终报告的LLM提示词"""

    # 提取关键信息
    pr_info = pr_data.get("extracted", {})
    execution_summary = execution_results.get("execution_summary", {})
    all_findings = execution_results.get("all_findings", [])

    prompt = f"""你是一个资深的代码安全审计专家，需要基于完整的代码审计结果，生成最终的安全评估报告。

## PR 基本信息:
- **PR编号**: {pr_info.get('number')}
- **PR标题**: {pr_info.get('title')}
- **PR作者**: {pr_info.get('user')}
- **分支**: {pr_info.get('head_ref')} → {pr_info.get('base_ref')}
- **状态**: {pr_info.get('state')}

## 代码变更统计:
{json.dumps(pr_data.get("diff_summary", {}), ensure_ascii=False, indent=2)}

## 功能风险分析结果:
- **总功能数量**: {len(feature_risk_plan.get('features', []))}
- **高风险功能**: {len([f for f in feature_risk_plan.get('features', []) if f.get('risk_overview', {}).get('max_risk_score', 0) >= 70])}
- **重点关注**: {len(feature_risk_plan.get('top_focus', []))}

## 审计执行统计:
- **总审计任务**: {execution_summary.get('total_tasks', 0)}
- **完成任务**: {execution_summary.get('completed_tasks', 0)}
- **失败任务**: {execution_summary.get('failed_tasks', 0)}
- **成功率**: {execution_summary.get('success_rate', 0):.1f}%
- **执行时长**: {execution_summary.get('total_duration_minutes', 0):.1f}分钟

## 发现的安全问题统计:
- **总问题数**: {len(all_findings)}
- **严重问题**: {execution_summary.get('findings_by_severity', {}).get('critical', 0)}
- **高风险问题**: {execution_summary.get('findings_by_severity', {}).get('high', 0)}
- **中风险问题**: {execution_summary.get('findings_by_severity', {}).get('medium', 0)}
- **低风险问题**: {execution_summary.get('findings_by_severity', {}).get('low', 0)}

## 详细问题列表:
{json.dumps(all_findings[:20], ensure_ascii=False, indent=2)}  # 限制显示前20个问题

## 审计任务执行结果:
{json.dumps(execution_results.get('execution_results', [])[:5], ensure_ascii=False, indent=2)}  # 限制显示前5个任务结果

## 报告要求:

请基于以上信息，生成一个全面的PR安全评估最终报告，包含以下部分：

### 1. 执行摘要
- 审计概况和主要发现
- 整体安全风险评估
- 关键安全建议

### 2. 详细安全分析
- 按严重级别分类的安全问题
- 每个问题的详细分析和影响评估
- 修复优先级建议

### 3. 风险评估
- 当前代码安全状况
- 潜在风险和影响
- 与行业标准对比

### 4. 修复建议
- 具体的修复行动计划
- 优先级排序
- 预期修复效果

### 5. 结论和建议
- 是否建议合并此PR
- 后续安全改进建议
- 监控和预防措施

## 输出格式要求:

请严格按照以下JSON格式输出最终报告：

{{
  "report_metadata": {{
    "pr_number": {pr_info.get('number')},
    "pr_title": "{pr_info.get('title')}",
    "generated_at": "{datetime.now().isoformat()}",
    "auditor": "AI Security Auditor",
    "report_version": "1.0"
  }},
  "executive_summary": {{
    "overall_security_grade": "A|B|C|D|F",
    "critical_issues_count": 0,
    "high_risk_issues_count": 0,
    "total_security_issues": 0,
    "risk_level": "low|medium|high|critical",
    "recommendation": "approve|conditional_approval|reject",
    "summary_text": "执行摘要文本"
  }},
  "security_analysis": {{
    "findings_by_category": {{
      "authentication": {{
        "count": 0,
        "issues": [],
        "risk_assessment": "low|medium|high"
      }},
      "authorization": {{
        "count": 0,
        "issues": [],
        "risk_assessment": "low|medium|high"
      }},
      "input_validation": {{
        "count": 0,
        "issues": [],
        "risk_assessment": "low|medium|high"
      }},
      "data_protection": {{
        "count": 0,
        "issues": [],
        "risk_assessment": "low|medium|high"
      }},
      "error_handling": {{
        "count": 0,
        "issues": [],
        "risk_assessment": "low|medium|high"
      }},
      "business_logic": {{
        "count": 0,
        "issues": [],
        "risk_assessment": "low|medium|high"
      }}
    }},
    "vulnerability_assessment": {{
      "critical_vulnerabilities": [],
      "high_risk_vulnerabilities": [],
      "medium_risk_vulnerabilities": [],
      "low_risk_vulnerabilities": []
    }}
  }},
  "risk_assessment": {{
    "current_security_posture": "excellent|good|fair|poor|critical",
    "exploitability": "low|medium|high",
    "business_impact": "low|medium|high",
    "compliance_risk": "low|medium|high",
    "security_score": 8.5,
    "trend_analysis": "improving|stable|degrading"
  }},
  "recommendations": {{
    "immediate_actions": [
      {{
        "priority": "critical|high|medium|low",
        "action": "具体修复动作",
        "description": "详细说明",
        "estimated_effort": "工作量和时间估算"
      }}
    ],
    "long_term_improvements": [
      "长期改进建议1",
      "长期改进建议2"
    ],
    "security_best_practices": [
      "安全最佳实践建议"
    ]
  }},
  "conclusion": {{
    "merge_recommendation": "approve|conditional_approval|reject",
    "rationale": "决策理由",
    "conditions_for_approval": [
      "批准条件1",
      "批准条件2"
    ],
    "security_monitoring": [
      "安全监控建议"
    ],
    "final_assessment": "最终评估总结"
  }},
  "appendices": {{
    "detailed_findings": [],
    "code_analysis_summary": "代码分析摘要",
    "methodology": "审计方法和工具说明"
  }}
}}

## 重要约束:
- 基于实际的审计结果进行分析
- 提供客观、具体的安全评估
- 给出明确可行的修复建议
- 评估要符合实际风险水平
- 结论要有充分的依据支撑
"""

    return prompt


def generate_final_report(
    pr_data: Dict[str, Any],
    feature_risk_plan: Dict[str, Any],
    todolist: Dict[str, Any],
    execution_results: Dict[str, Any],
    llm: ChatOpenAI
) -> Dict[str, Any]:
    """
    生成最终安全评估报告

    Args:
        pr_data: PR数据
        feature_risk_plan: 功能风险分析结果
        todolist: TODO列表
        execution_results: 执行结果
        llm: 语言模型

    Returns:
        最终报告
    """
    prompt = generate_final_report_prompt(pr_data, feature_risk_plan, todolist, execution_results)

    messages = [
        SystemMessage(content="你是一个资深的代码安全审计专家，具有丰富的安全评估和报告编写经验。"),
        HumanMessage(content=prompt)
    ]

    try:
        response = llm.invoke(messages)
        response_text = response.content if hasattr(response, "content") else str(response)

        # 解析JSON响应
        try:
            # 清理响应文本，提取JSON
            json_start = response_text.find("{")
            json_end = response_text.rfind("}") + 1
            if json_start != -1 and json_end > json_start:
                json_text = response_text[json_start:json_end]
                final_report = json.loads(json_text)
            else:
                final_report = json.loads(response_text)
        except json.JSONDecodeError as e:
            # JSON解析失败，创建基本报告结构
            final_report = create_basic_final_report(
                pr_data, feature_risk_plan, execution_results
            )
            final_report["parsing_error"] = str(e)
            final_report["raw_response"] = response_text[:1000]

        # 添加报告元数据
        if "report_metadata" not in final_report:
            final_report["report_metadata"] = {}

        final_report["report_metadata"].update({
            "generated_at": datetime.now().isoformat(),
            "auditor": "AI Security Auditor",
            "report_version": "1.0",
            "generation_method": "llm_generated"
        })

        # 添加原始数据引用
        final_report["source_data"] = {
            "pr_data_available": bool(pr_data),
            "feature_risk_plan_available": bool(feature_risk_plan),
            "todolist_available": bool(todolist),
            "execution_results_available": bool(execution_results)
        }

        return {
            "success": True,
            "final_report": final_report,
            "generated_at": datetime.now().isoformat()
        }

    except Exception as e:
        # 生成基本报告作为后备
        basic_report = create_basic_final_report(pr_data, feature_risk_plan, execution_results)
        basic_report["generation_error"] = str(e)

        return {
            "success": False,
            "final_report": basic_report,
            "error": f"生成最终报告失败: {str(e)}",
            "generated_at": datetime.now().isoformat()
        }


def create_basic_final_report(
    pr_data: Dict[str, Any],
    feature_risk_plan: Dict[str, Any],
    execution_results: Dict[str, Any]
) -> Dict[str, Any]:
    """创建基本报告结构（当LLM生成失败时使用）"""

    pr_info = pr_data.get("extracted", {})
    execution_summary = execution_results.get("execution_summary", {})
    all_findings = execution_results.get("all_findings", [])

    # 统计问题
    critical_count = len([f for f in all_findings if f.get("severity") == "critical"])
    high_count = len([f for f in all_findings if f.get("severity") == "high"])
    medium_count = len([f for f in all_findings if f.get("severity") == "medium"])
    low_count = len([f for f in all_findings if f.get("severity") == "low"])

    # 确定安全等级
    total_issues = critical_count + high_count + medium_count + low_count
    if critical_count > 0:
        security_grade = "F"
        risk_level = "critical"
        recommendation = "reject"
    elif high_count > 3:
        security_grade = "D"
        risk_level = "high"
        recommendation = "conditional_approval"
    elif high_count > 0 or medium_count > 5:
        security_grade = "C"
        risk_level = "medium"
        recommendation = "conditional_approval"
    else:
        security_grade = "B"
        risk_level = "low"
        recommendation = "approve"

    return {
        "report_metadata": {
            "pr_number": pr_info.get("number"),
            "pr_title": pr_info.get("title"),
            "generated_at": datetime.now().isoformat(),
            "auditor": "AI Security Auditor (Basic)",
            "report_version": "1.0",
            "generation_method": "basic_fallback"
        },
        "executive_summary": {
            "overall_security_grade": security_grade,
            "critical_issues_count": critical_count,
            "high_risk_issues_count": high_count,
            "total_security_issues": total_issues,
            "risk_level": risk_level,
            "recommendation": recommendation,
            "summary_text": f"基于自动化分析，PR中发现{total_issues}个安全问题，其中{critical_count}个严重问题，{high_count}个高风险问题。建议{recommendation}。"
        },
        "security_analysis": {
            "findings_by_category": {
                "all_issues": {
                    "count": total_issues,
                    "issues": all_findings,
                    "risk_assessment": risk_level
                }
            }
        },
        "risk_assessment": {
            "current_security_posture": "good" if security_grade in ["A", "B"] else "fair" if security_grade == "C" else "poor",
            "security_score": max(1, 10 - total_issues),
            "trend_analysis": "stable"
        },
        "recommendations": {
            "immediate_actions": [
                {
                    "priority": "critical" if critical_count > 0 else "high" if high_count > 0 else "medium",
                    "action": "修复发现的安全问题",
                    "description": f"需要修复{total_issues}个安全问题，重点关注{critical_count + high_count}个严重和高风险问题",
                    "estimated_effort": f"{max(1, total_issues * 0.5)}人天"
                }
            ]
        },
        "conclusion": {
            "merge_recommendation": recommendation,
            "rationale": f"基于发现的安全问题数量和严重程度，建议{recommendation}",
            "final_assessment": f"安全等级: {security_grade}，风险水平: {risk_level}"
        }
    }


def generate_precision_first_report(
    pr_data: Dict[str, Any],
    verified_findings: List[Dict[str, Any]],
    suspicions: List[Dict[str, Any]],
    execution_results: Dict[str, Any],
    llm: ChatOpenAI
) -> Dict[str, Any]:
    """
    生成最低误报优先的最终报告 - 三态输出结构

    Args:
        pr_data: PR数据
        verified_findings: 已确认漏洞
        suspicions: 疑点（不算漏洞）
        execution_results: 执行结果
        llm: 语言模型

    Returns:
        最终报告
    """
    pr_info = pr_data.get("extracted", {})
    execution_summary = execution_results.get("execution_summary", {})

    # 统计CONFIRMED发现
    critical_count = len([f for f in verified_findings if f.get("severity") == "CRITICAL"])
    high_count = len([f for f in verified_findings if f.get("severity") == "HIGH"])
    medium_count = len([f for f in verified_findings if f.get("severity") == "MEDIUM"])
    total_confirmed = len(verified_findings)

    # 确定安全等级 - 基于CONFIRMED发现
    if critical_count > 0:
        security_grade = "F"
        risk_level = "critical"
        recommendation = "reject"
    elif high_count > 2:
        security_grade = "D"
        risk_level = "high"
        recommendation = "conditional_approval"
    elif high_count > 0 or medium_count > 3:
        security_grade = "C"
        risk_level = "medium"
        recommendation = "conditional_approval"
    else:
        security_grade = "A" if total_confirmed == 0 else "B"
        risk_level = "low"
        recommendation = "approve"

    prompt = f"""你是资深的代码安全审计专家。请基于最低误报的审计结果生成最终报告。

## PR基本信息:
- **PR编号**: {pr_info.get('number')}
- **PR标题**: {pr_info.get('title')}
- **PR作者**: {pr_info.get('user')}
- **分支**: {pr_info.get('head_ref')} → {pr_info.get('base_ref')}

## 已确认漏洞（CONFIRMED） - 需要立即处理:
{json.dumps(verified_findings, ensure_ascii=False, indent=2)}

## 疑点（SUSPECTED） - 需要更多上下文（不算漏洞）:
{json.dumps(suspicions, ensure_ascii=False, indent=2)}

## 执行统计:
- **确认漏洞数**: {total_confirmed}
- **疑点数**: {len(suspicions)}
- **执行任务数**: {execution_summary.get('completed_tasks', 0)}

## 最低误报报告要求:

请按照三态输出结构生成报告：

### 1. Confirmed Findings（已确认漏洞）
- 只包含有确凿证据的漏洞
- 按严重度分类
- 每个漏洞包含完整的证据链

### 2. Suspicions & Questions（疑点与问题）
- 信号不足但值得关注的地方
- 需要额外上下文或测试
- 业务逻辑疑点

### 3. Diff Summary（变更摘要）
- PR变更的总体评估
- 风险控制情况

## JSON输出格式:

{{
  "report_metadata": {{
    "pr_number": {pr_info.get('number')},
    "pr_title": "{pr_info.get('title')}",
    "generated_at": "{datetime.now().isoformat()}",
    "auditor": "Precision-First AI Auditor",
    "report_version": "2.0"
  }},
  "executive_summary": {{
    "overall_security_grade": "{security_grade}",
    "critical_issues_count": {critical_count},
    "high_risk_issues_count": {high_count},
    "total_confirmed_findings": {total_confirmed},
    "total_suspicions": {len(suspicions)},
    "risk_level": "{risk_level}",
    "recommendation": "{recommendation}",
    "summary_text": "基于最低误报审计的结果摘要"
  }},
  "confirmed_findings": {{
    "critical": [],
    "high": [],
    "medium": [],
    "low": [],
    "by_category": {{
      "injection": [],
      "authentication": [],
      "authorization": [],
      "data_exposure": [],
      "logic_defect": [],
      "other": []
    }},
    "summary": {{
      "total_count": {total_confirmed},
      "evidence_based_count": {total_confirmed},
      "semgrep_validated": 0
    }}
  }},
  "suspicions": {{
    "total_count": {len(suspicions)},
    "categories": {{
      "insufficient_context": [],
      "business_logic": [],
      "potential_security": [],
      "testing_needed": []
    }},
    "requires_investigation": [
      "需要更多上下文或测试的疑点列表"
    ]
  }},
  "diff_analysis": {{
    "files_changed": 0,
    "lines_added": 0,
    "lines_removed": 0,
    "risk_coverage": "diff聚焦程度",
    "precision_assessment": "误报控制评估"
  }},
  "evidence_integrity": {{
    "total_evidence_items": {total_confirmed},
    "semgrep_findings": 0,
    "llm_validated": {total_confirmed},
    "evidence_chain_complete": true
  }},
  "recommendations": {{
    "immediate_actions": [
      {{
        "priority": "critical|high|medium",
        "action": "具体修复动作",
        "target_findings": ["finding_id"],
        "evidence_based": true
      }}
    ],
    "investigation_items": [
      "针对SUSPECTED的后续调查建议"
    ],
    "security_improvements": [
      "长期安全改进建议"
    ]
  }},
  "conclusion": {{
    "merge_recommendation": "{recommendation}",
    "confidence_level": "high|medium|low",
    "rationale": "基于证据的决策理由",
    "verified_risk_assessment": "经过验证的风险评估",
    "precision_guarantee": "只报告有证据证实的漏洞"
  }}
}}

请严格按照上述格式，强调最低误报和证据完整性。"""

    messages = [
        SystemMessage(content="你是资深的代码安全审计专家，擅长最低误报的风险评估和报告编写。"),
        HumanMessage(content=prompt)
    ]

    try:
        response = llm.invoke(messages)
        response_text = response.content if hasattr(response, "content") else str(response)

        # 解析JSON响应
        try:
            json_start = response_text.find("{")
            json_end = response_text.rfind("}") + 1
            if json_start != -1 and json_end > json_start:
                json_text = response_text[json_start:json_end]
                final_report = json.loads(json_text)
            else:
                final_report = json.loads(response_text)
        except json.JSONDecodeError as e:
            # 创建基本的精确报告结构
            final_report = create_precision_basic_report(
                pr_data, verified_findings, suspicions, execution_results
            )
            final_report["parsing_error"] = str(e)

        # 添加元数据
        if "report_metadata" not in final_report:
            final_report["report_metadata"] = {}

        final_report["report_metadata"].update({
            "generated_at": datetime.now().isoformat(),
            "auditor": "Precision-First AI Auditor",
            "report_version": "2.0",
            "precision_methodology": "evidence_based_validation"
        })

        return {
            "success": True,
            "final_report": final_report,
            "generated_at": datetime.now().isoformat()
        }

    except Exception as e:
        basic_report = create_precision_basic_report(
            pr_data, verified_findings, suspicions, execution_results
        )
        basic_report["generation_error"] = str(e)

        return {
            "success": False,
            "final_report": basic_report,
            "error": f"生成精确报告失败: {str(e)}",
            "generated_at": datetime.now().isoformat()
        }


def create_precision_basic_report(
    pr_data: Dict[str, Any],
    verified_findings: List[Dict[str, Any]],
    suspicions: List[Dict[str, Any]],
    execution_results: Dict[str, Any]
) -> Dict[str, Any]:
    """创建基本的精确报告结构"""
    pr_info = pr_data.get("extracted", {})

    # 统计
    critical_count = len([f for f in verified_findings if f.get("severity") == "CRITICAL"])
    high_count = len([f for f in verified_findings if f.get("severity") == "HIGH"])
    total_confirmed = len(verified_findings)
    total_suspicions = len(suspicions)

    # 安全等级
    if critical_count > 0:
        security_grade = "F"
        risk_level = "critical"
        recommendation = "reject"
    elif high_count > 2:
        security_grade = "D"
        risk_level = "high"
        recommendation = "conditional_approval"
    elif high_count > 0:
        security_grade = "C"
        risk_level = "medium"
        recommendation = "conditional_approval"
    else:
        security_grade = "A" if total_confirmed == 0 else "B"
        risk_level = "low"
        recommendation = "approve"

    return {
        "report_metadata": {
            "pr_number": pr_info.get("number"),
            "pr_title": pr_info.get("title"),
            "generated_at": datetime.now().isoformat(),
            "auditor": "Precision-First AI Auditor (Basic)",
            "report_version": "2.0",
            "precision_methodology": "evidence_based_validation"
        },
        "executive_summary": {
            "overall_security_grade": security_grade,
            "critical_issues_count": critical_count,
            "high_risk_issues_count": high_count,
            "total_confirmed_findings": total_confirmed,
            "total_suspicions": total_suspicions,
            "risk_level": risk_level,
            "recommendation": recommendation,
            "summary_text": f"基于证据验证，PR中确认{total_confirmed}个漏洞，{total_suspicions}个疑点。建议{recommendation}。"
        },
        "confirmed_findings": {
            "critical": [f for f in verified_findings if f.get("severity") == "CRITICAL"],
            "high": [f for f in verified_findings if f.get("severity") == "HIGH"],
            "medium": [f for f in verified_findings if f.get("severity") == "MEDIUM"],
            "low": [f for f in verified_findings if f.get("severity") == "LOW"],
            "summary": {
                "total_count": total_confirmed,
                "evidence_based_count": total_confirmed,
                "semgrep_validated": sum(1 for f in verified_findings if f.get("source") == "semgrep")
            }
        },
        "suspicions": {
            "total_count": total_suspicions,
            "items": suspicions
        },
        "evidence_integrity": {
            "total_evidence_items": total_confirmed,
            "evidence_chain_complete": True
        },
        "conclusion": {
            "merge_recommendation": recommendation,
            "confidence_level": "high" if total_confirmed == 0 else "medium",
            "verified_risk_assessment": f"基于{total_confirmed}个确认漏洞的风险评估",
            "precision_guarantee": "只报告有证据证实的漏洞"
        }
    }


def save_final_report(final_report: Dict[str, Any], pr_dir: str) -> str:
    """
    保存最终报告到文件

    Args:
        final_report: 最终报告
        pr_dir: PR目录

    Returns:
        保存的文件路径
    """
    output_dir = os.path.join(pr_dir, "out")
    os.makedirs(output_dir, exist_ok=True)

    output_file = os.path.join(output_dir, "final_security_report.json")

    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(final_report, f, ensure_ascii=False, indent=2)

    return output_file