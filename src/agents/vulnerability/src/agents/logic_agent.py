"""
Logic Agent - 逻辑缺陷审计专用Agent
专门负责发现由本次PR diff引入或修改导致的逻辑错误
"""

import json
import logging
import os
import traceback
from typing import Any, Dict, List, Optional

from langchain_core.messages import SystemMessage, HumanMessage
from langchain_openai import ChatOpenAI

from ..prompts.prompt import LOGIC_AGENT_SYSTEM, format_logic_agent_prompt
from ..scripts.todolist.todolist_generator import create_code_tools_for_pr
from ..analysis.hunk_index import build_hunk_index, select_logic_targets, build_audit_unit_from_hunk

logger = logging.getLogger(__name__)


def _safe_json_loads(text: str) -> Dict[str, Any]:
    """
    尽量从模型输出中提取 JSON（容忍前后杂质）。
    """
    text = text.strip()
    if text.startswith("{") and text.endswith("}"):
        return json.loads(text)
    l = text.find("{")
    r = text.rfind("}")
    if l != -1 and r != -1 and r > l:
        return json.loads(text[l:r+1])
    raise json.JSONDecodeError("no json object", text, 0)


def _build_logic_audit_units(feature_risk_plan: Dict[str, Any],
                             diff_ir: Dict[str, Any],
                             pr_dir: str,
                             risk_threshold: int = 60,
                             max_units: int = 12,
                             codebase_path: Optional[str] = None) -> List[Dict[str, Any]]:
    """
    使用新的hunk索引系统构建逻辑审计单元。
    解决字段不匹配问题，确保Logic Agent能找到审计单元。
    """
    logger.info(f"[Logic Agent] 开始构建审计单元，风险阈值: {risk_threshold}, 最大单元数: {max_units}")

    # 复用你项目里的 code_tools（能 read_file/search_code/find_function）
    tools_bundle = create_code_tools_for_pr(pr_dir, feature_risk_plan, codebase_path)
    code_tools = tools_bundle["code_tools"]

    # 构建hunk索引 - 建立feature_risk_plan与diff_ir之间的映射
    logger.info("[Logic Agent] 构建hunk索引映射")
    hunk_index = build_hunk_index(diff_ir)
    logger.info(f"[Logic Agent] 索引构建完成，共 {len(hunk_index)} 个hunks")

    # 选择Logic Agent的目标hunks
    logger.info("[Logic Agent] 选择Logic Agent目标hunks")
    logic_targets = select_logic_targets(
        feature_risk_plan=feature_risk_plan,
        risk_threshold=risk_threshold,
        max_units=max_units
    )

    logger.info(f"[Logic Agent] 选择了 {len(logic_targets)} 个逻辑目标hunks")

    if not logic_targets:
        logger.warning("[Logic Agent] 没有找到符合条件的逻辑目标hunks")
        return []

    units: List[Dict[str, Any]] = []
    total_targets = len(logic_targets)
    processed_targets = 0
    skipped_targets = 0

    for target_info in logic_targets:
        hunk_id = target_info.get("hunk_id")
        if not hunk_id:
            skipped_targets += 1
            logger.debug("[Logic Agent] 跳过target: 无hunk_id")
            continue

        # 从索引中获取hunk详情
        hunk_detail = hunk_index.get(hunk_id)
        if not hunk_detail:
            skipped_targets += 1
            logger.warning(f"[Logic Agent] hunk_id {hunk_id} 在索引中不存在")
            continue

        processed_targets += 1
        file_path = hunk_detail.get("file_path")
        risk_score = target_info.get("risk_score", 0)
        selection_reason = target_info.get("reason", "unknown")

        logger.debug(f"[Logic Agent] 处理目标 {processed_targets}/{total_targets}: {hunk_id} "
                    f"(文件: {file_path}, 分数: {risk_score}, 原因: {selection_reason})")

        try:
            # 使用hunk_index中的函数构建审计单元
            audit_unit = build_audit_unit_from_hunk(
                hunk_id=hunk_id,
                hunk=hunk_detail,
                code_tools=code_tools,
                target_info=target_info
            )

            units.append(audit_unit)
            logger.info(f"[{len(units)}/{max_units}] 已创建逻辑审计单元: {hunk_id} "
                       f"(风险分数: {risk_score}, 选择原因: {selection_reason})")

            if len(units) >= max_units:
                logger.info(f"[Logic Agent] 达到最大单元数限制: {max_units}")
                break

        except Exception as e:
            skipped_targets += 1
            logger.error(f"[Logic Agent] 构建审计单元失败 {hunk_id}: {str(e)}")
            continue

    logger.info(f"[Logic Agent] 逻辑审计单元构建完成")
    logger.info(f"[Logic Agent] 总目标: {total_targets}, 处理成功: {processed_targets}, 跳过: {skipped_targets}")
    logger.info(f"[Logic Agent] 最终生成单元: {len(units)}")

    return units


def run_logic_agent_for_pr(pr_dir: str,
                           diff_ir: Dict[str, Any],
                           feature_risk_plan: Dict[str, Any],
                           llm: ChatOpenAI,
                           risk_threshold: int = 60,
                           max_units: int = 12,
                           codebase_path: Optional[str] = None) -> Dict[str, Any]:
    """
    PR 级逻辑缺陷审计入口：挑选重点 hunks -> 调用 Logic Agent -> 汇总结果
    """
    logger.info(f"[Logic Agent] 开始PR级逻辑缺陷审计")
    logger.info(f"[Logic Agent] 参数: 风险阈值={risk_threshold}, 最大单元={max_units}")

    audit_units = _build_logic_audit_units(
        feature_risk_plan=feature_risk_plan,
        diff_ir=diff_ir,
        pr_dir=pr_dir,
        risk_threshold=risk_threshold,
        max_units=max_units,
        codebase_path=codebase_path
    )

    if not audit_units:
        logger.info("[Logic Agent] 没有需要分析的审计单元")
        return {
            "success": True,
            "units_analyzed": 0,
            "issues_found": 0,
            "issues": [],
            "raw_results": [],
            "errors": []
        }

    logger.info(f"[Logic Agent] 开始逐个分析 {len(audit_units)} 个审计单元")

    results: List[Dict[str, Any]] = []
    errors: List[str] = []
    success_count = 0
    no_issue_count = 0
    issue_count = 0

    for i, unit in enumerate(audit_units, 1):
        hunk_id = unit.get("hunk_id", "unknown")
        file_path = unit.get("file_path", "unknown")
        risk_score = unit.get("risk_score", 0)

        logger.info(f"[Logic Agent] [{i}/{len(audit_units)}] 分析hunk: {hunk_id} (文件: {file_path}, 分数: {risk_score})")

        prompt = format_logic_agent_prompt(unit)
        messages = [
            SystemMessage(content=LOGIC_AGENT_SYSTEM),
            HumanMessage(content=prompt)
        ]

        try:
            # 只在启用详细日志时记录LLM交互
            if os.getenv("ENABLE_DETAILED_LOGS", "false").lower() == "true":
                logger.debug(f"[Logic Agent] {hunk_id}: 开始LLM调用")
                logger.debug(f"[Logic Agent] {hunk_id}: 输入prompt长度: {len(prompt)} 字符")

                # 记录完整的输入（截断过长内容）
                prompt_preview = prompt[:1000] + "..." if len(prompt) > 1000 else prompt
                logger.debug(f"[Logic Agent] {hunk_id}: LLM输入:\n{prompt_preview}")

            # Retry logic for LLM calls with null response handling
            max_retries = 3
            text = None
            for attempt in range(max_retries):
                try:
                    resp = llm.invoke(messages)
                    text = resp.content if hasattr(resp, "content") else str(resp)
                    if text:
                        break
                except TypeError as e:
                    if "null value for `choices`" in str(e):
                        import time
                        logger.warning(f"[Logic Agent] {hunk_id}: LLM返回null choices，重试 {attempt + 1}/{max_retries}")
                        time.sleep(1)
                        continue
                    raise
                except Exception as e:
                    logger.warning(f"[Logic Agent] {hunk_id}: LLM调用失败，重试 {attempt + 1}/{max_retries}: {str(e)}")
                    import time
                    time.sleep(1)
                    continue
            
            if not text:
                # Fallback when LLM is unavailable
                logger.warning(f"[Logic Agent] {hunk_id}: LLM调用失败，使用fallback结果")
                success_count += 1
                no_issue_count += 1
                continue

            # 只在启用详细日志时记录LLM输出
            if os.getenv("ENABLE_DETAILED_LOGS", "false").lower() == "true":
                logger.debug(f"[Logic Agent] {hunk_id}: LLM输出长度: {len(text)} 字符")

                # 记录完整的输出（截断过长内容）
                output_preview = text[:2000] + "..." if len(text) > 2000 else text
                logger.debug(f"[Logic Agent] {hunk_id}: LLM输出:\n{output_preview}")

            obj = _safe_json_loads(text)

            # 轻量校验：必须有 result 字段
            if obj.get("result") not in ("NO_ISSUE", "ISSUE"):
                logger.warning(f"[Logic Agent] {hunk_id}: 输出格式无效，设置为NO_ISSUE")
                logger.warning(f"[Logic Agent] {hunk_id}: 无效输出内容: {obj}")
                obj = {
                    "result": "NO_ISSUE",
                    "issue": None,
                    "need_context": ["model_output_schema_invalid"]
                }
                success_count += 1
                no_issue_count += 1
            elif obj.get("result") == "ISSUE":
                issue_title = obj.get("issue", {}).get("title", "未知问题")
                issue_severity = obj.get("issue", {}).get("severity", "unknown")
                logger.info(f"[Logic Agent] {hunk_id}: 发现问题 - {issue_title} ({issue_severity})")

                # 详细记录发现的问题
                issue_data = obj.get("issue", {})
                if os.getenv("ENABLE_DETAILED_LOGS", "false").lower() == "true":
                    logger.debug(f"[Logic Agent] {hunk_id}: 问题详情:\n" + json.dumps(issue_data, indent=2, ensure_ascii=False))

                success_count += 1
                issue_count += 1
            else:
                logger.debug(f"[Logic Agent] {hunk_id}: 无问题")
                need_context = obj.get("need_context", [])
                if need_context and os.getenv("ENABLE_DETAILED_LOGS", "false").lower() == "true":
                    logger.debug(f"[Logic Agent] {hunk_id}: 需要更多上下文: {need_context}")
                success_count += 1
                no_issue_count += 1

            # 挂上定位信息，方便最终报告呈现
            obj["_meta"] = {
                "hunk_id": hunk_id,
                "file_path": file_path,
                "risk_score": risk_score,
            }
            results.append(obj)

        except Exception as e:
            error_msg = f"hunk_id={hunk_id} error={str(e)}"
            logger.error(f"[Logic Agent] {hunk_id}: 分析失败 - {str(e)}")
            logger.error(f"[Logic Agent] {hunk_id}: 异常详情: {traceback.format_exc()}")
            errors.append(error_msg)

    issues = [r for r in results if r.get("result") == "ISSUE"]

    # 最终统计
    logger.info(f"[Logic Agent] 分析完成统计:")
    logger.info(f"[Logic Agent] 成功: {success_count}/{len(audit_units)}")
    logger.info(f"[Logic Agent] 发现问题: {issue_count}")
    logger.info(f"[Logic Agent] 无问题: {no_issue_count}")
    logger.info(f"[Logic Agent] 执行错误: {len(errors)}")

    return {
        "success": True,
        "units_analyzed": len(audit_units),
        "issues_found": len(issues),
        "issues": issues,
        "raw_results": results,
        "errors": errors
    }