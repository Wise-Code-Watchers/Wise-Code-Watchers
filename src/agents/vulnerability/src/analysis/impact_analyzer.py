"""
æ™ºèƒ½å½±å“é¢åˆ†æå™¨ - æ£€æµ‹PRä¿®æ”¹ä»£ç çš„è·¨æ–‡ä»¶å½±å“
åŸºäºè°ƒç”¨å›¾ã€æ•°æ®æµå’Œä¾èµ–å…³ç³»åˆ†æ
"""

import ast
import os
import json
import re
from typing import Any, Dict, List, Set, Optional, Tuple
from pathlib import Path
from collections import defaultdict, deque


class ImpactAnalyzer:
    """æ™ºèƒ½å½±å“é¢åˆ†æå™¨"""

    def __init__(self, pr_dir: str, enable_logging: bool = True):
        self.pr_dir = pr_dir
        self.enable_logging = enable_logging
        self.call_graph = defaultdict(set)  # å‡½æ•° -> è°ƒç”¨è€…é›†åˆ
        self.reverse_call_graph = defaultdict(set)  # å‡½æ•° -> è¢«è°ƒç”¨å‡½æ•°é›†åˆ
        self.data_dependencies = defaultdict(set)  # å˜é‡/ç±» -> ä½¿ç”¨ä½ç½®
        self.import_graph = defaultdict(set)  # æ¨¡å— -> å¯¼å…¥è€…é›†åˆ

    def _log(self, message: str) -> None:
        """è®°å½•æ—¥å¿—"""
        if self.enable_logging:
            print(f"[ImpactAnalyzer] {message}")

    def analyze_pr_impact(self, diff_ir: Dict[str, Any]) -> Dict[str, Any]:
        """
        åˆ†æPRçš„å½±å“é¢

        Args:
            diff_ir: diffä¿¡æ¯

        Returns:
            å½±å“é¢åˆ†æç»“æœ
        """
        self._log("ğŸš€ å¼€å§‹æ™ºèƒ½å½±å“é¢åˆ†æ")

        # 1. æå–PRä¿®æ”¹çš„æ ¸å¿ƒå…ƒç´ 
        modified_elements = self._extract_modified_elements(diff_ir)
        self._log(f"ğŸ“‹ æå–ä¿®æ”¹å…ƒç´ : {len(modified_elements['functions'])}ä¸ªå‡½æ•°, "
                 f"{len(modified_elements['classes'])}ä¸ªç±», "
                 f"{len(modified_elements['variables'])}ä¸ªå˜é‡")

        # 2. æ„å»ºä»£ç åˆ†æå›¾
        self._build_code_analysis_graph()

        # 3. åˆ†æå½±å“èŒƒå›´
        impact_analysis = self._analyze_impact_scope(modified_elements)

        # 4. ç”Ÿæˆæ‰©å±•æ–‡ä»¶åˆ—è¡¨
        extended_files = self._generate_extended_file_list(impact_analysis)

        self._log(f"ğŸ¯ å½±å“åˆ†æå®Œæˆ: {len(extended_files['direct'])}ä¸ªç›´æ¥æ–‡ä»¶, "
                 f"{len(extended_files['callers'])}ä¸ªè°ƒç”¨æ–‡ä»¶, "
                 f"{len(extended_files['data_flow'])}ä¸ªæ•°æ®æµæ–‡ä»¶")

        return {
            "modified_elements": modified_elements,
            "impact_analysis": impact_analysis,
            "extended_files": extended_files,
            "call_graph_stats": {
                "functions_analyzed": len(self.call_graph),
                "call_relationships": sum(len(callees) for callees in self.call_graph.values())
            }
        }

    def _extract_modified_elements(self, diff_ir: Dict[str, Any]) -> Dict[str, Set[str]]:
        """ä»diffä¸­æå–ä¿®æ”¹çš„æ ¸å¿ƒå…ƒç´ """
        modified = {
            "functions": set(),
            "classes": set(),
            "variables": set(),
            "imports": set(),
            "methods": set()
        }

        # æ¨¡å¼åŒ¹é…æå–å…ƒç´ 
        patterns = {
            "functions": [
                r'^def\s+(\w+)\s*\(',          # def function_name(
                r'^async\s+def\s+(\w+)\s*\(',  # async def function_name(
            ],
            "classes": [
                r'^class\s+(\w+)',              # class ClassName
            ],
            "methods": [
                r'^\s*def\s+(\w+)\s*\(',       # æ–¹æ³•å®šä¹‰ï¼ˆç¼©è¿›ï¼‰
                r'^\s*async\s+def\s+(\w+)\s*\(',  # asyncæ–¹æ³•å®šä¹‰
            ],
            "variables": [
                r'^(\w+)\s*=',                 # variable_name =
                r'^self\.(\w+)\s*=',           # self.variable_name =
                r'@(\w+)',                     # è£…é¥°å™¨
            ],
            "imports": [
                r'^from\s+(\S+)\s+import',     # from module import
                r'^import\s+(\S+)',            # import module
            ]
        }

        for file_info in diff_ir.get("files", []):
            for hunk in file_info.get("hunks", []):
                for line in hunk.get("lines", []):
                    if line.get("type") in ["add", "context"]:
                        content = line.get("content", "")

                        for element_type, regex_list in patterns.items():
                            for regex in regex_list:
                                matches = re.findall(regex, content, re.MULTILINE)
                                for match in matches:
                                    if isinstance(match, tuple):
                                        modified[element_type].add(match[0])
                                    else:
                                        modified[element_type].add(match)

        return modified

    def _build_code_analysis_graph(self) -> None:
        """æ„å»ºä»£ç åˆ†æå›¾ï¼ˆè°ƒç”¨å›¾ã€ä¾èµ–å›¾ç­‰ï¼‰"""
        self._log("ğŸ“Š æ„å»ºä»£ç åˆ†æå›¾...")

        # éå†æ‰€æœ‰Pythonæ–‡ä»¶
        for py_file in Path(self.pr_dir).rglob("*.py"):
            if "__pycache__" in str(py_file):
                continue

            try:
                self._analyze_file_graph(str(py_file))
            except Exception as e:
                self._log(f"âš ï¸ åˆ†ææ–‡ä»¶å¤±è´¥ {py_file}: {str(e)}")

    def _analyze_file_graph(self, file_path: str) -> None:
        """åˆ†æå•ä¸ªæ–‡ä»¶çš„ä»£ç å›¾"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()

            tree = ast.parse(content)
            visitor = CodeAnalysisVisitor(file_path, self.call_graph,
                                       self.reverse_call_graph, self.data_dependencies,
                                       self.import_graph)
            visitor.visit(tree)

        except Exception as e:
            self._log(f"âš ï¸ ASTè§£æå¤±è´¥ {file_path}: {str(e)}")

    def _analyze_impact_scope(self, modified_elements: Dict[str, Set[str]]) -> Dict[str, Any]:
        """åˆ†æå½±å“èŒƒå›´"""
        impact_scope = {
            "direct_functions": set(),
            "caller_functions": set(),
            "data_flow_dependencies": set(),
            "class_dependencies": set(),
            "import_dependencies": set(),
            "transitive_impact": set()
        }

        # 1. åˆ†æå‡½æ•°è°ƒç”¨å½±å“
        for func in modified_elements["functions"]:
            impact_scope["direct_functions"].add(func)

            # æ‰¾åˆ°è°ƒç”¨è¿™ä¸ªå‡½æ•°çš„åœ°æ–¹
            callers = self._find_function_callers(func)
            impact_scope["caller_functions"].update(callers)

            # é€’å½’æŸ¥æ‰¾ä¼ é€’å½±å“
            transitive = self._find_transitive_callers(callers, max_depth=3)
            impact_scope["transitive_impact"].update(transitive)

        # 2. åˆ†æç±»/æ–¹æ³•å½±å“
        for cls in modified_elements["classes"]:
            class_methods = self._find_class_methods(cls)
            impact_scope["class_dependencies"].update(class_methods)

            for method in class_methods:
                callers = self._find_function_callers(f"{cls}.{method}")
                impact_scope["caller_functions"].update(callers)

        # 3. åˆ†ææ•°æ®æµå½±å“
        for var in modified_elements["variables"]:
            dependents = self.data_dependencies.get(var, set())
            impact_scope["data_flow_dependencies"].update(dependents)

        # 4. åˆ†æå¯¼å…¥å½±å“
        for module in modified_elements["imports"]:
            importers = self.import_graph.get(module, set())
            impact_scope["import_dependencies"].update(importers)

        return impact_scope

    def _find_function_callers(self, target_func: str) -> Set[str]:
        """æ‰¾åˆ°è°ƒç”¨ç›®æ ‡å‡½æ•°çš„æ‰€æœ‰å‡½æ•°"""
        callers = set()

        # æ£€æŸ¥ç›´æ¥è°ƒç”¨
        for caller, callees in self.call_graph.items():
            if target_func in callees:
                callers.add(caller)

        # æ£€æŸ¥æ–¹æ³•è°ƒç”¨ (ClassName.method)
        if "." in target_func:
            class_name, method_name = target_func.split(".", 1)
            for caller, callees in self.call_graph.items():
                for callee in callees:
                    if (callee == method_name or
                        callee.endswith(f".{method_name}") or
                        f"{class_name}." in callee):
                        callers.add(caller)

        return callers

    def _find_transitive_callers(self, initial_callers: Set[str], max_depth: int = 3) -> Set[str]:
        """é€’å½’æŸ¥æ‰¾ä¼ é€’è°ƒç”¨è€…"""
        transitive = set()
        visited = set()
        queue = deque(initial_callers)

        depth = 0
        while queue and depth < max_depth:
            level_size = len(queue)

            for _ in range(level_size):
                caller = queue.popleft()
                if caller in visited:
                    continue

                visited.add(caller)
                transitive.add(caller)

                # æ‰¾åˆ°è°ƒç”¨å½“å‰callerçš„å‡½æ•°
                callers_of_caller = self._find_function_callers(caller)
                for c in callers_of_caller:
                    if c not in visited:
                        queue.append(c)

            depth += 1

        return transitive

    def _find_class_methods(self, class_name: str) -> Set[str]:
        """æ‰¾åˆ°ç±»çš„æ‰€æœ‰æ–¹æ³•"""
        methods = set()

        for func in self.call_graph.keys():
            if func.startswith(f"{class_name}."):
                methods.add(func)

        return methods

    def _generate_extended_file_list(self, impact_analysis: Dict[str, Any]) -> Dict[str, List[str]]:
        """ç”Ÿæˆæ‰©å±•çš„æ–‡ä»¶æ‰«æåˆ—è¡¨"""
        extended_files = {
            "direct": [],          # ç›´æ¥ä¿®æ”¹çš„æ–‡ä»¶
            "callers": [],         # è°ƒç”¨ç›¸å…³æ–‡ä»¶
            "data_flow": [],       # æ•°æ®æµç›¸å…³æ–‡ä»¶
            "recommended": []      # æ¨èæ‰«ææ–‡ä»¶
        }

        # æ”¶é›†æ‰€æœ‰æ¶‰åŠçš„å‡½æ•°ä½ç½®
        all_functions = set()
        all_functions.update(impact_analysis["direct_functions"])
        all_functions.update(impact_analysis["caller_functions"])
        all_functions.update(impact_analysis["data_flow_dependencies"])
        all_functions.update(impact_analysis["transitive_impact"])

        # å°†å‡½æ•°æ˜ å°„å›æ–‡ä»¶
        function_to_file = {}
        for py_file in Path(self.pr_dir).rglob("*.py"):
            if "__pycache__" in str(py_file):
                continue

            try:
                with open(py_file, 'r', encoding='utf-8') as f:
                    content = f.read()

                tree = ast.parse(content)
                visitor = FunctionLocationVisitor(str(py_file))
                visitor.visit(tree)
                function_to_file.update(visitor.function_locations)

            except Exception:
                continue

        # æ ¹æ®å½±å“çº§åˆ«åˆ†ç±»æ–‡ä»¶
        file_impact_scores = defaultdict(int)

        for func in all_functions:
            file_path = function_to_file.get(func)
            if file_path and os.path.exists(file_path):
                # æ ¹æ®å½±å“ç±»å‹è®¡ç®—åˆ†æ•°
                if func in impact_analysis["direct_functions"]:
                    file_impact_scores[file_path] += 10
                if func in impact_analysis["caller_functions"]:
                    file_impact_scores[file_path] += 5
                if func in impact_analysis["data_flow_dependencies"]:
                    file_impact_scores[file_path] += 3
                if func in impact_analysis["transitive_impact"]:
                    file_impact_scores[file_path] += 1

        # åˆ†ç±»æ–‡ä»¶
        for file_path, score in sorted(file_impact_scores.items(),
                                      key=lambda x: x[1], reverse=True):
            if score >= 10:
                extended_files["direct"].append(file_path)
            elif score >= 5:
                extended_files["callers"].append(file_path)
            elif score >= 3:
                extended_files["data_flow"].append(file_path)

            # æ¨èæ‰«ææ–‡ä»¶ï¼ˆåˆ†æ•°>=1ï¼‰
            if score >= 1 and len(extended_files["recommended"]) < 50:  # é™åˆ¶æ€»æ•°
                extended_files["recommended"].append(file_path)

        return extended_files


class CodeAnalysisVisitor(ast.NodeVisitor):
    """ASTè®¿é—®å™¨ - ç”¨äºæ„å»ºä»£ç åˆ†æå›¾"""

    def __init__(self, file_path: str, call_graph: Dict, reverse_call_graph: Dict,
                 data_dependencies: Dict, import_graph: Dict):
        self.file_path = file_path
        self.call_graph = call_graph
        self.reverse_call_graph = reverse_call_graph
        self.data_dependencies = data_dependencies
        self.import_graph = import_graph
        self.current_function = None
        self.current_class = None

    def visit_FunctionDef(self, node):
        """è®¿é—®å‡½æ•°å®šä¹‰"""
        func_name = node.name
        if self.current_class:
            func_name = f"{self.current_class}.{func_name}"

        self.current_function = func_name

        # è®°å½•å‡½æ•°å®šä¹‰
        if func_name not in self.call_graph:
            self.call_graph[func_name] = set()

        # è®¿é—®å‡½æ•°ä½“
        self.generic_visit(node)

        self.current_function = None

    def visit_AsyncFunctionDef(self, node):
        """è®¿é—®å¼‚æ­¥å‡½æ•°å®šä¹‰"""
        self.visit_FunctionDef(node)

    def visit_ClassDef(self, node):
        """è®¿é—®ç±»å®šä¹‰"""
        old_class = self.current_class
        self.current_class = node.name

        self.generic_visit(node)

        self.current_class = old_class

    def visit_Call(self, node):
        """è®¿é—®å‡½æ•°è°ƒç”¨"""
        if self.current_function:
            callee = self._extract_callee_name(node)
            if callee:
                self.call_graph[self.current_function].add(callee)
                self.reverse_call_graph[callee].add(self.current_function)

        self.generic_visit(node)

    def visit_Name(self, node):
        """è®¿é—®å˜é‡å"""
        if self.current_function and isinstance(node.ctx, ast.Load):
            var_name = node.id
            self.data_dependencies[var_name].add(self.current_function)

        self.generic_visit(node)

    def visit_Import(self, node):
        """è®¿é—®importè¯­å¥"""
        for alias in node.names:
            module_name = alias.name
            self.import_graph[module_name].add(self.file_path)

        self.generic_visit(node)

    def visit_ImportFrom(self, node):
        """è®¿é—®from...importè¯­å¥"""
        if node.module:
            module_name = node.module
            self.import_graph[module_name].add(self.file_path)

        self.generic_visit(node)

    def _extract_callee_name(self, node) -> Optional[str]:
        """æå–è¢«è°ƒç”¨å‡½æ•°çš„åç§°"""
        if isinstance(node.func, ast.Name):
            return node.func.id
        elif isinstance(node.func, ast.Attribute):
            # å¤„ç† obj.method() æˆ– module.function() æƒ…å†µ
            parts = []
            current = node.func
            while isinstance(current, ast.Attribute):
                parts.append(current.attr)
                current = current.value
            if isinstance(current, ast.Name):
                parts.append(current.id)
            return ".".join(reversed(parts))

        return None


class FunctionLocationVisitor(ast.NodeVisitor):
    """å‡½æ•°ä½ç½®è®¿é—®å™¨ - ç”¨äºè®°å½•å‡½æ•°å®šä¹‰ä½ç½®"""

    def __init__(self, file_path: str):
        self.file_path = file_path
        self.function_locations = {}
        self.current_class = None

    def visit_FunctionDef(self, node):
        """è®¿é—®å‡½æ•°å®šä¹‰"""
        func_name = node.name
        if self.current_class:
            func_name = f"{self.current_class}.{func_name}"

        self.function_locations[func_name] = self.file_path

        self.generic_visit(node)

    def visit_AsyncFunctionDef(self, node):
        """è®¿é—®å¼‚æ­¥å‡½æ•°å®šä¹‰"""
        self.visit_FunctionDef(node)

    def visit_ClassDef(self, node):
        """è®¿é—®ç±»å®šä¹‰"""
        old_class = self.current_class
        self.current_class = node.name

        self.generic_visit(node)

        self.current_class = old_class