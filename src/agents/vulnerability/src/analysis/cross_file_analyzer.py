"""
跨文件分析器 (Cross-File Analyzer)
负责追踪代码变更的跨文件影响，包括调用关系、数据流和依赖分析
"""

import json
import logging
import os
import re
import subprocess
from typing import Any, Dict, List, Optional, Set, Tuple
from dataclasses import dataclass, field, asdict
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed

logger = logging.getLogger(__name__)


@dataclass
class Symbol:
    """代码符号"""
    name: str
    type: str  # function, class, method, variable, constant
    file_path: str
    line_start: int
    line_end: Optional[int] = None
    signature: Optional[str] = None
    visibility: str = "public"  # public, private, protected


@dataclass
class CallRelation:
    """调用关系"""
    caller_file: str
    caller_function: str
    caller_line: int
    callee_file: str
    callee_function: str
    call_type: str = "direct"  # direct, indirect, virtual


@dataclass
class DataFlow:
    """数据流"""
    source_file: str
    source_symbol: str
    source_line: int
    sink_file: str
    sink_symbol: str
    sink_line: int
    flow_type: str = "assignment"  # assignment, parameter, return


@dataclass
class CrossFileContext:
    """跨文件上下文"""
    target_file: str
    target_lines: Tuple[int, int]
    
    # 调用关系
    callers: List[Dict[str, Any]] = field(default_factory=list)
    callees: List[Dict[str, Any]] = field(default_factory=list)
    
    # 依赖关系
    imports_from: List[str] = field(default_factory=list)
    imported_by: List[str] = field(default_factory=list)
    
    # 接口变更影响
    interface_changes: List[Dict[str, Any]] = field(default_factory=list)
    breaking_changes: List[Dict[str, Any]] = field(default_factory=list)
    
    # 安全相关上下文
    api_routes: List[str] = field(default_factory=list)
    auth_checks: List[str] = field(default_factory=list)
    
    # 共享状态
    shared_state: List[str] = field(default_factory=list)
    
    # 相关代码片段
    related_snippets: List[Dict[str, Any]] = field(default_factory=list)
    
    def to_dict(self) -> Dict[str, Any]:
        return asdict(self)


class CrossFileAnalyzer:
    """
    跨文件分析器
    
    功能：
    1. 追踪函数/方法的调用者和被调用者
    2. 分析文件间的导入依赖关系
    3. 识别接口变更及其影响
    4. 发现相关的安全上下文（API路由、认证检查等）
    5. 追踪共享状态
    """
    
    # 支持的语言及其导入模式
    IMPORT_PATTERNS = {
        "python": [
            r'^\s*import\s+([\w.]+)',
            r'^\s*from\s+([\w.]+)\s+import',
        ],
        "javascript": [
            r'^\s*import\s+.*\s+from\s+[\'"]([^"\']+)[\'"]',
            r'^\s*const\s+.*\s*=\s*require\s*\(\s*[\'"]([^"\']+)[\'"]\s*\)',
            r'^\s*import\s*\(\s*[\'"]([^"\']+)[\'"]\s*\)',
        ],
        "typescript": [
            r'^\s*import\s+.*\s+from\s+[\'"]([^"\']+)[\'"]',
            r'^\s*import\s+type\s+.*\s+from\s+[\'"]([^"\']+)[\'"]',
        ],
        "go": [
            r'^\s*import\s+"([^"]+)"',
            r'^\s*"([^"]+)"',  # 在import块内
        ],
        "java": [
            r'^\s*import\s+([\w.]+);',
        ],
        "rust": [
            r'^\s*use\s+([\w:]+)',
            r'^\s*mod\s+(\w+)',
        ],
    }
    
    # 函数调用模式
    CALL_PATTERNS = {
        "python": r'(\w+)\s*\(',
        "javascript": r'(\w+)\s*\(',
        "typescript": r'(\w+)\s*[<(]',
        "go": r'(\w+)\s*\(',
        "java": r'(\w+)\s*\(',
        "rust": r'(\w+)\s*[!<(]',
    }
    
    # 函数定义模式
    FUNCTION_PATTERNS = {
        "python": [
            r'^\s*def\s+(\w+)\s*\(',
            r'^\s*async\s+def\s+(\w+)\s*\(',
        ],
        "javascript": [
            r'^\s*function\s+(\w+)\s*\(',
            r'^\s*const\s+(\w+)\s*=\s*(?:async\s*)?\(',
            r'^\s*(\w+)\s*:\s*(?:async\s*)?\(',
            r'^\s*async\s+(\w+)\s*\(',
        ],
        "typescript": [
            r'^\s*function\s+(\w+)',
            r'^\s*(?:public|private|protected)?\s*(?:async\s+)?(\w+)\s*\(',
            r'^\s*const\s+(\w+)\s*=',
        ],
        "go": [
            r'^\s*func\s+(\w+)\s*\(',
            r'^\s*func\s+\([^)]+\)\s*(\w+)\s*\(',
        ],
        "java": [
            r'^\s*(?:public|private|protected)?\s*(?:static\s+)?(?:\w+\s+)+(\w+)\s*\(',
        ],
        "rust": [
            r'^\s*(?:pub\s+)?fn\s+(\w+)',
            r'^\s*(?:pub\s+)?async\s+fn\s+(\w+)',
        ],
    }
    
    # API路由模式
    API_ROUTE_PATTERNS = {
        "python": [
            r'@app\.(?:route|get|post|put|delete|patch)\s*\([\'"]([^"\']+)[\'"]',
            r'@router\.(?:get|post|put|delete|patch)\s*\([\'"]([^"\']+)[\'"]',
            r'path\s*\(\s*[\'"]([^"\']+)[\'"]',
        ],
        "javascript": [
            r'\.(?:get|post|put|delete|patch)\s*\([\'"]([^"\']+)[\'"]',
            r'@(?:Get|Post|Put|Delete|Patch)\s*\([\'"]([^"\']+)[\'"]',
        ],
        "go": [
            r'\.(?:GET|POST|PUT|DELETE|PATCH|Handle|HandleFunc)\s*\([\'"]([^"\']+)[\'"]',
            r'r\.(?:Get|Post|Put|Delete|Patch)\s*\([\'"]([^"\']+)[\'"]',
        ],
        "java": [
            r'@(?:GetMapping|PostMapping|PutMapping|DeleteMapping|RequestMapping)\s*\([^)]*[\'"]([^"\']+)[\'"]',
            r'@Path\s*\([\'"]([^"\']+)[\'"]',
        ],
    }
    
    # 认证检查模式
    AUTH_PATTERNS = {
        "python": [
            r'@(?:login_required|auth_required|requires_auth)',
            r'@permission_required',
            r'check_permission',
            r'is_authenticated',
            r'verify_token',
        ],
        "javascript": [
            r'(?:isAuthenticated|requireAuth|authMiddleware)',
            r'passport\.authenticate',
            r'verifyToken',
            r'checkPermission',
        ],
        "go": [
            r'(?:AuthMiddleware|RequireAuth|CheckAuth)',
            r'jwt\.Parse',
            r'VerifyToken',
        ],
        "java": [
            r'@(?:PreAuthorize|Secured|RolesAllowed)',
            r'SecurityContextHolder',
            r'isAuthenticated',
        ],
    }
    
    def __init__(self, repo_path: str, semgrep_enabled: bool = True):
        """
        初始化跨文件分析器
        
        Args:
            repo_path: 仓库路径
            semgrep_enabled: 是否启用Semgrep辅助分析
        """
        self.repo_path = Path(repo_path)
        self.semgrep_enabled = semgrep_enabled
        
        # 缓存
        self._import_cache: Dict[str, List[str]] = {}
        self._function_cache: Dict[str, List[Symbol]] = {}
        self._file_content_cache: Dict[str, str] = {}
    
    def analyze_cross_file_context(self,
                                   file_path: str,
                                   line_range: Tuple[int, int],
                                   modified_symbols: Optional[List[str]] = None,
                                   language: str = "python") -> CrossFileContext:
        """
        分析跨文件上下文
        
        Args:
            file_path: 目标文件路径
            line_range: 修改的行号范围 (start, end)
            modified_symbols: 修改的符号列表
            language: 编程语言
        
        Returns:
            跨文件上下文
        """
        logger.info(f"[CrossFileAnalyzer] 分析: {file_path}:{line_range[0]}-{line_range[1]}")
        
        context = CrossFileContext(
            target_file=file_path,
            target_lines=line_range
        )
        
        # 1. 分析导入依赖
        imports = self._analyze_imports(file_path, language)
        context.imports_from = imports
        
        # 2. 找到谁导入了这个文件
        importers = self._find_importers(file_path, language)
        context.imported_by = importers
        
        # 3. 如果提供了修改的符号，分析调用关系
        if modified_symbols:
            for symbol in modified_symbols:
                # 找调用者
                callers = self._find_callers(file_path, symbol, language)
                context.callers.extend(callers)
                
                # 找被调用者
                callees = self._find_callees(file_path, line_range, language)
                context.callees.extend(callees)
        else:
            # 从修改区域提取符号
            symbols = self._extract_symbols_from_range(file_path, line_range, language)
            for symbol in symbols:
                callers = self._find_callers(file_path, symbol.name, language)
                context.callers.extend(callers)
        
        # 4. 检测API路由
        routes = self._find_api_routes(file_path, language)
        context.api_routes = routes
        
        # 5. 检测认证检查
        auth_checks = self._find_auth_checks(file_path, language)
        context.auth_checks = auth_checks
        
        # 6. 分析接口变更
        if modified_symbols:
            interface_changes = self._analyze_interface_changes(
                file_path, modified_symbols, language
            )
            context.interface_changes = interface_changes
            
            # 检测破坏性变更
            for change in interface_changes:
                if self._is_breaking_change(change):
                    context.breaking_changes.append(change)
        
        # 7. 查找相关代码片段
        related = self._find_related_snippets(
            file_path, line_range, context.callers, language
        )
        context.related_snippets = related
        
        logger.info(f"[CrossFileAnalyzer] 完成: "
                   f"调用者={len(context.callers)}, "
                   f"被调用={len(context.callees)}, "
                   f"路由={len(context.api_routes)}")
        
        return context
    
    def _get_file_content(self, file_path: str) -> str:
        """获取文件内容（带缓存）"""
        if file_path in self._file_content_cache:
            return self._file_content_cache[file_path]
        
        full_path = self.repo_path / file_path
        if full_path.exists():
            try:
                content = full_path.read_text(encoding='utf-8', errors='ignore')
                self._file_content_cache[file_path] = content
                return content
            except Exception as e:
                logger.warning(f"[CrossFileAnalyzer] 读取文件失败: {file_path}, {e}")
        
        return ""
    
    def _detect_language(self, file_path: str) -> str:
        """检测文件语言"""
        ext_map = {
            '.py': 'python',
            '.js': 'javascript',
            '.jsx': 'javascript',
            '.ts': 'typescript',
            '.tsx': 'typescript',
            '.go': 'go',
            '.java': 'java',
            '.rs': 'rust',
            '.rb': 'ruby',
            '.php': 'php',
        }
        ext = Path(file_path).suffix.lower()
        return ext_map.get(ext, 'unknown')
    
    def _analyze_imports(self, file_path: str, language: str) -> List[str]:
        """分析文件的导入"""
        if file_path in self._import_cache:
            return self._import_cache[file_path]
        
        content = self._get_file_content(file_path)
        if not content:
            return []
        
        imports = []
        patterns = self.IMPORT_PATTERNS.get(language, [])
        
        for pattern in patterns:
            matches = re.findall(pattern, content, re.MULTILINE)
            imports.extend(matches)
        
        # 去重
        imports = list(set(imports))
        self._import_cache[file_path] = imports
        
        return imports
    
    def _find_importers(self, file_path: str, language: str) -> List[str]:
        """找到导入了指定文件的其他文件"""
        importers = []
        
        # 提取模块名
        module_name = self._file_to_module(file_path, language)
        if not module_name:
            return importers
        
        # 搜索所有同语言文件
        ext_map = {
            'python': ['.py'],
            'javascript': ['.js', '.jsx'],
            'typescript': ['.ts', '.tsx'],
            'go': ['.go'],
            'java': ['.java'],
            'rust': ['.rs'],
        }
        
        extensions = ext_map.get(language, [])
        
        for ext in extensions:
            for path in self.repo_path.rglob(f'*{ext}'):
                if str(path).endswith(file_path):
                    continue
                
                relative_path = str(path.relative_to(self.repo_path))
                content = self._get_file_content(relative_path)
                
                if module_name in content:
                    importers.append(relative_path)
        
        return importers[:20]  # 限制数量
    
    def _file_to_module(self, file_path: str, language: str) -> str:
        """将文件路径转换为模块名"""
        path = Path(file_path)
        
        if language == "python":
            # Remove .py extension and convert path separators
            module = str(path.with_suffix('')).replace('/', '.').replace('\\', '.')
            return module
        elif language in ["javascript", "typescript"]:
            # Remove extension
            return str(path.with_suffix(''))
        elif language == "go":
            # Go uses directory as package
            return str(path.parent)
        
        return path.stem
    
    def _find_callers(self, file_path: str, function_name: str, 
                      language: str) -> List[Dict[str, Any]]:
        """查找函数的调用者"""
        callers = []
        
        # 使用Semgrep如果可用
        if self.semgrep_enabled:
            semgrep_callers = self._semgrep_find_callers(file_path, function_name, language)
            if semgrep_callers:
                return semgrep_callers
        
        # 回退到简单的grep搜索
        call_pattern = rf'\b{re.escape(function_name)}\s*\('
        
        ext_map = {
            'python': ['.py'],
            'javascript': ['.js', '.jsx'],
            'typescript': ['.ts', '.tsx'],
            'go': ['.go'],
            'java': ['.java'],
            'rust': ['.rs'],
        }
        
        extensions = ext_map.get(language, [])
        
        for ext in extensions:
            for path in self.repo_path.rglob(f'*{ext}'):
                relative_path = str(path.relative_to(self.repo_path))
                content = self._get_file_content(relative_path)
                
                for i, line in enumerate(content.split('\n'), 1):
                    if re.search(call_pattern, line):
                        callers.append({
                            "file": relative_path,
                            "line": i,
                            "function": self._get_enclosing_function(content, i, language),
                            "code": line.strip()[:100]
                        })
        
        return callers[:20]
    
    def _find_callees(self, file_path: str, line_range: Tuple[int, int],
                      language: str) -> List[Dict[str, Any]]:
        """查找修改区域调用的函数"""
        callees = []
        
        content = self._get_file_content(file_path)
        if not content:
            return callees
        
        lines = content.split('\n')
        start, end = line_range
        
        call_pattern = self.CALL_PATTERNS.get(language, r'(\w+)\s*\(')
        
        for i in range(max(0, start - 1), min(len(lines), end)):
            line = lines[i]
            matches = re.findall(call_pattern, line)
            
            for match in matches:
                # 过滤关键字
                keywords = {'if', 'for', 'while', 'switch', 'catch', 'with', 'print', 'return'}
                if match.lower() not in keywords:
                    callees.append({
                        "function": match,
                        "file": file_path,
                        "line": i + 1,
                        "code": line.strip()[:100]
                    })
        
        # 去重
        seen = set()
        unique_callees = []
        for c in callees:
            key = c["function"]
            if key not in seen:
                seen.add(key)
                unique_callees.append(c)
        
        return unique_callees[:20]
    
    def _semgrep_find_callers(self, file_path: str, function_name: str,
                              language: str) -> List[Dict[str, Any]]:
        """使用Semgrep查找调用者"""
        try:
            lang_map = {
                'python': 'python',
                'javascript': 'javascript',
                'typescript': 'typescript',
                'go': 'go',
                'java': 'java',
                'rust': 'rust',
            }
            
            semgrep_lang = lang_map.get(language)
            if not semgrep_lang:
                return []
            
            # 构建Semgrep规则
            rule = {
                "rules": [{
                    "id": "find-callers",
                    "pattern": f"{function_name}(...)",
                    "languages": [semgrep_lang],
                    "message": "Function call found",
                    "severity": "INFO"
                }]
            }
            
            rule_file = self.repo_path / ".semgrep_temp_rule.yaml"
            rule_file.write_text(json.dumps(rule))
            
            try:
                result = subprocess.run(
                    ["semgrep", "--config", str(rule_file), "--json", str(self.repo_path)],
                    capture_output=True,
                    text=True,
                    timeout=60
                )
                
                if result.returncode == 0:
                    output = json.loads(result.stdout)
                    callers = []
                    
                    for finding in output.get("results", []):
                        callers.append({
                            "file": finding.get("path", ""),
                            "line": finding.get("start", {}).get("line", 0),
                            "function": function_name,
                            "code": finding.get("extra", {}).get("lines", "")[:100]
                        })
                    
                    return callers
                    
            finally:
                if rule_file.exists():
                    rule_file.unlink()
                    
        except Exception as e:
            logger.debug(f"[CrossFileAnalyzer] Semgrep查找失败: {e}")
        
        return []
    
    def _extract_symbols_from_range(self, file_path: str, 
                                    line_range: Tuple[int, int],
                                    language: str) -> List[Symbol]:
        """从指定行范围提取符号定义"""
        symbols = []
        
        content = self._get_file_content(file_path)
        if not content:
            return symbols
        
        lines = content.split('\n')
        start, end = line_range
        
        patterns = self.FUNCTION_PATTERNS.get(language, [])
        
        for i in range(max(0, start - 1), min(len(lines), end)):
            line = lines[i]
            for pattern in patterns:
                match = re.search(pattern, line)
                if match:
                    symbols.append(Symbol(
                        name=match.group(1),
                        type="function",
                        file_path=file_path,
                        line_start=i + 1,
                        signature=line.strip()[:100]
                    ))
        
        return symbols
    
    def _find_api_routes(self, file_path: str, language: str) -> List[str]:
        """查找文件中的API路由定义"""
        routes = []
        
        content = self._get_file_content(file_path)
        if not content:
            return routes
        
        patterns = self.API_ROUTE_PATTERNS.get(language, [])
        
        for pattern in patterns:
            matches = re.findall(pattern, content, re.MULTILINE)
            routes.extend(matches)
        
        return list(set(routes))
    
    def _find_auth_checks(self, file_path: str, language: str) -> List[str]:
        """查找文件中的认证检查"""
        checks = []
        
        content = self._get_file_content(file_path)
        if not content:
            return checks
        
        patterns = self.AUTH_PATTERNS.get(language, [])
        
        for pattern in patterns:
            matches = re.findall(pattern, content, re.MULTILINE)
            checks.extend(matches)
        
        return list(set(checks))
    
    def _analyze_interface_changes(self, file_path: str,
                                   modified_symbols: List[str],
                                   language: str) -> List[Dict[str, Any]]:
        """分析接口变更"""
        changes = []
        
        # 这里简化实现，实际应该比较修改前后的签名
        for symbol in modified_symbols:
            changes.append({
                "symbol": symbol,
                "file": file_path,
                "change_type": "modified",
                "details": "符号已修改，可能影响调用方"
            })
        
        return changes
    
    def _is_breaking_change(self, change: Dict[str, Any]) -> bool:
        """判断是否为破坏性变更"""
        # 简化实现
        breaking_indicators = [
            "removed",
            "signature changed",
            "parameter removed",
            "return type changed"
        ]
        
        details = change.get("details", "").lower()
        return any(indicator in details for indicator in breaking_indicators)
    
    def _get_enclosing_function(self, content: str, line_num: int, 
                                language: str) -> str:
        """获取包含指定行的函数名"""
        lines = content.split('\n')
        patterns = self.FUNCTION_PATTERNS.get(language, [])
        
        # 向上搜索函数定义
        for i in range(line_num - 1, -1, -1):
            line = lines[i] if i < len(lines) else ""
            for pattern in patterns:
                match = re.search(pattern, line)
                if match:
                    return match.group(1)
        
        return "unknown"
    
    def _find_related_snippets(self, file_path: str,
                               line_range: Tuple[int, int],
                               callers: List[Dict[str, Any]],
                               language: str) -> List[Dict[str, Any]]:
        """查找相关代码片段"""
        snippets = []
        
        # 添加调用者的代码片段
        for caller in callers[:5]:
            caller_file = caller.get("file", "")
            caller_line = caller.get("line", 0)
            
            content = self._get_file_content(caller_file)
            if content:
                lines = content.split('\n')
                start = max(0, caller_line - 3)
                end = min(len(lines), caller_line + 3)
                
                snippet = '\n'.join(lines[start:end])
                snippets.append({
                    "file": caller_file,
                    "line_start": start + 1,
                    "line_end": end,
                    "code": snippet[:500],
                    "relation": "caller"
                })
        
        return snippets


class DiffImpactAnalyzer:
    """
    Diff影响分析器
    分析代码变更的传播影响
    """
    
    def __init__(self, cross_file_analyzer: CrossFileAnalyzer):
        self.analyzer = cross_file_analyzer
    
    def analyze_impact(self, diff_ir: Dict[str, Any]) -> Dict[str, Any]:
        """
        分析整个PR的跨文件影响
        
        Args:
            diff_ir: Diff IR数据
        
        Returns:
            影响分析结果
        """
        logger.info("[DiffImpactAnalyzer] 开始分析PR影响")
        
        impact = {
            "files_analyzed": 0,
            "total_callers": 0,
            "total_callees": 0,
            "breaking_changes": [],
            "high_impact_files": [],
            "api_changes": [],
            "auth_related_changes": [],
            "file_impacts": []
        }
        
        files = diff_ir.get("files", [])
        
        for file_info in files:
            file_path = file_info.get("file_path", "")
            language = file_info.get("language", "")
            
            if not language:
                language = self.analyzer._detect_language(file_path)
            
            hunks = file_info.get("hunks", [])
            
            for hunk in hunks:
                # 获取行范围
                new_start = hunk.get("new_start", 1)
                new_count = hunk.get("new_count", 0)
                line_range = (new_start, new_start + new_count)
                
                # 分析跨文件上下文
                context = self.analyzer.analyze_cross_file_context(
                    file_path=file_path,
                    line_range=line_range,
                    language=language
                )
                
                # 汇总结果
                impact["files_analyzed"] += 1
                impact["total_callers"] += len(context.callers)
                impact["total_callees"] += len(context.callees)
                
                if context.breaking_changes:
                    impact["breaking_changes"].extend(context.breaking_changes)
                
                if context.api_routes:
                    impact["api_changes"].append({
                        "file": file_path,
                        "routes": context.api_routes
                    })
                
                if context.auth_checks:
                    impact["auth_related_changes"].append({
                        "file": file_path,
                        "auth_checks": context.auth_checks
                    })
                
                # 高影响文件判定
                if len(context.callers) > 5 or context.breaking_changes:
                    impact["high_impact_files"].append({
                        "file": file_path,
                        "caller_count": len(context.callers),
                        "has_breaking_changes": bool(context.breaking_changes)
                    })
                
                impact["file_impacts"].append({
                    "file": file_path,
                    "line_range": line_range,
                    "context": context.to_dict()
                })
        
        logger.info(f"[DiffImpactAnalyzer] 分析完成: "
                   f"{impact['files_analyzed']} 文件, "
                   f"{len(impact['high_impact_files'])} 高影响文件")
        
        return impact


def create_cross_file_analyzer(repo_path: str) -> CrossFileAnalyzer:
    """创建跨文件分析器实例"""
    return CrossFileAnalyzer(repo_path=repo_path)


def analyze_pr_cross_file_impact(repo_path: str, 
                                 diff_ir: Dict[str, Any]) -> Dict[str, Any]:
    """
    分析PR的跨文件影响（便捷函数）
    
    Args:
        repo_path: 仓库路径
        diff_ir: Diff IR数据
    
    Returns:
        影响分析结果
    """
    analyzer = CrossFileAnalyzer(repo_path=repo_path)
    impact_analyzer = DiffImpactAnalyzer(analyzer)
    return impact_analyzer.analyze_impact(diff_ir)
