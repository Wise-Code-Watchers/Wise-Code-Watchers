"""
Integration Helper for Structured JSON Output System.

This module provides a high-level API for using the new structured output system
with validation and auto-downgrading.

Example usage:
    from agents.vulnerability.src.prompts import (
        structured_output_review,
        StructuredOutputConfig
    )

    # Configure
    config = StructuredOutputConfig(
        enable_auto_downgrade=True,
        max_diff_size=50000
    )

    # Run review
    result = structured_output_review(
        llm=llm,
        pr_metadata={"repo": "owner/repo", "pr_number": 123, ...},
        diff_content=pr_diff,
        semgrep_findings=semgrep_results,
        config=config
    )

    # Get results
    if result.success:
        markdown = result.markdown  # Ready for GitHub
        json_report = result.report  # Validated JSON
        validation_errors = result.validation_errors
        downgraded_items = result.downgraded_items
"""

import logging
from dataclasses import dataclass, field
from typing import Dict, Any, List, Optional
from langchain_openai import ChatOpenAI

from .schema_validator import (
    SchemaValidator,
    parse_and_validate_llm_output,
    validate_auto_downgrade_rules
)
from .markdown_renderer import render_comprehensive_review
from .prompt import STRUCTURED_OUTPUT_SYSTEM, format_structured_user_prompt

logger = logging.getLogger(__name__)


@dataclass
class StructuredOutputConfig:
    """Configuration for structured output system."""

    # Auto-downgrade settings
    enable_auto_downgrade: bool = True
    downgrade_low_confidence: bool = True
    downgrade_nil_without_path: bool = True

    # Token limits
    max_diff_size: int = 50000
    max_semgrep_findings: int = 50

    # Validation settings
    strict_validation: bool = False  # If True, fail on validation errors

    # Retry settings
    max_retries: int = 1
    retry_on_validation_error: bool = False


@dataclass
class StructuredOutputResult:
    """Result of structured output review."""

    # Success flag
    success: bool

    # Validated and filtered report
    report: Optional[Dict[str, Any]] = None

    # Rendered markdown
    markdown: Optional[str] = None

    # Validation and processing info
    validation_errors: List[str] = field(default_factory=list)
    downgraded_items: List[Dict[str, Any]] = field(default_factory=list)

    # Raw LLM output (for debugging)
    raw_output: Optional[str] = None

    # Error message if failed
    error: Optional[str] = None


def structured_output_review(
    llm: ChatOpenAI,
    pr_metadata: Dict[str, Any],
    diff_content: str,
    semgrep_findings: Optional[List[Dict[str, Any]]] = None,
    config: Optional[StructuredOutputConfig] = None,
) -> StructuredOutputResult:
    """
    Run a structured PR review with JSON validation and auto-downgrading.

    This is the main entry point for the new structured output system.
    It handles:
    1. Building prompts with nil-guard rules and rubrics
    2. Calling the LLM
    3. Parsing and validating JSON output
    4. Auto-downgrading low-confidence findings
    5. Rendering markdown for GitHub

    Args:
        llm: LangChain LLM instance
        pr_metadata: PR metadata dict with keys:
            - repo: str (e.g., "owner/repo")
            - pr_number: int
            - base_sha: str
            - head_sha: str
            - files_changed: int
        diff_content: PR diff content
        semgrep_findings: Optional list of Semgrep scan results
        config: Optional configuration

    Returns:
        StructuredOutputResult with validated report and markdown
    """
    if config is None:
        config = StructuredOutputConfig()

    result = StructuredOutputResult(success=False)

    try:
        # Step 1: Build prompts
        logger.info("[Structured Output] Building prompts...")
        system_prompt = STRUCTURED_OUTPUT_SYSTEM
        user_prompt = format_structured_user_prompt(
            pr_metadata=pr_metadata,
            diff_content=diff_content[:config.max_diff_size],
            semgrep_findings=(semgrep_findings[:config.max_semgrep_findings]
                             if semgrep_findings else None)
        )

        # Step 2: Call LLM
        logger.info("[Structured Output] Calling LLM...")
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ]

        raw_output = llm.invoke(messages).content
        result.raw_output = raw_output

        # Step 3: Parse and validate JSON
        logger.info("[Structured Output] Parsing and validating JSON...")
        validator = SchemaValidator()

        report, parse_errors = parse_and_validate_llm_output(
            raw_output=raw_output,
            validator=validator
        )

        result.validation_errors = parse_errors

        if report is None:
            result.error = f"Failed to parse LLM output as JSON: {parse_errors}"
            logger.error(f"[Structured Output] {result.error}")
            return result

        # Step 4: Apply auto-downgrade rules
        if config.enable_auto_downgrade:
            logger.info("[Structured Output] Applying auto-downgrade rules...")
            report, downgraded = validate_auto_downgrade_rules(report)
            result.downgraded_items = downgraded

            if downgraded:
                logger.info(
                    f"[Structured Output] Downgraded {len(downgraded)} items "
                    f"to suggestions"
                )

        # Step 5: Render markdown
        logger.info("[Structured Output] Rendering markdown...")
        markdown = render_comprehensive_review(report)

        # Success
        result.success = True
        result.report = report
        result.markdown = markdown

        logger.info(
            f"[Structured Output] Review complete: "
            f"{report.get('summary', {}).get('security_issues', 0)} security issues, "
            f"{report.get('summary', {}).get('logic_issues', 0)} logic issues, "
            f"{len(report.get('non_blocking_suggestions', []))} suggestions"
        )

        return result

    except Exception as e:
        result.error = f"Structured output review failed: {str(e)}"
        logger.error(f"[Structured Output] {result.error}", exc_info=True)
        return result


def convert_legacy_report_to_structured(
    legacy_report: Dict[str, Any],
    pr_metadata: Dict[str, Any]
) -> Dict[str, Any]:
    """
    Convert legacy report format to new structured JSON format.

    This helps migrate existing reports to the new schema.

    Args:
        legacy_report: Old format report (from logic_review/security_review)
        pr_metadata: PR metadata for the PR section

    Returns:
        New format report following the schema
    """
    findings = []
    suggestions = []

    # Extract logic issues
    logic_review = legacy_report.get("logic_review", {})
    for unit in logic_review.get("issues", []):
        if unit.get("result") == "ISSUE":
            for issue in unit.get("issues", []):
                findings.append({
                    "id": f"LOGIC-{len(findings) + 1}",
                    "category": "LOGIC",
                    "title": issue.get("title", "Logic Issue"),
                    "severity": issue.get("severity", "MEDIUM").upper(),
                    "confidence": issue.get("confidence", "MEDIUM").upper(),
                    "file": unit.get("_meta", {}).get("file_path", ""),
                    "line_start": issue.get("location", {}).get("line_start", 0),
                    "line_end": issue.get("location", {}).get("line_end", 0),
                    "evidence": {
                        "code_excerpt": issue.get("evidence", {}).get("diff_snippet", ""),
                        "reasoning": issue.get("evidence", {}).get("explanation", "")
                    },
                    "trigger": issue.get("trigger_condition", ""),
                    "impact": issue.get("error_result", ""),
                    "recommendation": issue.get("suggestion", "")
                })

    # Extract security issues
    security_review = legacy_report.get("security_review", {})
    for unit in security_review.get("issues", []):
        if unit.get("result") == "ISSUE":
            for vuln in unit.get("issues", []):
                findings.append({
                    "id": f"SEC-{len(findings) + 1}",
                    "category": "SECURITY",
                    "title": vuln.get("title", "Security Issue"),
                    "severity": vuln.get("severity", "MEDIUM").upper(),
                    "confidence": vuln.get("confidence", "MEDIUM").upper(),
                    "cwe": ",".join(vuln.get("cwe", [])),
                    "file": unit.get("_meta", {}).get("file_path", ""),
                    "line_start": vuln.get("location", {}).get("line_start", 0),
                    "line_end": vuln.get("location", {}).get("line_end", 0),
                    "evidence": {
                        "code_excerpt": vuln.get("evidence", {}).get("source", ""),
                        "reasoning": vuln.get("evidence", {}).get("dataflow", "")
                    },
                    "trigger": vuln.get("attack_scenario", {}).get("attack_vector", ""),
                    "impact": vuln.get("attack_scenario", {}).get("impact", ""),
                    "recommendation": vuln.get("remediation", "")
                })

    # Build summary
    security_count = sum(1 for f in findings if f.get("category") == "SECURITY")
    logic_count = sum(1 for f in findings if f.get("category") == "LOGIC")
    maintainability_count = sum(1 for f in findings if f.get("category") == "MAINTAINABILITY")

    # Determine highest severity
    if findings:
        severity_order = {"CRITICAL": 4, "HIGH": 3, "MEDIUM": 2, "LOW": 1}
        highest = max(
            findings,
            key=lambda f: severity_order.get(f.get("severity", "LOW"), 0)
        )
        highest_severity = highest.get("severity", "NONE")
    else:
        highest_severity = "NONE"

    # Build structured report
    structured_report = {
        "tool": "WiseCodeWatchers",
        "version": "3.0",
        "pr": {
            "repo": pr_metadata.get("repo", ""),
            "number": pr_metadata.get("pr_number", 0),
            "base_sha": pr_metadata.get("base_sha", ""),
            "head_sha": pr_metadata.get("head_sha", "")
        },
        "summary": {
            "security_issues": security_count,
            "logic_issues": logic_count,
            "maintainability_issues": maintainability_count,
            "highest_severity": highest_severity,
            "notes": []
        },
        "findings": findings,
        "non_blocking_suggestions": suggestions
    }

    return structured_report
