"""
漏洞分析模块 - 对应6.py功能
基于AI和静态分析结果进行漏洞分析，使用LLM生成最终报告（已移除CodeQL依赖）
注意：虽然函数名中仍包含"codeql"，但实际调用时传入空的codeql_results字典即可正常工作
"""

import json
import logging
import os
import threading
import traceback
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import Any, Dict, List, Tuple, Optional

from langchain_core.messages import SystemMessage, HumanMessage
from langchain_openai import ChatOpenAI

# 配置日志
logger = logging.getLogger(__name__)

# Thread-safe printing (保留用于兼容性)
print_lock = threading.Lock()

def safe_print(*args, **kwargs):
    """Thread-safe print function."""
    with print_lock:
        print(*args, **kwargs)


def read_json(path: str) -> Dict[str, Any]:
    """Read JSON file safely."""
    with open(path, "r", encoding="utf-8") as f:
        return json.load(f)


def write_json(path: str, obj: Any) -> None:
    """Write JSON file safely."""
    os.makedirs(os.path.dirname(path) or ".", exist_ok=True)
    with open(path, "w", encoding="utf-8") as f:
        json.dump(obj, f, ensure_ascii=False, indent=2)


def read_file_content(path: str) -> str:
    """Read file content if exists, return empty string if not."""
    try:
        with open(path, "r", encoding="utf-8") as f:
            return f.read()
    except FileNotFoundError:
        return f"FILE_NOT_FOUND: {path}"
    except Exception as e:
        return f"ERROR_READING_FILE {path}: {str(e)}"


def load_codeql_results(results_dir: str) -> Dict[str, Any]:
    """Load CodeQL query results from results directory."""
    results = {}
    if not os.path.exists(results_dir):
        return results

    manifest_path = os.path.join(results_dir, "results_manifest.json")
    if not os.path.exists(manifest_path):
        return results

    manifest = read_json(manifest_path)

    for result_item in manifest:
        template_id = result_item.get("template_id")
        json_path = result_item.get("json")

        if json_path and os.path.exists(json_path):
            result_data = read_json(json_path)
            results[template_id] = {
                "result_data": result_data,
                "metadata": result_item
            }

    return results


def get_feature_hunks_with_lines(feature: Dict[str, Any], diff_ir: Dict[str, Any]) -> List[Dict[str, Any]]:
    """
    Get detailed hunks information with line numbers for a feature.
    """
    feature_hunks = feature.get("hunks", [])
    detailed_hunks = []

    for feature_hunk in feature_hunks:
        hunk_id = feature_hunk.get("hunk_id")
        file_path = feature_hunk.get("file_path")

        if not hunk_id or not file_path:
            continue

        # Find corresponding hunk in diff_ir
        try:
            file_idx, hunk_idx = map(int, hunk_id.split(":"))
            diff_files = diff_ir.get("files", [])
            if file_idx < len(diff_files):
                diff_file = diff_files[file_idx]
                diff_hunks = diff_file.get("hunks", [])
                if hunk_idx < len(diff_hunks):
                    diff_hunk = diff_hunks[hunk_idx]
                    detailed_hunks.append({
                        "hunk_id": hunk_id,
                        "file_path": file_path,
                        "old_start": diff_hunk.get("old_start"),
                        "old_count": diff_hunk.get("old_count"),
                        "new_start": diff_hunk.get("new_start"),
                        "new_count": diff_hunk.get("new_count"),
                        "header": diff_hunk.get("header"),
                        "lines": diff_hunk.get("lines", []),
                        "functional_change": feature_hunk.get("functional_change"),
                        "risk_score": feature_hunk.get("risk_score"),
                        "severity": feature_hunk.get("severity")
                    })
        except (ValueError, IndexError):
            continue

    return detailed_hunks


def extract_diff_files_for_feature(feature: Dict[str, Any], pr_dir: str) -> Dict[str, Tuple[str, str]]:
    """
    Extract before and after file content for a feature.
    Returns: {file_path: (before_content, after_content)}
    """
    files_processed = {}

    # Find all hunks for this feature
    hunks = feature.get("hunks", [])
    for hunk in hunks:
        file_path = hunk.get("file_path")
        if not file_path:
            continue

        if file_path in files_processed:
            continue  # Already processed this file

        # Try to find the file in the repo snapshots
        # Assuming we have both before and after snapshots in the PR directory
        before_path = os.path.join(pr_dir, "repo_before", file_path)
        after_path = os.path.join(pr_dir, "repo_after", file_path)

        # Fallback: try to find in parent directories
        if not os.path.exists(before_path):
            before_path = os.path.join(pr_dir, "..", "repo_before", file_path)
        if not os.path.exists(after_path):
            after_path = os.path.join(pr_dir, "..", "repo_after", file_path)

        before_content = read_file_content(before_path)
        after_content = read_file_content(after_path)

        files_processed[file_path] = (before_content, after_content)

    return files_processed


def map_queries_to_feature(feature: Dict[str, Any], query_plan: Dict[str, Any]) -> List[Dict[str, Any]]:
    """
    Map CodeQL queries to a specific feature based on relevance.
    """
    feature_hunks = feature.get("hunks", [])
    feature_files = {hunk.get("file_path") for hunk in feature_hunks if hunk.get("file_path")}

    relevant_queries = []
    all_queries = query_plan.get("queries", [])

    for query in all_queries:
        query_params = query.get("params", {})
        query_file = query_params.get("module_path", query_params.get("file_path", ""))

        # Convert module_path to file_path if needed
        if query_file and "." in query_file:
            query_file = query_file.replace(".", "/") + ".py"

        # Check if query relates to files in this feature
        if any(feature_file in query_file or query_file in feature_file
               for feature_file in feature_files if feature_file):
            relevant_queries.append(query)
        elif query.get("template_id") in ["PY_REFERENCES_OF_SYMBOL", "PY_CALLERS_OF_FUNCTION"]:
            # Symbol-based queries might be relevant
            relevant_queries.append(query)

    return relevant_queries


def format_file_with_diff_highlight(
    file_content: str,
    diff_lines: List[Dict[str, Any]],
    new_start: int,
    new_count: int
) -> str:
    """
    Format file content with diff highlighting.
    """
    if not file_content or not diff_lines:
        return file_content

    lines = file_content.split('\n')
    highlighted_lines = []

    # Create a set of modified line numbers
    modified_lines = set()
    for diff_line in diff_lines:
        line_type = diff_line.get("type")
        new_lineno = diff_line.get("new_lineno")
        if line_type in ["add", "del"] and new_lineno is not None:
            modified_lines.add(new_lineno)

    # Highlight modified lines
    for i, line in enumerate(lines, 1):
        if i in modified_lines:
            highlighted_lines.append(f"[MODIFIED] {line}")
        else:
            highlighted_lines.append(line)

    return '\n'.join(highlighted_lines)


def build_vulnerability_analysis_prompt(
    feature: Dict[str, Any],
    files_content: Dict[str, Tuple[str, str]],
    relevant_queries: List[Dict[str, Any]],
    codeql_results: Dict[str, Any],
    detailed_hunks: List[Dict[str, Any]]
) -> str:
    """Build comprehensive LLM prompt for vulnerability analysis."""

    feature_name = feature.get("feature_name", "")
    feature_summary = feature.get("summary", "")
    business_impact = feature.get("business_impact", "")
    risk_overview = feature.get("risk_overview", {})
    key_risks = risk_overview.get("key_risks", [])

    # Build files section with diff details
    files_section = []

    # Group hunks by file_path
    hunks_by_file = {}
    for hunk in detailed_hunks:
        file_path = hunk.get("file_path")
        if file_path not in hunks_by_file:
            hunks_by_file[file_path] = []
        hunks_by_file[file_path].append(hunk)

    for file_path, (before, after) in files_content.items():
        files_section.append(f"## File: {file_path}")

        # Add diff information for this file
        if file_path in hunks_by_file:
            file_hunks = hunks_by_file[file_path]
            files_section.append("### 具体修改信息:")
            for hunk in file_hunks:
                hunk_id = hunk.get("hunk_id")
                old_start = hunk.get("old_start")
                old_count = hunk.get("old_count")
                new_start = hunk.get("new_start")
                new_count = hunk.get("new_count")
                functional_change = hunk.get("functional_change", "")
                risk_score = hunk.get("risk_score", 0)
                severity = hunk.get("severity", "")

                files_section.append(f"**Hunk {hunk_id}:**")
                files_section.append(f"- 修改范围: {old_start}-{old_start + old_count - 1} → {new_start}-{new_start + new_count - 1}")
                files_section.append(f"- 功能变更: {functional_change}")
                files_section.append(f"- 风险评分: {risk_score} ({severity})")

                # Add actual diff lines
                diff_lines = hunk.get("lines", [])
                if diff_lines:
                    files_section.append("- 具体修改内容:")
                    for diff_line in diff_lines[:20]:  # Limit to first 20 lines
                        line_type = diff_line.get("type")
                        content = diff_line.get("content", "")
                        old_lineno = diff_line.get("old_lineno")
                        new_lineno = diff_line.get("new_lineno")

                        prefix = ""
                        if line_type == "add":
                            prefix = "+"
                        elif line_type == "del":
                            prefix = "-"
                        else:
                            prefix = " "

                        line_info = f"(old:{old_lineno}, new:{new_lineno})" if old_lineno is not None or new_lineno is not None else ""
                        files_section.append(f"  {prefix} {line_info} {content}")

                    if len(diff_lines) > 20:
                        files_section.append(f"  ... (还有 {len(diff_lines) - 20} 行修改)")

                files_section.append("")

        # Add file content with highlighting
        if file_path in hunks_by_file:
            # Find the relevant hunk for highlighting
            file_hunks = hunks_by_file[file_path]
            if file_hunks:
                hunk = file_hunks[0]  # Use first hunk for highlighting
                highlighted_after = format_file_with_diff_highlight(
                    after, hunk.get("lines", []),
                    hunk.get("new_start", 1), hunk.get("new_count", 0)
                )
                files_section.append("### AFTER (修改后，带修改标记):")
                files_section.append(f"```\n{highlighted_after[:3000]}...\n```" if len(highlighted_after) > 3000 else f"```\n{highlighted_after}\n```")
        else:
            files_section.append("### AFTER (修改后):")
            files_section.append(f"```\n{after[:2000]}...\n```" if len(after) > 2000 else f"```\n{after}\n```")

        files_section.append("")

    # Build CodeQL results section
    codeql_section = []
    for query in relevant_queries:
        template_id = query.get("template_id")
        if template_id in codeql_results:
            result = codeql_results[template_id]
            codeql_section.append(f"### CodeQL Query: {template_id}")
            codeql_section.append(f"**Why:** {query.get('why', '')}")
            codeql_section.append(f"**Params:** {json.dumps(query.get('params', {}), ensure_ascii=False)}")

            # Include CodeQL results (limit size)
            result_data = result.get("result_data", [])
            if isinstance(result_data, list) and len(result_data) > 10:
                codeql_section.append(f"**Results (showing first 10 of {len(result_data)}):**")
                codeql_section.append(json.dumps(result_data[:10], ensure_ascii=False, indent=2))
            else:
                codeql_section.append(f"**Results:**")
                codeql_section.append(json.dumps(result_data, ensure_ascii=False, indent=2))
            codeql_section.append("")

    prompt = f"""你是一个专业的代码安全审查专家。请分析以下PR功能变更是否存在安全漏洞。

## 功能分析目标
- **功能名称**: {feature_name}
- **功能摘要**: {feature_summary}
- **业务影响**: {business_impact}
- **已知风险**: {', '.join(key_risks)}

## 代码变更详情

{chr(10).join(files_section)}

## CodeQL查询结果

{chr(10).join(codeql_section) if codeql_section else "无相关CodeQL查询结果"}

## 分析要求

请仔细分析上述代码变更和CodeQL查询结果，识别是否存在以下类型的安全问题：
1. **并发安全问题** - 数据竞争、死锁、条件竞争等
2. **逻辑错误** - 边界条件、错误处理、状态管理等
3. **注入漏洞** - SQL注入、命令注入、路径遍历等
4. **权限控制** - 访问控制、授权绕过等
5. **数据完整性** - 数据泄露、数据篡改等
6. **资源管理** - 内存泄漏、资源耗尽等

## 重要：行号定位说明

上面提供了具体的diff信息，包含：
- **精确的修改行号范围** (old_start-old_end → new_start-new_end)
- **逐行修改详情** (显示每行是添加"+"、删除"-"还是保持" ")
- **标记了修改的代码** (使用[MODIFIED]标记)

## 输出格式要求

请严格按照以下JSON格式输出分析结果：

{{
  "vulnerability_found": true/false,
  "vulnerability_summary": "简要总结发现的主要问题",
  "vulnerabilities": [
    {{
      "type": "问题类型",
      "severity": "critical/high/medium/low/info",
      "confidence": "high/medium/low",
      "file_path": "文件路径",
      "line_number": 具体行号或范围（必须基于上面提供的diff信息）,
      "description": "详细问题描述",
      "root_cause": "根本原因分析",
      "exploit_scenario": "可能的利用场景",
      "fix_recommendation": "修复建议",
      "code_snippet": "问题代码片段",
      "references_codeql": "相关的CodeQL查询结果"
    }}
  ],
  "overall_risk_assessment": "整体风险评估",
  "additional_observations": "其他观察"
}}

## 关键要求
- **必须使用提供的diff行号信息**，不要使用-1
- line_number必须是具体的行号或范围，如42或45-48
- 如果没有发现漏洞，vulnerabilities数组应为空
- code_snippet请包含实际的问题代码
- 必须输出严格的JSON格式，不要包含markdown标记或额外解释
"""

    return prompt


def analyze_feature_vulnerability(
    feature: Dict[str, Any],
    files_content: Dict[str, Tuple[str, str]],
    relevant_queries: List[Dict[str, Any]],
    codeql_results: Dict[str, Any],
    llm: ChatOpenAI,
    feature_index: int,
    total_features: int,
    detailed_hunks: List[Dict[str, Any]]
) -> Dict[str, Any]:
    """Analyze a single feature for vulnerabilities using LLM."""

    feature_id = feature.get("feature_id", "unknown")
    feature_name = feature.get("feature_name", "unknown")
    risk_score = feature.get("risk_overview", {}).get("overall_risk_score", 0)

    logger.info(f"[Vulnerability Analyzer] [{feature_index}/{total_features}] 开始分析功能: {feature_id} - {feature_name}")
    logger.info(f"[Vulnerability Analyzer] {feature_id}: 风险评分: {risk_score}, 涉及文件: {len(files_content)} 个")
    logger.debug(f"[Vulnerability Analyzer] {feature_id}: 相关查询: {len(relevant_queries)} 个, CodeQL结果: {len(codeql_results)} 个")

    safe_print(f"[{feature_index}/{total_features}] Starting analysis: {feature_id} - {feature_name}")

    # 记录详细的分析输入信息
    if os.getenv("ENABLE_DETAILED_LOGS", "false").lower() == "true":
        logger.debug(f"[Vulnerability Analyzer] {feature_id}: 功能详情:")
        logger.debug(f"[Vulnerability Analyzer] {feature_id}:   - 摘要: {feature.get('summary', 'N/A')}")
        logger.debug(f"[Vulnerability Analyzer] {feature_id}:   - 业务影响: {feature.get('business_impact', 'N/A')}")
        logger.debug(f"[Vulnerability Analyzer] {feature_id}:   - 详细hunks: {len(detailed_hunks)} 个")
        logger.debug(f"[Vulnerability Analyzer] {feature_id}:   - 文件列表: {list(files_content.keys())}")

        if relevant_queries:
            for i, query in enumerate(relevant_queries[:3]):  # 只记录前3个查询
                logger.debug(f"[Vulnerability Analyzer] {feature_id}: 查询{i+1}: {query.get('template_id', 'unknown')} - {query.get('why', 'N/A')[:100]}")

    try:
        logger.debug(f"[Vulnerability Analyzer] {feature_id}: 构建分析prompt...")
        prompt = build_vulnerability_analysis_prompt(feature, files_content, relevant_queries, codeql_results, detailed_hunks)

        # 记录prompt大小信息
        if os.getenv("ENABLE_DETAILED_LOGS", "false").lower() == "true":
            logger.debug(f"[Vulnerability Analyzer] {feature_id}: prompt长度: {len(prompt)} 字符")
            prompt_preview = prompt[:1500] + "..." if len(prompt) > 1500 else prompt
            logger.debug(f"[Vulnerability Analyzer] {feature_id}: prompt内容预览:\n{prompt_preview}")

        messages = [
            SystemMessage(content="你是一个专业的代码安全审查专家，专注于发现代码变更中的安全漏洞。"),
            HumanMessage(content=prompt)
        ]

        logger.debug(f"[Vulnerability Analyzer] {feature_id}: 开始调用LLM...")
        
        # Retry logic for LLM calls with null response handling
        max_retries = 3
        response_text = None
        for attempt in range(max_retries):
            try:
                response = llm.invoke(messages)
                response_text = response.content if hasattr(response, "content") else str(response)
                if response_text:
                    break
            except TypeError as e:
                if "null value for `choices`" in str(e):
                    import time
                    logger.warning(f"[Vulnerability Analyzer] {feature_id}: LLM返回null choices，重试 {attempt + 1}/{max_retries}")
                    time.sleep(1)
                    continue
                raise
            except Exception as e:
                logger.warning(f"[Vulnerability Analyzer] {feature_id}: LLM调用失败，重试 {attempt + 1}/{max_retries}: {str(e)}")
                import time
                time.sleep(1)
                continue
        
        if not response_text:
            # Fallback when LLM is unavailable
            logger.warning(f"[Vulnerability Analyzer] {feature_id}: LLM调用失败，使用fallback结果")
            return {
                "feature_id": feature.get("feature_id"),
                "feature_name": feature.get("feature_name"),
                "vulnerability_found": False,
                "vulnerability_summary": "LLM服务暂时不可用，无法进行漏洞分析",
                "vulnerabilities": [],
                "overall_risk_assessment": "unknown",
                "additional_observations": "由于LLM API返回空响应，本次分析被跳过",
                "llm_fallback": True,
                "analysis_timestamp": "2025-12-24"
            }

        # 记录LLM响应信息
        if os.getenv("ENABLE_DETAILED_LOGS", "false").lower() == "true":
            logger.debug(f"[Vulnerability Analyzer] {feature_id}: LLM响应长度: {len(response_text)} 字符")
            response_preview = response_text[:1000] + "..." if len(response_text) > 1000 else response_text
            logger.debug(f"[Vulnerability Analyzer] {feature_id}: LLM响应预览:\n{response_preview}")

        # Try to parse JSON response
        logger.debug(f"[Vulnerability Analyzer] {feature_id}: 解析JSON响应...")
        try:
            # Clean up response if it contains markdown
            json_start = response_text.find("{")
            json_end = response_text.rfind("}") + 1
            if json_start != -1 and json_end > json_start:
                json_text = response_text[json_start:json_end]
                result = json.loads(json_text)
            else:
                result = json.loads(response_text)

            logger.debug(f"[Vulnerability Analyzer] {feature_id}: JSON解析成功")
        except json.JSONDecodeError as e:
            logger.warning(f"[Vulnerability Analyzer] {feature_id}: JSON解析失败 - {str(e)}")
            # Fallback if JSON parsing fails
            result = {
                "vulnerability_found": False,
                "vulnerability_summary": "LLM响应解析失败",
                "vulnerabilities": [],
                "overall_risk_assessment": "无法评估",
                "additional_observations": f"LLM原始响应: {response_text[:500]}...",
                "parsing_error": True
            }

        # Add metadata
        result["feature_id"] = feature.get("feature_id")
        result["feature_name"] = feature.get("feature_name")
        result["analysis_timestamp"] = "2025-12-21"

        # 记录分析结果
        vuln_found = result.get("vulnerability_found", False)
        vuln_count = len(result.get("vulnerabilities", []))

        if vuln_found and vuln_count > 0:
            logger.info(f"[Vulnerability Analyzer] {feature_id}: 发现漏洞 - {vuln_count} 个")

            # 记录漏洞详情（详细日志模式）
            if os.getenv("ENABLE_DETAILED_LOGS", "false").lower() == "true":
                for i, vuln in enumerate(result.get("vulnerabilities", [])[:5]):  # 最多记录5个漏洞
                    vuln_type = vuln.get("type", "unknown")
                    severity = vuln.get("severity", "unknown")
                    confidence = vuln.get("confidence", "unknown")
                    line_number = vuln.get("line_number", "unknown")
                    file_path = vuln.get("file_path", "unknown")

                    logger.info(f"[Vulnerability Analyzer] {feature_id}: 漏洞{i+1}: {vuln_type} ({severity}, {confidence})")
                    logger.info(f"[Vulnerability Analyzer] {feature_id}:   位置: {file_path}:{line_number}")
                    logger.debug(f"[Vulnerability Analyzer] {feature_id}:   描述: {vuln.get('description', 'N/A')[:200]}")
        else:
            logger.info(f"[Vulnerability Analyzer] {feature_id}: 未发现漏洞")

        safe_print(f"[{feature_index}/{total_features}] Completed: {feature_id} - Vulnerabilities: {vuln_found}, Count: {vuln_count}")

        logger.debug(f"[Vulnerability Analyzer] {feature_id}: 分析完成")
        return result

    except Exception as e:
        logger.error(f"[Vulnerability Analyzer] {feature_id}: 分析过程中出错 - {str(e)}")
        logger.error(f"[Vulnerability Analyzer] {feature_id}: 异常详情: {traceback.format_exc()}")

        error_result = {
            "vulnerability_found": False,
            "vulnerability_summary": f"分析过程中出错: {str(e)}",
            "vulnerabilities": [],
            "overall_risk_assessment": "分析失败",
            "additional_observations": f"错误: {str(e)}",
            "feature_id": feature.get("feature_id"),
            "feature_name": feature.get("feature_name"),
            "analysis_error": True
        }
        safe_print(f"[{feature_index}/{total_features}] ERROR: {feature_id} - {str(e)}")
        return error_result


def analyze_feature_parallel(args: Tuple[Dict[str, Any], str, Dict[str, Any], Dict[str, Any], Dict[str, Any], int, int, Dict[str, Any], List[Dict[str, Any]]]) -> Dict[str, Any]:
    """
    Parallel analysis function that processes a single feature.
    Args: (feature, pr_dir, relevant_queries, codeql_results, llm_config, feature_index, total_features, diff_ir, detailed_hunks)
    """
    feature, pr_dir, relevant_queries, codeql_results, llm_config, feature_index, total_features, diff_ir, detailed_hunks = args

    # Create LLM instance for this thread
    llm = ChatOpenAI(
        model=llm_config["model"],
        temperature=llm_config["temperature"],
        base_url=llm_config["base_url"],
        api_key=llm_config["api_key"],
    )

    # Extract files content for this feature
    files_content = extract_diff_files_for_feature(feature, pr_dir)

    # Analyze with LLM
    result = analyze_feature_vulnerability(
        feature, files_content, relevant_queries, codeql_results, llm, feature_index, total_features, detailed_hunks
    )

    return result


def analyze_vulnerabilities(
    pr_dir: str,
    feature_risk_plan: Dict[str, Any],
    query_plan: Dict[str, Any],
    codeql_results: Dict[str, Any],
    llm: ChatOpenAI,
    workers: int = 1,
    diff_ir: Optional[Dict[str, Any]] = None
) -> Dict[str, Any]:
    """
    执行漏洞分析

    Args:
        pr_dir: PR目录
        feature_risk_plan: 功能风险计划
        query_plan: 查询计划
        codeql_results: CodeQL结果
        llm: 语言模型
        workers: 并行工作线程数
        diff_ir: 差异信息

    Returns:
        漏洞分析结果
    """
    logger.info(f"[Vulnerability Analyzer] 开始漏洞分析")
    logger.info(f"[Vulnerability Analyzer] PR目录: {pr_dir}")
    logger.info(f"[Vulnerability Analyzer] 并行工作线程数: {workers}")

    # Load diff_ir if not provided
    if not diff_ir:
        logger.debug(f"[Vulnerability Analyzer] 加载diff_ir数据...")
        diff_ir_path = os.path.join(pr_dir, "out", "diff_ir.json")
        try:
            diff_ir = read_json(diff_ir_path)
            logger.debug(f"[Vulnerability Analyzer] 成功加载diff_ir: {len(diff_ir.get('files', []))} 个文件")
        except Exception as e:
            logger.error(f"[Vulnerability Analyzer] 加载diff_ir失败: {str(e)}")
            diff_ir = {"files": []}

    # LLM configuration
    llm_config = {
        "model": llm.model_name,
        "temperature": llm.temperature,
        "base_url": llm.openai_api_base,
        "api_key": llm.openai_api_key,
    }

    logger.info(f"[Vulnerability Analyzer] LLM模型: {llm_config['model']}")

    # Analyze each feature
    features = feature_risk_plan.get("features", [])
    total_features = len(features)

    logger.info(f"[Vulnerability Analyzer] 待分析功能数: {total_features}")

    if total_features == 0:
        logger.warning(f"[Vulnerability Analyzer] 没有需要分析的功能")
        return {
            "analysis_summary": {
                "total_features_analyzed": 0,
                "features_with_vulnerabilities": 0,
                "total_vulnerabilities_found": 0,
            },
            "feature_analyses": []
        }

    # Determine worker count
    if workers <= 1:
        workers = 1
    else:
        workers = min(workers, total_features)

    logger.info(f"[Vulnerability Analyzer] 实际使用工作线程数: {workers}")

    # 记录功能概览
    if os.getenv("ENABLE_DETAILED_LOGS", "false").lower() == "true":
        logger.debug(f"[Vulnerability Analyzer] 功能列表:")
        for i, feature in enumerate(features[:10]):  # 最多显示10个
            feature_id = feature.get("feature_id", "unknown")
            risk_score = feature.get("risk_overview", {}).get("overall_risk_score", 0)
            hunk_count = len(feature.get("hunks", []))
            logger.debug(f"[Vulnerability Analyzer]   功能{i+1}: {feature_id} (风险:{risk_score}, hunk:{hunk_count})")

    safe_print(f"[INFO] Starting vulnerability analysis for {total_features} features using {workers} workers...")

    # Prepare analysis tasks
    logger.debug(f"[Vulnerability Analyzer] 准备分析任务...")
    analysis_tasks = []
    total_queries = 0
    total_hunks = 0

    for i, feature in enumerate(features, 1):
        # Find relevant queries for this feature
        relevant_queries = map_queries_to_feature(feature, query_plan)
        total_queries += len(relevant_queries)

        # Get detailed hunks with line numbers for this feature
        detailed_hunks = get_feature_hunks_with_lines(feature, diff_ir)
        total_hunks += len(detailed_hunks)

        feature_id = feature.get("feature_id", "unknown")
        logger.debug(f"[Vulnerability Analyzer] 功能{feature_id}: {len(relevant_queries)} 个查询, {len(detailed_hunks)} 个详细hunks")

        task_args = (
            feature,
            pr_dir,
            relevant_queries,
            codeql_results,
            llm_config,
            i,
            total_features,
            diff_ir,
            detailed_hunks
        )
        analysis_tasks.append(task_args)

    logger.info(f"[Vulnerability Analyzer] 分析统计: 总查询={total_queries}, 总hunks={total_hunks}")

    all_results = []
    success_count = 0
    error_count = 0
    vulnerability_count = 0

    if workers == 1:
        # Sequential execution
        logger.info(f"[Vulnerability Analyzer] 开始串行分析...")
        safe_print("[INFO] Running sequential analysis...")
        for task_args in analysis_tasks:
            try:
                # For sequential execution, we can pass directly without creating LLM instance
                feature, pr_dir, relevant_queries, codeql_results, llm_config, feature_index, total_features, diff_ir, detailed_hunks = task_args

                logger.debug(f"[Vulnerability Analyzer] 为功能创建LLM实例: {llm_config['model']}")

                # Create LLM instance for sequential execution
                llm = ChatOpenAI(
                    model=llm_config["model"],
                    temperature=llm_config["temperature"],
                    base_url=llm_config["base_url"],
                    api_key=llm_config["api_key"],
                )

                # Extract files content for this feature
                logger.debug(f"[Vulnerability Analyzer] 提取文件内容...")
                files_content = extract_diff_files_for_feature(feature, pr_dir)

                # Analyze with LLM
                result = analyze_feature_vulnerability(
                    feature, files_content, relevant_queries, codeql_results, llm, feature_index, total_features, detailed_hunks
                )
                all_results.append(result)

                # 统计结果
                if result.get("analysis_error"):
                    error_count += 1
                else:
                    success_count += 1
                    if result.get("vulnerability_found", False):
                        vulnerability_count += len(result.get("vulnerabilities", []))

            except Exception as e:
                logger.error(f"[Vulnerability Analyzer] 串行分析功能失败 - {str(e)}")
                feature = task_args[0]
                error_result = {
                    "vulnerability_found": False,
                    "vulnerability_summary": f"串行分析失败: {str(e)}",
                    "vulnerabilities": [],
                    "overall_risk_assessment": "分析失败",
                    "additional_observations": f"串行分析错误: {str(e)}",
                    "feature_id": feature.get("feature_id"),
                    "feature_name": feature.get("feature_name"),
                    "analysis_error": True,
                    "sequential_error": True
                }
                all_results.append(error_result)
                error_count += 1
                safe_print(f"[ERROR] Feature {feature.get('feature_id', 'unknown')} failed: {str(e)}")
    else:
        # Parallel execution
        logger.info(f"[Vulnerability Analyzer] 开始并行分析 ({workers} 工作线程)...")
        safe_print(f"[INFO] Running parallel analysis with {workers} workers...")
        with ThreadPoolExecutor(max_workers=workers) as executor:
            # Submit all tasks
            future_to_index = {
                executor.submit(analyze_feature_parallel, task_args): i
                for i, task_args in enumerate(analysis_tasks)
            }

            logger.info(f"[Vulnerability Analyzer] 已提交 {len(analysis_tasks)} 个并行任务")

            # Collect results as they complete
            completed_count = 0
            for future in as_completed(future_to_index):
                try:
                    result = future.result()
                    all_results.append(result)
                    completed_count += 1
                    logger.debug(f"[Vulnerability Analyzer] 并行任务完成: {completed_count}/{total_features}")
                    safe_print(f"[PROGRESS] Completed {completed_count}/{total_features} features")

                    # 统计结果
                    if result.get("analysis_error"):
                        error_count += 1
                    else:
                        success_count += 1
                        if result.get("vulnerability_found", False):
                            vulnerability_count += len(result.get("vulnerabilities", []))

                except Exception as e:
                    logger.error(f"[Vulnerability Analyzer] 并行任务执行失败 - {str(e)}")
                    # Handle failed future
                    original_index = future_to_index[future]
                    feature = analysis_tasks[original_index][0]
                    error_result = {
                        "vulnerability_found": False,
                        "vulnerability_summary": f"并行执行失败: {str(e)}",
                        "vulnerabilities": [],
                        "overall_risk_assessment": "分析失败",
                        "additional_observations": f"并行执行错误: {str(e)}",
                        "feature_id": feature.get("feature_id"),
                        "feature_name": feature.get("feature_name"),
                        "analysis_error": True,
                        "parallel_error": True
                    }
                    all_results.append(error_result)
                    error_count += 1
                    safe_print(f"[ERROR] Feature {original_index} failed: {str(e)}")

        # Sort results by original feature order
        logger.debug(f"[Vulnerability Analyzer] 按原始功能顺序排序结果...")
        all_results.sort(key=lambda x: features.index(next(f for f in features if f.get("feature_id") == x.get("feature_id"))))

    # Generate final report
    logger.info(f"[Vulnerability Analyzer] 生成最终报告...")

    features_with_vulnerabilities = sum(1 for r in all_results if r.get("vulnerability_found", False))
    total_vulnerabilities_found = sum(len(r.get("vulnerabilities", [])) for r in all_results)

    final_report = {
        "analysis_summary": {
            "total_features_analyzed": total_features,
            "features_with_vulnerabilities": features_with_vulnerabilities,
            "total_vulnerabilities_found": total_vulnerabilities_found,
            "analysis_timestamp": "2025-12-21",
            "parallel_execution": workers > 1,
            "workers_used": workers
        },
        "pr_identification": query_plan.get("pr_identification", {}),
        "feature_analyses": all_results
    }

    # 最终统计日志
    logger.info(f"[Vulnerability Analyzer] 漏洞分析完成统计:")
    logger.info(f"[Vulnerability Analyzer]   总功能数: {total_features}")
    logger.info(f"[Vulnerability Analyzer]   分析成功: {success_count}")
    logger.info(f"[Vulnerability Analyzer]   分析失败: {error_count}")
    logger.info(f"[Vulnerability Analyzer]   有漏洞功能: {features_with_vulnerabilities}")
    logger.info(f"[Vulnerability Analyzer]   发现漏洞总数: {total_vulnerabilities_found}")

    # 漏洞严重程度统计
    if total_vulnerabilities_found > 0:
        severity_counts = {"critical": 0, "high": 0, "medium": 0, "low": 0, "info": 0}
        type_counts = {}

        for result in all_results:
            for vuln in result.get("vulnerabilities", []):
                severity = vuln.get("severity", "unknown")
                vuln_type = vuln.get("type", "unknown")

                if severity in severity_counts:
                    severity_counts[severity] += 1
                type_counts[vuln_type] = type_counts.get(vuln_type, 0) + 1

        logger.info(f"[Vulnerability Analyzer] 漏洞严重程度分布: {severity_counts}")
        if type_counts:
            logger.info(f"[Vulnerability Analyzer] 漏洞类型分布: {dict(list(type_counts.items())[:10])}")  # 最多显示10种类型

    return final_report