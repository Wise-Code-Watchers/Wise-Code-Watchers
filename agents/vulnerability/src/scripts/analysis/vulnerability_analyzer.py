"""
æ¼æ´åˆ†ææ¨¡å— - å¯¹åº”6.pyåŠŸèƒ½
åŸºäºAIå’Œé™æ€åˆ†æç»“æœè¿›è¡Œæ¼æ´åˆ†æï¼Œä½¿ç”¨LLMç”Ÿæˆæœ€ç»ˆæŠ¥å‘Šï¼ˆå·²ç§»é™¤CodeQLä¾èµ–ï¼‰
æ³¨æ„ï¼šè™½ç„¶å‡½æ•°åä¸­ä»åŒ…å«"codeql"ï¼Œä½†å®é™…è°ƒç”¨æ—¶ä¼ å…¥ç©ºçš„codeql_resultså­—å…¸å³å¯æ­£å¸¸å·¥ä½œ
"""

import json
import logging
import os
import threading
import traceback
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import Any, Dict, List, Tuple, Optional

from langchain_core.messages import SystemMessage, HumanMessage
from langchain_openai import ChatOpenAI

# é…ç½®æ—¥å¿—
logger = logging.getLogger(__name__)

# Thread-safe printing (ä¿ç•™ç”¨äºå…¼å®¹æ€§)
print_lock = threading.Lock()

def safe_print(*args, **kwargs):
    """Thread-safe print function."""
    with print_lock:
        print(*args, **kwargs)


def read_json(path: str) -> Dict[str, Any]:
    """Read JSON file safely."""
    with open(path, "r", encoding="utf-8") as f:
        return json.load(f)


def write_json(path: str, obj: Any) -> None:
    """Write JSON file safely."""
    os.makedirs(os.path.dirname(path) or ".", exist_ok=True)
    with open(path, "w", encoding="utf-8") as f:
        json.dump(obj, f, ensure_ascii=False, indent=2)


def read_file_content(path: str) -> str:
    """Read file content if exists, return empty string if not."""
    try:
        with open(path, "r", encoding="utf-8") as f:
            return f.read()
    except FileNotFoundError:
        return f"FILE_NOT_FOUND: {path}"
    except Exception as e:
        return f"ERROR_READING_FILE {path}: {str(e)}"


def load_codeql_results(results_dir: str) -> Dict[str, Any]:
    """Load CodeQL query results from results directory."""
    results = {}
    if not os.path.exists(results_dir):
        return results

    manifest_path = os.path.join(results_dir, "results_manifest.json")
    if not os.path.exists(manifest_path):
        return results

    manifest = read_json(manifest_path)

    for result_item in manifest:
        template_id = result_item.get("template_id")
        json_path = result_item.get("json")

        if json_path and os.path.exists(json_path):
            result_data = read_json(json_path)
            results[template_id] = {
                "result_data": result_data,
                "metadata": result_item
            }

    return results


def get_feature_hunks_with_lines(feature: Dict[str, Any], diff_ir: Dict[str, Any]) -> List[Dict[str, Any]]:
    """
    Get detailed hunks information with line numbers for a feature.
    """
    feature_hunks = feature.get("hunks", [])
    detailed_hunks = []

    for feature_hunk in feature_hunks:
        hunk_id = feature_hunk.get("hunk_id")
        file_path = feature_hunk.get("file_path")

        if not hunk_id or not file_path:
            continue

        # Find corresponding hunk in diff_ir
        try:
            file_idx, hunk_idx = map(int, hunk_id.split(":"))
            diff_files = diff_ir.get("files", [])
            if file_idx < len(diff_files):
                diff_file = diff_files[file_idx]
                diff_hunks = diff_file.get("hunks", [])
                if hunk_idx < len(diff_hunks):
                    diff_hunk = diff_hunks[hunk_idx]
                    detailed_hunks.append({
                        "hunk_id": hunk_id,
                        "file_path": file_path,
                        "old_start": diff_hunk.get("old_start"),
                        "old_count": diff_hunk.get("old_count"),
                        "new_start": diff_hunk.get("new_start"),
                        "new_count": diff_hunk.get("new_count"),
                        "header": diff_hunk.get("header"),
                        "lines": diff_hunk.get("lines", []),
                        "functional_change": feature_hunk.get("functional_change"),
                        "risk_score": feature_hunk.get("risk_score"),
                        "severity": feature_hunk.get("severity")
                    })
        except (ValueError, IndexError):
            continue

    return detailed_hunks


def extract_diff_files_for_feature(feature: Dict[str, Any], pr_dir: str) -> Dict[str, Tuple[str, str]]:
    """
    Extract before and after file content for a feature.
    Returns: {file_path: (before_content, after_content)}
    """
    files_processed = {}

    # Find all hunks for this feature
    hunks = feature.get("hunks", [])
    for hunk in hunks:
        file_path = hunk.get("file_path")
        if not file_path:
            continue

        if file_path in files_processed:
            continue  # Already processed this file

        # Try to find the file in the repo snapshots
        # Assuming we have both before and after snapshots in the PR directory
        before_path = os.path.join(pr_dir, "repo_before", file_path)
        after_path = os.path.join(pr_dir, "repo_after", file_path)

        # Fallback: try to find in parent directories
        if not os.path.exists(before_path):
            before_path = os.path.join(pr_dir, "..", "repo_before", file_path)
        if not os.path.exists(after_path):
            after_path = os.path.join(pr_dir, "..", "repo_after", file_path)

        before_content = read_file_content(before_path)
        after_content = read_file_content(after_path)

        files_processed[file_path] = (before_content, after_content)

    return files_processed


def map_queries_to_feature(feature: Dict[str, Any], query_plan: Dict[str, Any]) -> List[Dict[str, Any]]:
    """
    Map CodeQL queries to a specific feature based on relevance.
    """
    feature_hunks = feature.get("hunks", [])
    feature_files = {hunk.get("file_path") for hunk in feature_hunks if hunk.get("file_path")}

    relevant_queries = []
    all_queries = query_plan.get("queries", [])

    for query in all_queries:
        query_params = query.get("params", {})
        query_file = query_params.get("module_path", query_params.get("file_path", ""))

        # Convert module_path to file_path if needed
        if query_file and "." in query_file:
            query_file = query_file.replace(".", "/") + ".py"

        # Check if query relates to files in this feature
        if any(feature_file in query_file or query_file in feature_file
               for feature_file in feature_files if feature_file):
            relevant_queries.append(query)
        elif query.get("template_id") in ["PY_REFERENCES_OF_SYMBOL", "PY_CALLERS_OF_FUNCTION"]:
            # Symbol-based queries might be relevant
            relevant_queries.append(query)

    return relevant_queries


def format_file_with_diff_highlight(
    file_content: str,
    diff_lines: List[Dict[str, Any]],
    new_start: int,
    new_count: int
) -> str:
    """
    Format file content with diff highlighting.
    """
    if not file_content or not diff_lines:
        return file_content

    lines = file_content.split('\n')
    highlighted_lines = []

    # Create a set of modified line numbers
    modified_lines = set()
    for diff_line in diff_lines:
        line_type = diff_line.get("type")
        new_lineno = diff_line.get("new_lineno")
        if line_type in ["add", "del"] and new_lineno is not None:
            modified_lines.add(new_lineno)

    # Highlight modified lines
    for i, line in enumerate(lines, 1):
        if i in modified_lines:
            highlighted_lines.append(f"[MODIFIED] {line}")
        else:
            highlighted_lines.append(line)

    return '\n'.join(highlighted_lines)


def build_vulnerability_analysis_prompt(
    feature: Dict[str, Any],
    files_content: Dict[str, Tuple[str, str]],
    relevant_queries: List[Dict[str, Any]],
    codeql_results: Dict[str, Any],
    detailed_hunks: List[Dict[str, Any]]
) -> str:
    """Build comprehensive LLM prompt for vulnerability analysis."""

    feature_name = feature.get("feature_name", "")
    feature_summary = feature.get("summary", "")
    business_impact = feature.get("business_impact", "")
    risk_overview = feature.get("risk_overview", {})
    key_risks = risk_overview.get("key_risks", [])

    # Build files section with diff details
    files_section = []

    # Group hunks by file_path
    hunks_by_file = {}
    for hunk in detailed_hunks:
        file_path = hunk.get("file_path")
        if file_path not in hunks_by_file:
            hunks_by_file[file_path] = []
        hunks_by_file[file_path].append(hunk)

    for file_path, (before, after) in files_content.items():
        files_section.append(f"## File: {file_path}")

        # Add diff information for this file
        if file_path in hunks_by_file:
            file_hunks = hunks_by_file[file_path]
            files_section.append("### å…·ä½“ä¿®æ”¹ä¿¡æ¯:")
            for hunk in file_hunks:
                hunk_id = hunk.get("hunk_id")
                old_start = hunk.get("old_start")
                old_count = hunk.get("old_count")
                new_start = hunk.get("new_start")
                new_count = hunk.get("new_count")
                functional_change = hunk.get("functional_change", "")
                risk_score = hunk.get("risk_score", 0)
                severity = hunk.get("severity", "")

                files_section.append(f"**Hunk {hunk_id}:**")
                files_section.append(f"- ä¿®æ”¹èŒƒå›´: {old_start}-{old_start + old_count - 1} â†’ {new_start}-{new_start + new_count - 1}")
                files_section.append(f"- åŠŸèƒ½å˜æ›´: {functional_change}")
                files_section.append(f"- é£é™©è¯„åˆ†: {risk_score} ({severity})")

                # Add actual diff lines WITH line numbers (è¡Œå·åŒ– diff)
                diff_lines = hunk.get("lines", [])
                if diff_lines:
                    files_section.append("- å…·ä½“ä¿®æ”¹å†…å®¹ (å¸¦è¡Œå·):")
                    for diff_line in diff_lines[:20]:  # Limit to first 20 lines
                        line_type = diff_line.get("type")
                        content = diff_line.get("content", "")
                        old_lineno = diff_line.get("old_lineno")
                        new_lineno = diff_line.get("new_lineno")

                        prefix = ""
                        line_info = ""
                        if line_type == "add":
                            prefix = "+"
                            # ğŸ”§ å¯¹äºæ·»åŠ çš„è¡Œï¼Œå¼ºåˆ¶æ˜¾ç¤º NEW è¡Œå·ï¼ˆè¿™æ˜¯å…³é”®ï¼ï¼‰
                            if new_lineno is not None:
                                line_info = f"[Line {new_lineno}]"
                        elif line_type == "del":
                            prefix = "-"
                            if old_lineno is not None:
                                line_info = f"[Line {old_lineno}]"
                        else:
                            prefix = " "
                            if new_lineno is not None:
                                line_info = f"[Line {new_lineno}]"

                        files_section.append(f"  {prefix} {line_info:12} {content}")

                    if len(diff_lines) > 20:
                        files_section.append(f"  ... (è¿˜æœ‰ {len(diff_lines) - 20} è¡Œä¿®æ”¹)")

                files_section.append("")

        # Add file content with highlighting
        if file_path in hunks_by_file:
            # Find the relevant hunk for highlighting
            file_hunks = hunks_by_file[file_path]
            if file_hunks:
                hunk = file_hunks[0]  # Use first hunk for highlighting
                highlighted_after = format_file_with_diff_highlight(
                    after, hunk.get("lines", []),
                    hunk.get("new_start", 1), hunk.get("new_count", 0)
                )
                files_section.append("### AFTER (ä¿®æ”¹åï¼Œå¸¦ä¿®æ”¹æ ‡è®°):")
                files_section.append(f"```\n{highlighted_after[:3000]}...\n```" if len(highlighted_after) > 3000 else f"```\n{highlighted_after}\n```")
        else:
            files_section.append("### AFTER (ä¿®æ”¹å):")
            files_section.append(f"```\n{after[:2000]}...\n```" if len(after) > 2000 else f"```\n{after}\n```")

        files_section.append("")

    # Build CodeQL results section
    codeql_section = []
    for query in relevant_queries:
        template_id = query.get("template_id")
        if template_id in codeql_results:
            result = codeql_results[template_id]
            codeql_section.append(f"### CodeQL Query: {template_id}")
            codeql_section.append(f"**Why:** {query.get('why', '')}")
            codeql_section.append(f"**Params:** {json.dumps(query.get('params', {}), ensure_ascii=False)}")

            # Include CodeQL results (limit size)
            result_data = result.get("result_data", [])
            if isinstance(result_data, list) and len(result_data) > 10:
                codeql_section.append(f"**Results (showing first 10 of {len(result_data)}):**")
                codeql_section.append(json.dumps(result_data[:10], ensure_ascii=False, indent=2))
            else:
                codeql_section.append(f"**Results:**")
                codeql_section.append(json.dumps(result_data, ensure_ascii=False, indent=2))
            codeql_section.append("")

    prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä»£ç å®‰å…¨å®¡æŸ¥ä¸“å®¶ã€‚è¯·åˆ†æä»¥ä¸‹PRåŠŸèƒ½å˜æ›´æ˜¯å¦å­˜åœ¨å®‰å…¨æ¼æ´ã€‚

## åŠŸèƒ½åˆ†æç›®æ ‡
- **åŠŸèƒ½åç§°**: {feature_name}
- **åŠŸèƒ½æ‘˜è¦**: {feature_summary}
- **ä¸šåŠ¡å½±å“**: {business_impact}
- **å·²çŸ¥é£é™©**: {', '.join(key_risks)}

## ä»£ç å˜æ›´è¯¦æƒ…

{chr(10).join(files_section)}

## CodeQLæŸ¥è¯¢ç»“æœ

{chr(10).join(codeql_section) if codeql_section else "æ— ç›¸å…³CodeQLæŸ¥è¯¢ç»“æœ"}

## åˆ†æè¦æ±‚

è¯·ä»”ç»†åˆ†æä¸Šè¿°ä»£ç å˜æ›´å’ŒCodeQLæŸ¥è¯¢ç»“æœï¼Œè¯†åˆ«æ˜¯å¦å­˜åœ¨ä»¥ä¸‹ç±»å‹çš„å®‰å…¨é—®é¢˜ï¼š
1. **å¹¶å‘å®‰å…¨é—®é¢˜** - æ•°æ®ç«äº‰ã€æ­»é”ã€æ¡ä»¶ç«äº‰ç­‰
2. **é€»è¾‘é”™è¯¯** - è¾¹ç•Œæ¡ä»¶ã€é”™è¯¯å¤„ç†ã€çŠ¶æ€ç®¡ç†ç­‰
3. **æ³¨å…¥æ¼æ´** - SQLæ³¨å…¥ã€å‘½ä»¤æ³¨å…¥ã€è·¯å¾„éå†ç­‰
4. **æƒé™æ§åˆ¶** - è®¿é—®æ§åˆ¶ã€æˆæƒç»•è¿‡ç­‰
5. **æ•°æ®å®Œæ•´æ€§** - æ•°æ®æ³„éœ²ã€æ•°æ®ç¯¡æ”¹ç­‰
6. **èµ„æºç®¡ç†** - å†…å­˜æ³„æ¼ã€èµ„æºè€—å°½ç­‰

## é‡è¦ï¼šè¡Œå·å®šä½è¯´æ˜

ä¸Šé¢æä¾›äº†å…·ä½“çš„diffä¿¡æ¯ï¼ŒåŒ…å«ï¼š
- **é€è¡Œä¿®æ”¹è¯¦æƒ…ï¼Œæ¯è¡Œéƒ½æ ‡è®°äº†ç²¾ç¡®è¡Œå·** (æ ¼å¼ï¼š`[Line XXX]`)
- æ·»åŠ çš„è¡Œæ˜¾ç¤ºä¸º `+ [Line 123] ä»£ç å†…å®¹`
- åˆ é™¤çš„è¡Œæ˜¾ç¤ºä¸º `- [Line 45] ä»£ç å†…å®¹`
- æœªä¿®æ”¹çš„è¡Œæ˜¾ç¤ºä¸º `  [Line 78] ä»£ç å†…å®¹`

## è¾“å‡ºæ ¼å¼è¦æ±‚

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºåˆ†æç»“æœï¼š

{{
  "vulnerability_found": true/false,
  "vulnerability_summary": "ç®€è¦æ€»ç»“å‘ç°çš„ä¸»è¦é—®é¢˜",
  "vulnerabilities": [
    {{
      "type": "é—®é¢˜ç±»å‹",
      "severity": "critical/high/medium/low/info",
      "confidence": "high/medium/low",
      "file_path": "æ–‡ä»¶è·¯å¾„",
      "line": å•ä¸ªè¡Œå·ï¼ˆå¿…é¡»æ˜¯æ•´æ•°ï¼ŒåŸºäºä¸Šé¢diffä¸­çš„[Line XXX]ï¼‰,
      "description": "è¯¦ç»†é—®é¢˜æè¿°",
      "root_cause": "æ ¹æœ¬åŸå› åˆ†æ",
      "exploit_scenario": "å¯èƒ½çš„åˆ©ç”¨åœºæ™¯",
      "fix_recommendation": "ä¿®å¤å»ºè®®",
      "code_snippet": "é—®é¢˜ä»£ç ç‰‡æ®µ",
      "references_codeql": "ç›¸å…³çš„CodeQLæŸ¥è¯¢ç»“æœ"
    }}
  ],
  "overall_risk_assessment": "æ•´ä½“é£é™©è¯„ä¼°",
  "additional_observations": "å…¶ä»–è§‚å¯Ÿ"
}}

## å…³é”®è¦æ±‚ï¼ˆé‡è¦ï¼‰
- **line å¿…é¡»æ˜¯å•ä¸ªæ•´æ•°è¡Œå·**ï¼Œä¸å¾—ä½¿ç”¨èŒƒå›´æˆ–æ•°ç»„
- **å¿…é¡»ä½¿ç”¨ä¸Šé¢diffä¸­æ˜¾ç¤ºçš„ç²¾ç¡®è¡Œå·**ï¼ˆæ ¼å¼ï¼š[Line XXX]ï¼‰
- å¦‚æœé—®é¢˜è·¨è¶Šå¤šè¡Œï¼Œ**å¿…é¡»é€‰æ‹©æœ€å…³é”®çš„é‚£ä¸€è¡Œ**ä½œä¸º line
- ä¸å¾—ä½¿ç”¨ line_number å­—æ®µï¼Œå¿…é¡»ä½¿ç”¨ line å­—æ®µ
- ä¸å¾—è¿”å› block èŒƒå›´ï¼ˆå¦‚ 45-48 æˆ– [45, 48]ï¼‰
- å¦‚æœæ²¡æœ‰å‘ç°æ¼æ´ï¼Œvulnerabilitiesæ•°ç»„åº”ä¸ºç©º
- code_snippetè¯·åŒ…å«å®é™…çš„é—®é¢˜ä»£ç 
- å¿…é¡»è¾“å‡ºä¸¥æ ¼çš„JSONæ ¼å¼ï¼Œä¸è¦åŒ…å«markdownæ ‡è®°æˆ–é¢å¤–è§£é‡Š
"""

    return prompt


def _check_filter_gate(
    feature: Dict[str, Any],
    feature_index: int,
    total_features: int
) -> Dict[str, Any]:
    """
    ğŸ”§ é˜¶æ®µ1: ç¡¬é—¨æ§ - æ£€æŸ¥åŠŸèƒ½æ˜¯å¦åº”è¢«è·³è¿‡ï¼ˆä¸Šæ¸¸å·²å¤„ç†ï¼‰

    åˆ¤æ–­é€»è¾‘ï¼š
    1. æ£€æŸ¥ feature.filter_status.decision æ˜¯å¦ä¸º BLOCK/SANITIZE
    2. æ£€æŸ¥æ˜¯å¦æœ‰æ˜æ˜¾çš„"å·²å¤„ç†"ç‰¹å¾ï¼ˆå¦‚æµ‹è¯•ä»£ç ã€é…ç½®æ–‡ä»¶ã€æ–‡æ¡£ç­‰ï¼‰
    3. æ£€æŸ¥é£é™©è¯„åˆ†æ˜¯å¦è¿‡ä½ï¼ˆå¯é€‰ï¼‰

    Args:
        feature: åŠŸèƒ½å¯¹è±¡
        feature_index: åŠŸèƒ½ç´¢å¼•
        total_features: æ€»åŠŸèƒ½æ•°

    Returns:
        {
            "should_skip": bool,  # æ˜¯å¦åº”è¯¥è·³è¿‡ LLM åˆ†æ
            "skip_reason": str,   # è·³è¿‡åŸå› 
            "decision": str,      # è¿‡æ»¤å™¨å†³ç­– (BLOCK/SANITIZE/ALLOW/NONE)
            "summary": str,       # ç®€çŸ­æ‘˜è¦
            "details": str        # è¯¦ç»†ä¿¡æ¯
        }
    """
    feature_id = feature.get("feature_id", "unknown")
    feature_name = feature.get("feature_name", "")

    # è§„åˆ™1: æ£€æŸ¥æ˜¾å¼çš„ filter_status
    filter_status = feature.get("filter_status", {})
    decision = filter_status.get("decision", "NONE").upper()

    if decision == "BLOCK":
        return {
            "should_skip": True,
            "skip_reason": "è¯·æ±‚å·²è¢«ä¸Šæ¸¸è¿‡æ»¤å™¨æ‹¦æˆªï¼ˆBLOCKï¼‰",
            "decision": decision,
            "summary": f"åŠŸèƒ½ '{feature_name}' å·²è¢«ä¸Šæ¸¸è¿‡æ»¤å™¨æ‹¦æˆª",
            "details": f"Filter reasons: {', '.join(filter_status.get('reasons', ['Unknown']))}"
        }

    if decision == "SANITIZE":
        return {
            "should_skip": True,
            "skip_reason": "å±é™©å†…å®¹å·²è¢«ä¸Šæ¸¸è¿‡æ»¤å™¨å‡€åŒ–ï¼ˆSANITIZEï¼‰",
            "decision": decision,
            "summary": f"åŠŸèƒ½ '{feature_name}' çš„å±é™©å†…å®¹å·²è¢«ç§»é™¤/æ›¿æ¢",
            "details": f"Sanitization method: {filter_status.get('sanitization_method', 'Unknown')}"
        }

    # è§„åˆ™2: æ£€æŸ¥æ–‡ä»¶ç±»å‹ç‰¹å¾ï¼ˆè¯†åˆ«æ˜æ˜¾çš„éé£é™©ä»£ç ï¼‰
    hunks = feature.get("hunks", [])
    low_risk_patterns = []

    for hunk in hunks:
        file_path = hunk.get("file_path", "")

        # 2.1 æµ‹è¯•æ–‡ä»¶
        if any(pattern in file_path for pattern in ["test_", "_test.py", "tests/", "test/", "conftest.py"]):
            low_risk_patterns.append(f"æµ‹è¯•æ–‡ä»¶: {file_path}")

        # 2.2 é…ç½®æ–‡ä»¶
        elif any(file_path.endswith(ext) for ext in [
            ".yaml", ".yml", ".json", ".toml", ".ini", ".cfg",
            ".md", ".txt", ".rst", ".adoc"
        ]):
            low_risk_patterns.append(f"é…ç½®/æ–‡æ¡£æ–‡ä»¶: {file_path}")

        # 2.3 æ•°æ®åº“è¿ç§»æ–‡ä»¶
        elif any(pattern in file_path for pattern in ["migrations/", "alembic/"]):
            low_risk_patterns.append(f"æ•°æ®åº“è¿ç§»: {file_path}")

    # å¦‚æœæ‰€æœ‰ hunk éƒ½æ˜¯ä½é£é™©æ¨¡å¼ï¼Œåˆ™è·³è¿‡
    if low_risk_patterns and len(low_risk_patterns) == len(hunks):
        return {
            "should_skip": True,
            "skip_reason": "æ‰€æœ‰æ–‡ä»¶éƒ½æ˜¯ä½é£é™©ç±»å‹ï¼ˆæµ‹è¯•/é…ç½®/æ–‡æ¡£ï¼‰",
            "decision": "LOW_RISK_FILETYPE",
            "summary": f"åŠŸèƒ½ '{feature_name}' ä»…åŒ…å«ä½é£é™©æ–‡ä»¶ç±»å‹",
            "details": f"Files: {'; '.join(low_risk_patterns[:5])}"
        }

    # è§„åˆ™3: æ£€æŸ¥é£é™©è¯„åˆ†ï¼ˆè½¯é—¨æ§ - ä¸è·³è¿‡LLMï¼Œåªè®°å½•çŠ¶æ€ï¼‰
    risk_overview = feature.get("risk_overview", {})
    overall_risk_score = risk_overview.get("overall_risk_score", 0)
    severity = risk_overview.get("severity", "unknown").lower()

    # ğŸ”§ æ”¹ä¸ºè½¯æ£€æŸ¥ï¼šè®°å½•æ˜¯å¦ä¸ºä½é£é™©ï¼Œä½†ä¸è·³è¿‡LLMåˆ†æ
    is_low_risk_score = (overall_risk_score == 0 and severity not in ["critical", "high"])

    if is_low_risk_score:
        # è®°å½•ä½é£é™©çŠ¶æ€ï¼Œä½†ä»è¿”å› should_skip=False è®©LLMåˆ†æ
        pass  # ç»§ç»­æ‰§è¡Œï¼Œä¸æå‰è¿”å›

    # è§„åˆ™4: æ£€æŸ¥æ˜¯å¦ä¸ºçº¯æ³¨é‡Š/æ–‡æ¡£å˜æ›´
    # ğŸ”§ å·²ç¦ç”¨ï¼šè®©æ‰€æœ‰å˜æ›´éƒ½ç»è¿‡LLMåˆ†æï¼Œå³ä½¿æ²¡æœ‰æ˜æ˜¾åŠŸèƒ½æ€§å˜æ›´
    # functional_change_keywords = ["æ·»åŠ ", "åˆ é™¤", "ä¿®æ”¹", "æ›´æ–°", "ä¼˜åŒ–", "ä¿®å¤", "é‡æ„", "implement", "add", "remove", "fix"]
    # has_functional_change = False
    #
    # for hunk in hunks:
    #     functional_change = hunk.get("functional_change", "")
    #     if functional_change and any(keyword in functional_change.lower() for keyword in functional_change_keywords):
    #         has_functional_change = True
    #         break
    #
    # if not has_functional_change and hunks:
    #     return {
    #         "should_skip": True,
    #         "skip_reason": "æ— æ˜æ˜¾åŠŸèƒ½æ€§å˜æ›´ï¼ˆå¯èƒ½æ˜¯æ³¨é‡Šæˆ–æ ¼å¼è°ƒæ•´ï¼‰",
    #         "decision": "NO_FUNCTIONAL_CHANGE",
    #         "summary": f"åŠŸèƒ½ '{feature_name}' æœªæ£€æµ‹åˆ°åŠŸèƒ½æ€§å˜æ›´",
    #         "details": f"Hunks count: {len(hunks)}, æ‰€æœ‰ hunk ç¼ºå°‘åŠŸèƒ½æ€§å˜æ›´æè¿°"
    #     }

    # é€šè¿‡æ‰€æœ‰é—¨æ§æ£€æŸ¥ï¼Œéœ€è¦ LLM åˆ†æ
    return {
        "should_skip": False,
        "skip_reason": "",
        "decision": "ALLOW",
        "summary": "",
        "details": "",
        # ğŸ”§ æ·»åŠ é£é™©è¯„åˆ†ä¿¡æ¯ï¼Œä¾›æŠ¥å‘Šé˜¶æ®µä½¿ç”¨
        "risk_score": overall_risk_score,
        "severity": severity,
        "is_low_risk": is_low_risk_score if 'is_low_risk_score' in locals() else False
    }


# =============================================================================
# Nil-Guard è¿‡æ»¤å™¨ - ç§»é™¤ nil/NoMethodError è¯¯æŠ¥
# =============================================================================

def _is_nil_false_positive(vuln: Dict[str, Any]) -> tuple[bool, str]:
    """
    åˆ¤æ–­ä¸€ä¸ªæ¼æ´æ˜¯å¦æ˜¯ nil/NoMethodError è¯¯æŠ¥

    è§„åˆ™ï¼š
    1. ç±»åˆ«ä¸º"ç©ºå€¼å¤„ç†" â†’ ç›´æ¥è¿‡æ»¤
    2. æœ‰æ•°æ®åº“ä¿æŠ¤æœºåˆ¶ï¼ˆFK/NOT NULL/validationsï¼‰â†’ è¿‡æ»¤
    3. å‡è®¾ç¡¬åˆ é™¤/ç ´åæ•°æ®å®Œæ•´æ€§ â†’ è¿‡æ»¤
    4. ç¼ºå°‘å¯è¾¾æ‰§è¡Œè·¯å¾„ â†’ è¿‡æ»¤
    5. é˜²å¾¡æ€§ç¼–ç¨‹å»ºè®® â†’ è¿‡æ»¤
    """
    title = vuln.get("title", "")
    description = vuln.get("description", "")
    trigger = vuln.get("trigger", "")
    category = vuln.get("category", "").lower()

    # ğŸ” è§„åˆ™0: ç›´æ¥è¿‡æ»¤æ‰€æœ‰"ç©ºå€¼å¤„ç†"ç±»åˆ«çš„æ¼æ´
    if "ç©ºå€¼" in category or "null" in category or "nil" in category:
        return True, f"ç±»åˆ«ä¸º'{category}'"

    # è½¬ä¸ºå°å†™
    title_lower = title.lower()
    desc_lower = description.lower()
    trigger_lower = trigger.lower()

    # æ£€æŸ¥æ˜¯å¦æ˜¯ nil ç±»å‹
    nil_keywords = ["nil", "null", "å¯èƒ½ä¸ºç©º", "å¯èƒ½ä¸º nil", "ç©ºå€¼", "ç©ºæŒ‡é’ˆ"]
    is_nil = any(kw in title_lower or kw in desc_lower for kw in nil_keywords)

    if not is_nil:
        return False, ""

    # âœ… è§„åˆ™1: æœ‰ä¿æŠ¤æœºåˆ¶
    protective = ["å¤–é”®", "not null", "belongs_to", "has_many", "validates", "presence"]
    if any(kw in desc_lower or kw in trigger_lower for kw in protective):
        return True, "æœ‰æ•°æ®åº“çº¦æŸ/å…³è”ä¿æŠ¤"

    # âœ… è§„åˆ™2: å‡è®¾ç¡¬åˆ é™¤
    corruption = ["è¢«åˆ é™¤", "ç¡¬åˆ é™¤", "æ‰‹åŠ¨åˆ é™¤", "æ•°æ®åº“è¢«ä¿®æ”¹"]
    if any(kw in desc_lower or kw in trigger_lower for kw in corruption):
        return True, "å‡è®¾ç¡¬åˆ é™¤/ç ´åæ•°æ®å®Œæ•´æ€§"

    # âœ… è§„åˆ™3: ç¼ºå°‘æ‰§è¡Œè·¯å¾„
    has_path = ["controller", "job", "service", "ç”¨æˆ·è¯·æ±‚", "api", "route"]
    if not any(kw in desc_lower or kw in trigger_lower for kw in has_path):
        return True, "ç¼ºå°‘å¯è¾¾æ‰§è¡Œè·¯å¾„"

    # âœ… è§„åˆ™4: é˜²å¾¡æ€§å»ºè®®
    defensive = ["å»ºè®®æ·»åŠ ", "åº”è¯¥æ£€æŸ¥", "é˜²å¾¡æ€§", "å¯ä»¥æ·»åŠ ", "best practice"]
    if any(kw in title_lower or kw in desc_lower for kw in defensive):
        return True, "é˜²å¾¡æ€§ç¼–ç¨‹å»ºè®®"

    return False, ""


def _apply_nil_guard(result: Dict[str, Any]) -> Dict[str, Any]:
    """åº”ç”¨ Nil-Guard è¿‡æ»¤"""
    vulnerabilities = result.get("vulnerabilities", [])
    if not vulnerabilities:
        return result

    # è¿‡æ»¤
    filtered = []
    false_positives = []

    for vuln in vulnerabilities:
        is_fp, reason = _is_nil_false_positive(vuln)
        if is_fp:
            false_positives.append((vuln, reason))
        else:
            filtered.append(vuln)

    if not false_positives:
        return result

    # æ›´æ–°ç»“æœ
    result["vulnerabilities"] = filtered
    result["nil_guard_applied"] = True
    result["nil_guard_stats"] = {
        "original": len(vulnerabilities),
        "filtered": len(filtered),
        "removed": len(false_positives)
    }

    # æ—¥å¿—
    logger.info(f"ğŸ›¡ï¸ Nil-Guard è¿‡æ»¤: {len(vulnerabilities)} â†’ {len(filtered)} (ç§»é™¤ {len(false_positives)} ä¸ªè¯¯æŠ¥)")
    for i, (vuln, reason) in enumerate(false_positives[:5]):
        logger.info(f"  {i+1}. {vuln.get('title', 'Unknown')} - {reason}")

    if filtered == []:
        result["vulnerability_found"] = False
        result["vulnerability_summary"] = f"å‘ç°{len(vulnerabilities)}ä¸ªé—®é¢˜ä½†å‡è¢«Nil-Guardè¿‡æ»¤ä¸ºè¯¯æŠ¥"

    return result


def analyze_feature_vulnerability(
    feature: Dict[str, Any],
    files_content: Dict[str, Tuple[str, str]],
    relevant_queries: List[Dict[str, Any]],
    codeql_results: Dict[str, Any],
    llm: ChatOpenAI,
    feature_index: int,
    total_features: int,
    detailed_hunks: List[Dict[str, Any]],
    num_llm_votes: int = 3  # ğŸ”§ æ–°å¢ï¼šLLMæŠ•ç¥¨æ•°é‡
) -> Dict[str, Any]:
    """Analyze a single feature for vulnerabilities using multiple LLM votes."""

    feature_id = feature.get("feature_id", "unknown")
    feature_name = feature.get("feature_name", "unknown")
    initial_risk_score = feature.get("risk_overview", {}).get("overall_risk_score", 0)

    logger.info(f"[Vulnerability Analyzer] [{feature_index}/{total_features}] å¼€å§‹åˆ†æåŠŸèƒ½: {feature_id} - {feature_name}")
    logger.info(f"[Vulnerability Analyzer] {feature_id}: åˆå§‹é£é™©è¯„åˆ†: {initial_risk_score}, æ¶‰åŠæ–‡ä»¶: {len(files_content)} ä¸ª")
    logger.info(f"[Vulnerability Analyzer] {feature_id}: ğŸ”§ ä½¿ç”¨ {num_llm_votes} ä¸ªLLMå¹¶è¡ŒæŠ•ç¥¨åˆ†æ")
    logger.debug(f"[Vulnerability Analyzer] {feature_id}: ç›¸å…³æŸ¥è¯¢: {len(relevant_queries)} ä¸ª, CodeQLç»“æœ: {len(codeql_results)} ä¸ª")

    # ğŸ”§ é˜¶æ®µ1: ç¡¬é—¨æ§ - æ£€æŸ¥ä¸Šæ¸¸è¿‡æ»¤çŠ¶æ€
    filter_gate_result = _check_filter_gate(feature, feature_index, total_features)
    if filter_gate_result["should_skip"]:
        logger.info(
            f"[Vulnerability Analyzer] ğŸ”’ ç¡¬é—¨æ§æ‹¦æˆª: {feature_id} - "
            f"åŸå› : {filter_gate_result['skip_reason']}"
        )
        safe_print(f"[{feature_index}/{total_features}] â›” SKIPPED (Filtered): {feature_id} - {filter_gate_result['skip_reason']}")

        # è¿”å›"å·²è¢«å¤„ç†"çš„ç»“æœï¼Œä¸è®¡å…¥æ¼æ´å‘Šè­¦
        return {
            "feature_id": feature_id,
            "feature_name": feature_name,
            "vulnerability_found": False,  # ç¡¬æ‹¦æˆªä¸ç®—æ¼æ´
            "vulnerability_summary": filter_gate_result.get("summary", "åŠŸèƒ½å·²è¢«ä¸Šæ¸¸è¿‡æ»¤å™¨å¤„ç†"),
            "vulnerabilities": [],
            "overall_risk_assessment": "no_risk",
            "additional_observations": filter_gate_result.get("details", ""),
            "filter_handled": True,  # æ ‡è®°ä¸ºå·²å¤„ç†
            "filter_gate": {
                "decision": filter_gate_result.get("decision", "UNKNOWN"),
                "reason": filter_gate_result.get("skip_reason", ""),
                "category": "hard_gate_skip"
            },
            "analysis_timestamp": "2025-12-30",
            "analysis_skipped": True
        }

    # è®°å½•è¯¦ç»†çš„åˆ†æè¾“å…¥ä¿¡æ¯
    if os.getenv("ENABLE_DETAILED_LOGS", "false").lower() == "true":
        logger.debug(f"[Vulnerability Analyzer] {feature_id}: åŠŸèƒ½è¯¦æƒ…:")
        logger.debug(f"[Vulnerability Analyzer] {feature_id}:   - æ‘˜è¦: {feature.get('summary', 'N/A')}")
        logger.debug(f"[Vulnerability Analyzer] {feature_id}:   - ä¸šåŠ¡å½±å“: {feature.get('business_impact', 'N/A')}")
        logger.debug(f"[Vulnerability Analyzer] {feature_id}:   - è¯¦ç»†hunks: {len(detailed_hunks)} ä¸ª")
        logger.debug(f"[Vulnerability Analyzer] {feature_id}:   - æ–‡ä»¶åˆ—è¡¨: {list(files_content.keys())}")

        if relevant_queries:
            for i, query in enumerate(relevant_queries[:3]):  # åªè®°å½•å‰3ä¸ªæŸ¥è¯¢
                logger.debug(f"[Vulnerability Analyzer] {feature_id}: æŸ¥è¯¢{i+1}: {query.get('template_id', 'unknown')} - {query.get('why', 'N/A')[:100]}")

    safe_print(f"[{feature_index}/{total_features}] Starting analysis: {feature_id} - {feature_name} (with {num_llm_votes} LLM votes)")

    try:
        logger.debug(f"[Vulnerability Analyzer] {feature_id}: æ„å»ºåˆ†æprompt...")
        prompt = build_vulnerability_analysis_prompt(feature, files_content, relevant_queries, codeql_results, detailed_hunks)

        # è®°å½•promptå¤§å°ä¿¡æ¯
        if os.getenv("ENABLE_DETAILED_LOGS", "false").lower() == "true":
            logger.debug(f"[Vulnerability Analyzer] {feature_id}: prompté•¿åº¦: {len(prompt)} å­—ç¬¦")
            prompt_preview = prompt[:1500] + "..." if len(prompt) > 1500 else prompt
            logger.debug(f"[Vulnerability Analyzer] {feature_id}: promptå†…å®¹é¢„è§ˆ:\n{prompt_preview}")

        # ğŸ”§ æ–°å¢ï¼šLLMæŠ•ç¥¨æœºåˆ¶ - å¤šä¸ªLLMå¹¶è¡Œåˆ†æåŒä¸€ä¸ªåŠŸèƒ½
        llm_votes = []
        llm_risk_scores = []

        for vote_idx in range(num_llm_votes):
            logger.debug(f"[Vulnerability Analyzer] {feature_id}: LLMæŠ•ç¥¨ {vote_idx + 1}/{num_llm_votes}...")

            messages = [
                SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä»£ç å®‰å…¨å®¡æŸ¥ä¸“å®¶ï¼Œä¸“æ³¨äºå‘ç°ä»£ç å˜æ›´ä¸­çš„å®‰å…¨æ¼æ´ã€‚"),
                HumanMessage(content=prompt)
            ]

            # Retry logic for LLM calls with null response handling
            max_retries = 3
            response_text = None
            for attempt in range(max_retries):
                try:
                    response = llm.invoke(messages)
                    response_text = response.content if hasattr(response, "content") else str(response)
                    if response_text:
                        break
                except TypeError as e:
                    if "null value for `choices`" in str(e):
                        import time
                        logger.warning(f"[Vulnerability Analyzer] {feature_id}: LLMè¿”å›null choicesï¼Œé‡è¯• {attempt + 1}/{max_retries}")
                        time.sleep(1)
                        continue
                    raise
                except Exception as e:
                    logger.warning(f"[Vulnerability Analyzer] {feature_id}: LLMè°ƒç”¨å¤±è´¥ï¼Œé‡è¯• {attempt + 1}/{max_retries}: {str(e)}")
                    import time
                    time.sleep(1)
                    continue

            if not response_text:
                # Fallback when LLM is unavailable
                logger.warning(f"[Vulnerability Analyzer] {feature_id}: LLMæŠ•ç¥¨ {vote_idx + 1} å¤±è´¥")
                llm_votes.append({
                    "success": False,
                    "error": "LLM unavailable",
                    "vote_index": vote_idx
                })
                continue

            # Try to parse JSON response
            try:
                # Clean up response if it contains markdown
                json_start = response_text.find("{")
                json_end = response_text.rfind("}") + 1
                if json_start != -1 and json_end > json_start:
                    json_text = response_text[json_start:json_end]
                    vote_result = json.loads(json_text)
                else:
                    vote_result = json.loads(response_text)

                # ğŸ”§ ä»LLMå“åº”ä¸­æå–é£é™©è¯„åˆ†ï¼ˆåŸºäºæ¼æ´æ•°é‡å’Œä¸¥é‡ç¨‹åº¦ï¼‰
                vulns = vote_result.get("vulnerabilities", [])
                risk_score = 0

                if vulns:
                    for vuln in vulns:
                        severity = vuln.get("severity", "low").lower()
                        confidence = vuln.get("confidence", "low").lower()

                        # ä¸¥é‡ç¨‹åº¦æƒé‡
                        severity_weights = {
                            "critical": 90,
                            "high": 70,
                            "medium": 50,
                            "low": 30,
                            "info": 10
                        }

                        # ç½®ä¿¡åº¦æƒé‡
                        confidence_weights = {
                            "high": 1.0,
                            "medium": 0.7,
                            "low": 0.4
                        }

                        base_score = severity_weights.get(severity, 20)
                        confidence_factor = confidence_weights.get(confidence, 0.5)
                        vuln_score = base_score * confidence_factor

                        risk_score += vuln_score

                # é™åˆ¶åœ¨0-100èŒƒå›´
                risk_score = min(100, max(0, int(risk_score)))

                llm_votes.append({
                    "success": True,
                    "vote_index": vote_idx,
                    "result": vote_result,
                    "risk_score": risk_score,
                    "vulnerability_found": vote_result.get("vulnerability_found", False),
                    "vulnerabilities_count": len(vulns)
                })

                llm_risk_scores.append(risk_score)

                # ğŸ”§ è¯¦ç»†è®°å½•æ¯ä¸ªLLMçš„è¯„åˆ†å’Œæ¼æ´è¯¦æƒ…
                logger.info(f"[Vulnerability Analyzer] {feature_id}: LLMæŠ•ç¥¨ {vote_idx + 1}/{num_llm_votes} å®Œæˆ:")
                logger.info(f"[Vulnerability Analyzer] {feature_id}:   - é£é™©è¯„åˆ†: {risk_score}/100")
                logger.info(f"[Vulnerability Analyzer] {feature_id}:   - å‘ç°æ¼æ´: {len(vulns)} ä¸ª")
                if vulns:
                    for v_idx, vuln in enumerate(vulns[:3]):  # æœ€å¤šæ˜¾ç¤º3ä¸ª
                        logger.info(f"[Vulnerability Analyzer] {feature_id}:     {v_idx+1}. {vuln.get('type', 'unknown')} ({vuln.get('severity', 'unknown')}, {vuln.get('confidence', 'unknown')})")

            except json.JSONDecodeError as e:
                logger.warning(f"[Vulnerability Analyzer] {feature_id}: LLMæŠ•ç¥¨ {vote_idx + 1} JSONè§£æå¤±è´¥ - {str(e)}")
                llm_votes.append({
                    "success": False,
                    "error": f"JSON parse error: {str(e)}",
                    "vote_index": vote_idx,
                    "raw_response": response_text[:500]
                })

        # ğŸ”§ è®¡ç®—LLMæŠ•ç¥¨çš„å…±è¯†ç»“æœ
        successful_votes = [v for v in llm_votes if v.get("success", False)]
        failed_votes = num_llm_votes - len(successful_votes)

        if failed_votes == num_llm_votes:
            # æ‰€æœ‰LLMæŠ•ç¥¨éƒ½å¤±è´¥
            logger.error(f"[Vulnerability Analyzer] {feature_id}: æ‰€æœ‰ {num_llm_votes} ä¸ªLLMæŠ•ç¥¨éƒ½å¤±è´¥")
            return {
                "feature_id": feature.get("feature_id"),
                "feature_name": feature.get("feature_name"),
                "vulnerability_found": False,
                "vulnerability_summary": f"æ‰€æœ‰{num_llm_votes}ä¸ªLLMæŠ•ç¥¨éƒ½å¤±è´¥",
                "vulnerabilities": [],
                "overall_risk_assessment": "analysis_failed",
                "additional_observations": f"å¤±è´¥åŸå› : {'; '.join([v.get('error', 'unknown') for v in llm_votes[:3]])}",
                "llm_fallback": True,
                "llm_votes": llm_votes,
                "analysis_timestamp": "2025-12-30"
            }

        # è®¡ç®—å¹³å‡é£é™©è¯„åˆ†
        if llm_risk_scores:
            avg_risk_score = sum(llm_risk_scores) / len(llm_risk_scores)
        else:
            avg_risk_score = 0

        # ğŸ”§ åŸºäºå¹³å‡åˆ†å†³å®šæ˜¯å¦æŠ¥å‘Š
        # è§„åˆ™ï¼š
        # - å¹³å‡åˆ† >= 40: æŠ¥å‘Šæ‰€æœ‰å‘ç°çš„æ¼æ´
        # - 20 <= å¹³å‡åˆ† < 40: åªæŠ¥å‘Š high/critical çº§åˆ«çš„æ¼æ´
        # - å¹³å‡åˆ† < 20: ä¸æŠ¥å‘Šæ¼æ´ï¼ˆè®¤ä¸ºå®‰å…¨ï¼‰
        should_report = False
        report_threshold = os.getenv("LLM_REPORT_THRESHOLD", "40").lower()

        if report_threshold == "conservative":
            # ä¿å®ˆç­–ç•¥ï¼šå¹³å‡åˆ† >= 30 æ‰æŠ¥å‘Š
            should_report = avg_risk_score >= 30
        elif report_threshold == "aggressive":
            # æ¿€è¿›ç­–ç•¥ï¼šå¹³å‡åˆ† >= 20 å°±æŠ¥å‘Š
            should_report = avg_risk_score >= 20
        else:
            # é»˜è®¤ç­–ç•¥ï¼šå¹³å‡åˆ† >= 40 æ‰æŠ¥å‘Š
            should_report = avg_risk_score >= 40

        logger.info(f"[Vulnerability Analyzer] {feature_id}: LLMæŠ•ç¥¨å®Œæˆ - å¹³å‡é£é™©è¯„åˆ†: {avg_risk_score:.1f}/{100}")
        logger.info(f"[Vulnerability Analyzer] {feature_id}:   - å„LLMè¯„åˆ†: {llm_risk_scores}")
        logger.info(f"[Vulnerability Analyzer] {feature_id}:   - æŠ¥å‘Šé˜ˆå€¼: {report_threshold}, æ˜¯å¦æŠ¥å‘Š: {should_report}")

        # ğŸ”§ æ”¹è¿›ï¼šé€‰æ‹©é£é™©è¯„åˆ†æœ€é«˜çš„é‚£æ¬¡LLMæŠ•ç¥¨ç»“æœï¼Œè€Œä¸æ˜¯åˆå¹¶æ‰€æœ‰ç»“æœ
        # è¿™æ ·å¯ä»¥é¿å…é‡å¤æŠ¥å‘ŠåŒä¸€ä¸ªæ¼æ´
        best_vote = None
        best_vote_score = -1

        for vote in successful_votes:
            # ğŸ”§ åªè€ƒè™‘çœŸæ­£å‘ç°äº†æ¼æ´çš„æŠ•ç¥¨ï¼ˆvulnerability_found=True ä¸”æœ‰å®é™…æ¼æ´åˆ—è¡¨ï¼‰
            if not vote.get("vulnerability_found", False):
                continue

            vulns = vote.get("result", {}).get("vulnerabilities", [])
            if not vulns:
                continue

            vote_score = vote.get("risk_score", 0)
            if vote_score > best_vote_score:
                best_vote_score = vote_score
                best_vote = vote

        # ğŸ”§ å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä»»ä½•å‘ç°æ¼æ´çš„æŠ•ç¥¨ï¼Œç›´æ¥è¿”å›ç©ºç»“æœ
        if not best_vote:
            logger.info(f"[Vulnerability Analyzer] {feature_id}: æ‰€æœ‰{len(successful_votes)}ä¸ªæˆåŠŸçš„LLMæŠ•ç¥¨å‡æœªå‘ç°æ¼æ´")
            return {
                "feature_id": feature.get("feature_id"),
                "feature_name": feature.get("feature_name"),
                "vulnerability_found": False,
                "vulnerability_summary": f"åŸºäº{len(successful_votes)}ä¸ªLLMæŠ•ç¥¨çš„å…±è¯†åˆ†æ - æœªå‘ç°æ¼æ´",
                "vulnerabilities": [],
                "overall_risk_assessment": f"å¹³å‡é£é™©è¯„åˆ†: {avg_risk_score:.1f}/100 (ä½äºæŠ¥å‘Šé˜ˆå€¼)",
                "additional_observations": f"LLMæŠ•ç¥¨æ•°: {num_llm_votes}, æˆåŠŸ: {len(successful_votes)}, å¤±è´¥: {failed_votes}. å„LLMè¯„åˆ†: {llm_risk_scores}. æ‰€æœ‰æŠ•ç¥¨å‡æœªå‘ç°å®è´¨æ€§æ¼æ´.",
                "llm_consensus": {
                    "num_votes": num_llm_votes,
                    "successful_votes": len(successful_votes),
                    "failed_votes": failed_votes,
                    "risk_scores": llm_risk_scores,
                    "average_risk_score": avg_risk_score,
                    "best_vote_score": 0,
                    "best_vote_index": -1,
                    "no_vulnerabilities_found": True,
                    "should_report": False,
                    "report_threshold": report_threshold
                },
                "analysis_timestamp": "2025-12-30"
            }

        logger.info(f"[Vulnerability Analyzer] {feature_id}:   - é€‰æ‹©æœ€é«˜åˆ†æŠ•ç¥¨: LLM#{best_vote.get('vote_index', 0) + 1} (è¯„åˆ†: {best_vote_score})")

        # ä½¿ç”¨æœ€ä½³æŠ•ç¥¨çš„ç»“æœ
        vulns = best_vote.get("result", {}).get("vulnerabilities", [])
        merged_vuln_found = True  # èƒ½åˆ°è¿™é‡Œè¯´æ˜è‚¯å®šæœ‰æ¼æ´

        # æ ¹æ®å¹³å‡åˆ†å†³å®šæ˜¯å¦åŒ…å«æ‰€æœ‰æ¼æ´
        if should_report:
            # åŒ…å«æ‰€æœ‰æ¼æ´
            merged_vulnerabilities = vulns
        else:
            # åªåŒ…å« high/critical çº§åˆ«çš„æ¼æ´
            merged_vulnerabilities = [
                v for v in vulns
                if v.get("severity", "low").lower() in ["critical", "high"]
            ]
            # ğŸ”§ å¦‚æœè¿‡æ»¤åæ²¡æœ‰æ¼æ´äº†ï¼Œè¿”å›ç©ºç»“æœ
            if not merged_vulnerabilities:
                logger.info(f"[Vulnerability Analyzer] {feature_id}: æœ€ä½³æŠ•ç¥¨å‘ç°äº†æ¼æ´ï¼Œä½†æ ¹æ®å¹³å‡åˆ†({avg_risk_score:.1f})è¿‡æ»¤åæ— high/criticalçº§åˆ«æ¼æ´")
                return {
                    "feature_id": feature.get("feature_id"),
                    "feature_name": feature.get("feature_name"),
                    "vulnerability_found": False,
                    "vulnerability_summary": f"åŸºäº{len(successful_votes)}ä¸ªLLMæŠ•ç¥¨çš„å…±è¯†åˆ†æ - å‘ç°äº†{len(vulns)}ä¸ªæ¼æ´ä½†å‡éhigh/criticalçº§åˆ«",
                    "vulnerabilities": [],
                    "overall_risk_assessment": f"å¹³å‡é£é™©è¯„åˆ†: {avg_risk_score:.1f}/100 (ä½äºhigh/criticalæŠ¥å‘Šé˜ˆå€¼)",
                    "additional_observations": f"æœ€ä½³æŠ•ç¥¨(è¯„åˆ†:{best_vote_score})å‘ç°äº†{len(vulns)}ä¸ªæ¼æ´ï¼Œä½†å¹³å‡åˆ†{avg_risk_score:.1f}ä½äºæŠ¥å‘Šé˜ˆå€¼ï¼Œä»…high/criticalä¼šè¢«æŠ¥å‘Š.",
                    "llm_consensus": {
                        "num_votes": num_llm_votes,
                        "successful_votes": len(successful_votes),
                        "failed_votes": failed_votes,
                        "risk_scores": llm_risk_scores,
                        "average_risk_score": avg_risk_score,
                        "best_vote_score": best_vote_score,
                        "best_vote_index": best_vote.get("vote_index", -1),
                        "vulnerabilities_found_but_filtered": True,
                        "original_vuln_count": len(vulns),
                        "should_report": False,
                        "report_threshold": report_threshold
                    },
                    "analysis_timestamp": "2025-12-30"
                }

        # æ„å»ºæœ€ç»ˆç»“æœ
        result = {
            "feature_id": feature.get("feature_id"),
            "feature_name": feature.get("feature_name"),
            "vulnerability_found": should_report and merged_vuln_found,
            "vulnerability_summary": f"åŸºäº{len(successful_votes)}ä¸ªLLMæŠ•ç¥¨çš„å…±è¯†åˆ†æï¼Œé€‰æ‹©æœ€é«˜åˆ†æŠ•ç¥¨ (è¯„åˆ†: {best_vote_score if best_vote else 0}, å¹³å‡: {avg_risk_score:.1f})",
            "vulnerabilities": merged_vulnerabilities if should_report else [],
            "overall_risk_assessment": f"å¹³å‡é£é™©è¯„åˆ†: {avg_risk_score:.1f}/100, æœ€ä½³æŠ•ç¥¨: {best_vote_score if best_vote else 0}",
            "additional_observations": f"LLMæŠ•ç¥¨æ•°: {num_llm_votes}, æˆåŠŸ: {len(successful_votes)}, å¤±è´¥: {failed_votes}. å„LLMè¯„åˆ†: {llm_risk_scores}",
            "llm_consensus": {
                "num_votes": num_llm_votes,
                "successful_votes": len(successful_votes),
                "failed_votes": failed_votes,
                "risk_scores": llm_risk_scores,
                "average_risk_score": avg_risk_score,
                "best_vote_score": best_vote_score,
                "best_vote_index": best_vote.get("vote_index", -1) if best_vote else -1,
                "should_report": should_report,
                "report_threshold": report_threshold
            },
            "analysis_timestamp": "2025-12-30"
        }

        # è®°å½•åˆ†æç»“æœ
        vuln_found = result.get("vulnerability_found", False)
        vuln_count = len(result.get("vulnerabilities", []))

        if vuln_found and vuln_count > 0:
            logger.info(f"[Vulnerability Analyzer] {feature_id}: åŸºäºLLMå…±è¯†å‘ç°æ¼æ´ - {vuln_count} ä¸ª (å¹³å‡åˆ†: {avg_risk_score:.1f})")

            # è®°å½•æ¼æ´è¯¦æƒ…ï¼ˆè¯¦ç»†æ—¥å¿—æ¨¡å¼ï¼‰
            if os.getenv("ENABLE_DETAILED_LOGS", "false").lower() == "true":
                for i, vuln in enumerate(result.get("vulnerabilities", [])[:5]):  # æœ€å¤šè®°å½•5ä¸ªæ¼æ´
                    vuln_type = vuln.get("type", "unknown")
                    severity = vuln.get("severity", "unknown")
                    confidence = vuln.get("confidence", "unknown")
                    line_number = vuln.get("line", vuln.get("line_number", "unknown"))
                    file_path = vuln.get("file_path", "unknown")

                    logger.info(f"[Vulnerability Analyzer] {feature_id}: æ¼æ´{i+1}: {vuln_type} ({severity}, {confidence})")
                    logger.info(f"[Vulnerability Analyzer] {feature_id}:   ä½ç½®: {file_path}:{line_number}")
                    logger.debug(f"[Vulnerability Analyzer] {feature_id}:   æè¿°: {vuln.get('description', 'N/A')[:200]}")
        else:
            logger.info(f"[Vulnerability Analyzer] {feature_id}: åŸºäºLLMå…±è¯†æœªå‘ç°æ¼æ´ (å¹³å‡åˆ†: {avg_risk_score:.1f} < é˜ˆå€¼)")

        safe_print(f"[{feature_index}/{total_features}] Completed: {feature_id} - Avg Score: {avg_risk_score:.1f}, Vulns: {vuln_count}, Reported: {should_report}")

        # ğŸ”§ åº”ç”¨ Nil-Guard è¿‡æ»¤å™¨ï¼ˆç§»é™¤ nil/NoMethodError è¯¯æŠ¥ï¼‰
        if vuln_count > 0:
            logger.info(f"[Vulnerability Analyzer] {feature_id}: ğŸ›¡ï¸ åº”ç”¨ Nil-Guard è¿‡æ»¤å™¨ (å½“å‰æ¼æ´æ•°: {vuln_count})...")
            result = _apply_nil_guard(result)

        logger.debug(f"[Vulnerability Analyzer] {feature_id}: åˆ†æå®Œæˆ")
        return result

    except Exception as e:
        logger.error(f"[Vulnerability Analyzer] {feature_id}: åˆ†æè¿‡ç¨‹ä¸­å‡ºé”™ - {str(e)}")
        logger.error(f"[Vulnerability Analyzer] {feature_id}: å¼‚å¸¸è¯¦æƒ…: {traceback.format_exc()}")

        error_result = {
            "vulnerability_found": False,
            "vulnerability_summary": f"åˆ†æè¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}",
            "vulnerabilities": [],
            "overall_risk_assessment": "åˆ†æå¤±è´¥",
            "additional_observations": f"é”™è¯¯: {str(e)}",
            "feature_id": feature.get("feature_id"),
            "feature_name": feature.get("feature_name"),
            "analysis_error": True
        }
        safe_print(f"[{feature_index}/{total_features}] ERROR: {feature_id} - {str(e)}")
        return error_result


def analyze_feature_parallel(args: Tuple[Dict[str, Any], str, Dict[str, Any], Dict[str, Any], Dict[str, Any], int, int, Dict[str, Any], List[Dict[str, Any]], int]) -> Dict[str, Any]:
    """
    Parallel analysis function that processes a single feature.
    Args: (feature, pr_dir, relevant_queries, codeql_results, llm_config, feature_index, total_features, diff_ir, detailed_hunks, num_llm_votes)
    """
    feature, pr_dir, relevant_queries, codeql_results, llm_config, feature_index, total_features, diff_ir, detailed_hunks, num_llm_votes = args

    # Create LLM instance for this thread
    llm = ChatOpenAI(
        model=llm_config["model"],
        temperature=llm_config["temperature"],
        base_url=llm_config["base_url"],
        api_key=llm_config["api_key"],
    )

    # Extract files content for this feature
    files_content = extract_diff_files_for_feature(feature, pr_dir)

    # ğŸ”§ ä¼ é€’ LLM æŠ•ç¥¨æ•°é‡
    result = analyze_feature_vulnerability(
        feature, files_content, relevant_queries, codeql_results, llm, feature_index, total_features, detailed_hunks, num_llm_votes
    )

    return result


def analyze_vulnerabilities(
    pr_dir: str,
    feature_risk_plan: Dict[str, Any],
    query_plan: Dict[str, Any],
    codeql_results: Dict[str, Any],
    llm: ChatOpenAI,
    workers: int = 1,
    diff_ir: Optional[Dict[str, Any]] = None,
    num_llm_votes: int = 3  # ğŸ”§ æ–°å¢ï¼šæ¯ä¸ªåŠŸèƒ½çš„LLMæŠ•ç¥¨æ•°é‡
) -> Dict[str, Any]:
    """
    æ‰§è¡Œæ¼æ´åˆ†æ

    Args:
        pr_dir: PRç›®å½•
        feature_risk_plan: åŠŸèƒ½é£é™©è®¡åˆ’
        query_plan: æŸ¥è¯¢è®¡åˆ’
        codeql_results: CodeQLç»“æœ
        llm: è¯­è¨€æ¨¡å‹
        workers: å¹¶è¡Œå·¥ä½œçº¿ç¨‹æ•°
        diff_ir: å·®å¼‚ä¿¡æ¯
        num_llm_votes: æ¯ä¸ªåŠŸèƒ½çš„LLMæŠ•ç¥¨æ•°é‡ï¼ˆé»˜è®¤3ä¸ªï¼‰

    Returns:
        æ¼æ´åˆ†æç»“æœ
    """
    logger.info(f"[Vulnerability Analyzer] å¼€å§‹æ¼æ´åˆ†æ")
    logger.info(f"[Vulnerability Analyzer] PRç›®å½•: {pr_dir}")
    logger.info(f"[Vulnerability Analyzer] å¹¶è¡Œå·¥ä½œçº¿ç¨‹æ•°: {workers}")

    # Load diff_ir if not provided
    if not diff_ir:
        logger.debug(f"[Vulnerability Analyzer] åŠ è½½diff_iræ•°æ®...")
        diff_ir_path = os.path.join(pr_dir, "out", "diff_ir.json")
        try:
            diff_ir = read_json(diff_ir_path)
            logger.debug(f"[Vulnerability Analyzer] æˆåŠŸåŠ è½½diff_ir: {len(diff_ir.get('files', []))} ä¸ªæ–‡ä»¶")
        except Exception as e:
            logger.error(f"[Vulnerability Analyzer] åŠ è½½diff_irå¤±è´¥: {str(e)}")
            diff_ir = {"files": []}

    # LLM configuration
    llm_config = {
        "model": llm.model_name,
        "temperature": llm.temperature,
        "base_url": llm.openai_api_base,
        "api_key": llm.openai_api_key,
    }

    logger.info(f"[Vulnerability Analyzer] LLMæ¨¡å‹: {llm_config['model']}")

    # Analyze each feature
    features = feature_risk_plan.get("features", [])
    total_features = len(features)

    logger.info(f"[Vulnerability Analyzer] å¾…åˆ†æåŠŸèƒ½æ•°: {total_features}")

    if total_features == 0:
        logger.warning(f"[Vulnerability Analyzer] æ²¡æœ‰éœ€è¦åˆ†æçš„åŠŸèƒ½")
        return {
            "analysis_summary": {
                "total_features_analyzed": 0,
                "features_with_vulnerabilities": 0,
                "total_vulnerabilities_found": 0,
            },
            "feature_analyses": []
        }

    # Determine worker count
    if workers <= 1:
        workers = 1
    else:
        workers = min(workers, total_features)

    logger.info(f"[Vulnerability Analyzer] å®é™…ä½¿ç”¨å·¥ä½œçº¿ç¨‹æ•°: {workers}")

    # è®°å½•åŠŸèƒ½æ¦‚è§ˆ
    if os.getenv("ENABLE_DETAILED_LOGS", "false").lower() == "true":
        logger.debug(f"[Vulnerability Analyzer] åŠŸèƒ½åˆ—è¡¨:")
        for i, feature in enumerate(features[:10]):  # æœ€å¤šæ˜¾ç¤º10ä¸ª
            feature_id = feature.get("feature_id", "unknown")
            risk_score = feature.get("risk_overview", {}).get("overall_risk_score", 0)
            hunk_count = len(feature.get("hunks", []))
            logger.debug(f"[Vulnerability Analyzer]   åŠŸèƒ½{i+1}: {feature_id} (é£é™©:{risk_score}, hunk:{hunk_count})")

    safe_print(f"[INFO] Starting vulnerability analysis for {total_features} features using {workers} workers...")

    # Prepare analysis tasks
    logger.debug(f"[Vulnerability Analyzer] å‡†å¤‡åˆ†æä»»åŠ¡...")
    analysis_tasks = []
    total_queries = 0
    total_hunks = 0

    for i, feature in enumerate(features, 1):
        # Find relevant queries for this feature
        relevant_queries = map_queries_to_feature(feature, query_plan)
        total_queries += len(relevant_queries)

        # Get detailed hunks with line numbers for this feature
        detailed_hunks = get_feature_hunks_with_lines(feature, diff_ir)
        total_hunks += len(detailed_hunks)

        feature_id = feature.get("feature_id", "unknown")
        logger.debug(f"[Vulnerability Analyzer] åŠŸèƒ½{feature_id}: {len(relevant_queries)} ä¸ªæŸ¥è¯¢, {len(detailed_hunks)} ä¸ªè¯¦ç»†hunks")

        task_args = (
            feature,
            pr_dir,
            relevant_queries,
            codeql_results,
            llm_config,
            i,
            total_features,
            diff_ir,
            detailed_hunks,
            num_llm_votes  # ğŸ”§ æ·»åŠ LLMæŠ•ç¥¨æ•°é‡
        )
        analysis_tasks.append(task_args)

    logger.info(f"[Vulnerability Analyzer] åˆ†æç»Ÿè®¡: æ€»æŸ¥è¯¢={total_queries}, æ€»hunks={total_hunks}")

    all_results = []
    success_count = 0
    error_count = 0
    vulnerability_count = 0

    # ğŸ”§ é˜¶æ®µ1: ç¡¬é—¨æ§ç»Ÿè®¡æŒ‡æ ‡
    gate_skipped_count = 0
    gate_stats = {
        "BLOCK": 0,
        "SANITIZE": 0,
        "LOW_RISK_FILETYPE": 0,
        "LOW_RISK_SCORE": 0,
        "NO_FUNCTIONAL_CHANGE": 0,
        "ALLOW": 0
    }

    if workers == 1:
        # Sequential execution
        logger.info(f"[Vulnerability Analyzer] å¼€å§‹ä¸²è¡Œåˆ†æ...")
        safe_print("[INFO] Running sequential analysis...")
        for task_args in analysis_tasks:
            try:
                # For sequential execution, we can pass directly without creating LLM instance
                feature, pr_dir, relevant_queries, codeql_results, llm_config, feature_index, total_features, diff_ir, detailed_hunks = task_args

                logger.debug(f"[Vulnerability Analyzer] ä¸ºåŠŸèƒ½åˆ›å»ºLLMå®ä¾‹: {llm_config['model']}")

                # Create LLM instance for sequential execution
                llm = ChatOpenAI(
                    model=llm_config["model"],
                    temperature=llm_config["temperature"],
                    base_url=llm_config["base_url"],
                    api_key=llm_config["api_key"],
                )

                # Extract files content for this feature
                logger.debug(f"[Vulnerability Analyzer] æå–æ–‡ä»¶å†…å®¹...")
                files_content = extract_diff_files_for_feature(feature, pr_dir)

                # ğŸ”§ Analyze with LLM (ä¼ é€’æŠ•ç¥¨æ•°é‡)
                result = analyze_feature_vulnerability(
                    feature, files_content, relevant_queries, codeql_results, llm, feature_index, total_features, detailed_hunks, num_llm_votes
                )
                all_results.append(result)

                # ğŸ”§ ç»Ÿè®¡ç¡¬é—¨æ§è·³è¿‡æƒ…å†µ
                if result.get("analysis_skipped"):
                    gate_skipped_count += 1
                    gate_decision = result.get("filter_gate", {}).get("decision", "UNKNOWN")
                    if gate_decision in gate_stats:
                        gate_stats[gate_decision] += 1
                # ç»Ÿè®¡ç»“æœ
                elif result.get("analysis_error"):
                    error_count += 1
                else:
                    success_count += 1
                    if result.get("vulnerability_found", False):
                        vulnerability_count += len(result.get("vulnerabilities", []))

            except Exception as e:
                logger.error(f"[Vulnerability Analyzer] ä¸²è¡Œåˆ†æåŠŸèƒ½å¤±è´¥ - {str(e)}")
                feature = task_args[0]
                error_result = {
                    "vulnerability_found": False,
                    "vulnerability_summary": f"ä¸²è¡Œåˆ†æå¤±è´¥: {str(e)}",
                    "vulnerabilities": [],
                    "overall_risk_assessment": "åˆ†æå¤±è´¥",
                    "additional_observations": f"ä¸²è¡Œåˆ†æé”™è¯¯: {str(e)}",
                    "feature_id": feature.get("feature_id"),
                    "feature_name": feature.get("feature_name"),
                    "analysis_error": True,
                    "sequential_error": True
                }
                all_results.append(error_result)
                error_count += 1
                safe_print(f"[ERROR] Feature {feature.get('feature_id', 'unknown')} failed: {str(e)}")
    else:
        # Parallel execution
        logger.info(f"[Vulnerability Analyzer] å¼€å§‹å¹¶è¡Œåˆ†æ ({workers} å·¥ä½œçº¿ç¨‹)...")
        safe_print(f"[INFO] Running parallel analysis with {workers} workers...")
        with ThreadPoolExecutor(max_workers=workers) as executor:
            # Submit all tasks
            future_to_index = {
                executor.submit(analyze_feature_parallel, task_args): i
                for i, task_args in enumerate(analysis_tasks)
            }

            logger.info(f"[Vulnerability Analyzer] å·²æäº¤ {len(analysis_tasks)} ä¸ªå¹¶è¡Œä»»åŠ¡")

            # Collect results as they complete
            completed_count = 0
            for future in as_completed(future_to_index):
                try:
                    result = future.result()
                    all_results.append(result)
                    completed_count += 1
                    logger.debug(f"[Vulnerability Analyzer] å¹¶è¡Œä»»åŠ¡å®Œæˆ: {completed_count}/{total_features}")
                    safe_print(f"[PROGRESS] Completed {completed_count}/{total_features} features")

                    # ğŸ”§ ç»Ÿè®¡ç¡¬é—¨æ§è·³è¿‡æƒ…å†µ
                    if result.get("analysis_skipped"):
                        gate_skipped_count += 1
                        gate_decision = result.get("filter_gate", {}).get("decision", "UNKNOWN")
                        if gate_decision in gate_stats:
                            gate_stats[gate_decision] += 1
                    # ç»Ÿè®¡ç»“æœ
                    elif result.get("analysis_error"):
                        error_count += 1
                    else:
                        success_count += 1
                        if result.get("vulnerability_found", False):
                            vulnerability_count += len(result.get("vulnerabilities", []))

                except Exception as e:
                    logger.error(f"[Vulnerability Analyzer] å¹¶è¡Œä»»åŠ¡æ‰§è¡Œå¤±è´¥ - {str(e)}")
                    # Handle failed future
                    original_index = future_to_index[future]
                    feature = analysis_tasks[original_index][0]
                    error_result = {
                        "vulnerability_found": False,
                        "vulnerability_summary": f"å¹¶è¡Œæ‰§è¡Œå¤±è´¥: {str(e)}",
                        "vulnerabilities": [],
                        "overall_risk_assessment": "åˆ†æå¤±è´¥",
                        "additional_observations": f"å¹¶è¡Œæ‰§è¡Œé”™è¯¯: {str(e)}",
                        "feature_id": feature.get("feature_id"),
                        "feature_name": feature.get("feature_name"),
                        "analysis_error": True,
                        "parallel_error": True
                    }
                    all_results.append(error_result)
                    error_count += 1
                    safe_print(f"[ERROR] Feature {original_index} failed: {str(e)}")

        # Sort results by original feature order
        logger.debug(f"[Vulnerability Analyzer] æŒ‰åŸå§‹åŠŸèƒ½é¡ºåºæ’åºç»“æœ...")
        all_results.sort(key=lambda x: features.index(next(f for f in features if f.get("feature_id") == x.get("feature_id"))))

    # Generate final report
    logger.info(f"[Vulnerability Analyzer] ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š...")

    features_with_vulnerabilities = sum(1 for r in all_results if r.get("vulnerability_found", False))
    total_vulnerabilities_found = sum(len(r.get("vulnerabilities", [])) for r in all_results)

    # åˆ†ç±»æ¼æ´åˆ° logic å’Œ security
    logic_vulnerabilities = []
    security_vulnerabilities = []

    for result in all_results:
        for vuln in result.get("vulnerabilities", []):
            vuln_type = vuln.get("type", "")

            # æ ¹æ®æ¼æ´ç±»å‹åˆ†ç±»
            security_keywords = [
                "æ³¨å…¥", "injection", "sql", "xss", "ssrf", "csrf",
                "æƒé™", "permission", "è®¤è¯", "auth", "æˆæƒ",
                "æ•æ„Ÿ", "sensitive", "æ³„éœ²", "leak",
                "ååºåˆ—åŒ–", "deserialize", "unmarshal"
            ]

            logic_keywords = [
                "å¹¶å‘", "concurrent", "æ­»é”", "deadlock", "ç«äº‰", "race",
                "è¾¹ç•Œ", "boundary", "ç©ºå€¼", "null", "èµ„æº", "resource",
                "ç®—æ³•", "algorithm", "çŠ¶æ€", "state"
            ]

            is_security = any(keyword in vuln_type.lower() for keyword in security_keywords)
            is_logic = any(keyword in vuln_type.lower() for keyword in logic_keywords)

            # è½¬æ¢ä¸º Agent çš„ issue æ ¼å¼,å…¼å®¹ _convert_issue_to_inline_comment
            # æ ¼å¼: {result: "ISSUE", issues: [...], _meta: {...}, location: {...}}

            # ğŸ†• ä¼˜å…ˆä½¿ç”¨æ–°çš„ `line` å­—æ®µï¼ˆå•ä¸ªæ•´æ•°ï¼‰ï¼Œfallback åˆ° `line_number`
            line_value = vuln.get("line", vuln.get("line_number", 0))

            # Parse line ranges - now expects single integer from `line` field
            line_ranges = []

            if isinstance(line_value, list):
                # Legacy format: [46, 47] or [[46, 47], [52, 53]]
                if len(line_value) > 0 and isinstance(line_value[0], list):
                    # List of ranges: [[46, 47], [52, 53]]
                    line_ranges = [(int(r[0]), int(r[1]) if len(r) > 1 else int(r[0])) for r in line_value]
                elif len(line_value) >= 2:
                    # Single range as list: [46, 47]
                    start = int(line_value[0])
                    end = int(line_value[1])
                    line_ranges = [(start, end)]
                else:
                    # Single number as list: [46]
                    num = int(line_value[0]) if len(line_value) > 0 else 0
                    line_ranges = [(num, num)]
            elif isinstance(line_value, str):
                # String format: "46-47,52-53,60-68" or "182-184" or "449"
                try:
                    parts = line_value.split(',')
                    for part in parts:
                        part = part.strip()
                        if '-' in part:
                            start_end = part.split('-')
                            start = int(start_end[0].strip())
                            end = int(start_end[1].strip()) if len(start_end) > 1 else start
                            line_ranges.append((start, end))
                        else:
                            num = int(part)
                            line_ranges.append((num, num))
                except (ValueError, IndexError) as e:
                    logger.warning(f"Failed to parse line '{line_value}': {e}")
                    line_ranges = [(0, 0)]
            else:
                # Integer format: 46 (æœŸæœ›çš„æ–°æ ¼å¼)
                try:
                    num = int(line_value)
                    line_ranges = [(num, num)]
                except (ValueError, TypeError):
                    logger.warning(f"Invalid line format: {line_value} (type: {type(line_value)})")
                    line_ranges = [(0, 0)]

            # ğŸ†• ä½¿ç”¨ hunk_id æ¥å®šä½ï¼Œè€Œä¸æ˜¯ä¾èµ–ä¸å‡†ç¡®çš„è¡Œå·
            # ä¸ Logic Agent å’Œ Security Agent ä¿æŒä¸€è‡´
            file_path = vuln.get("file_path", "")

            # ä» diff_ir ä¸­æŸ¥æ‰¾åŒ¹é…çš„ hunk_idï¼ˆå”¯ä¸€çœŸæºï¼‰
            matched_hunk_id = ""
            if diff_ir:
                # 1. æŒ‰ file_path æ‰¾åˆ° diff_ir ä¸­å¯¹åº”çš„ file
                diff_files = diff_ir.get("files", [])
                target_file = None
                target_file_idx = None
                for idx, df in enumerate(diff_files):
                    if df.get("file_path") == file_path:
                        target_file = df
                        target_file_idx = idx
                        break

                if target_file:
                    # 2. åœ¨è¯¥æ–‡ä»¶çš„ hunks ä¸­æŸ¥æ‰¾ä¸ line_ranges æœ‰é‡å çš„ hunk
                    hunks = target_file.get("hunks", [])
                    for h_idx, hunk in enumerate(hunks):
                        hunk_id = hunk.get("hunk_id", f"{target_file_idx}:{h_idx}")

                        # è·å– hunk çš„è¡Œå·èŒƒå›´ï¼ˆRIGHT sideï¼‰
                        new_start = hunk.get("new_start", 0)
                        new_count = hunk.get("new_count", 0)
                        hunk_line_start = new_start
                        hunk_line_end = new_start + new_count - 1

                        # æ£€æŸ¥æ˜¯å¦æœ‰ä»»æ„ä¸€ä¸ª line_range ä¸ hunk èŒƒå›´é‡å 
                        has_overlap = False
                        for (line_start, line_end) in line_ranges:
                            # åˆ¤æ–­ä¸¤ä¸ªåŒºé—´æ˜¯å¦é‡å 
                            if not (line_end < hunk_line_start or line_start > hunk_line_end):
                                has_overlap = True
                                break

                        if has_overlap:
                            matched_hunk_id = hunk_id
                            logger.debug(
                                f"[Vulnerability Analyzer] åŒ¹é…åˆ° hunk_id: {hunk_id} "
                                f"for {file_path}:{line_ranges} "
                                f"(hunk range: {hunk_line_start}-{hunk_line_end})"
                            )
                            break

                        # Fallback: å¦‚æœä¸Šé¢çš„é‡å æ£€æµ‹å¤±è´¥ï¼Œå°è¯•ç”¨ hunk.lines[*].new_lineno ç²¾ç¡®åŒ¹é…
                        lines = hunk.get("lines", [])
                        for line in lines:
                            new_lineno = line.get("new_lineno")
                            if new_lineno is not None:
                                for (line_start, line_end) in line_ranges:
                                    if line_start <= new_lineno <= line_end:
                                        matched_hunk_id = hunk_id
                                        logger.debug(
                                            f"[Vulnerability Analyzer] é€šè¿‡ lines åŒ¹é…åˆ° hunk_id: {hunk_id} "
                                            f"for {file_path}:{line_ranges} "
                                            f"(matched line: {new_lineno})"
                                        )
                                        break
                                if matched_hunk_id:
                                    break
                        if matched_hunk_id:
                            break

                    if not matched_hunk_id:
                        logger.warning(
                            f"[Vulnerability Analyzer] æœªæ‰¾åˆ°åŒ¹é…çš„ hunk_id "
                            f"for {file_path}:{line_ranges}"
                        )
                else:
                    logger.warning(
                        f"[Vulnerability Analyzer] åœ¨ diff_ir ä¸­æœªæ‰¾åˆ°æ–‡ä»¶: {file_path}"
                    )
            else:
                logger.warning(
                    f"[Vulnerability Analyzer] diff_ir ä¸ºç©ºï¼Œæ— æ³•æŸ¥æ‰¾ hunk_id"
                )

            converted_issue = {
                "result": "ISSUE",
                "issues": [{  # issues æ•°ç»„,æ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªé—®é¢˜å¯¹è±¡
                    "title": vuln.get("type", "æœªçŸ¥é—®é¢˜"),
                    "severity": vuln.get("severity", "medium"),
                    "confidence": vuln.get("confidence", "medium"),
                    "description": vuln.get("description", ""),
                    "root_cause": vuln.get("root_cause", ""),
                    "fix_recommendation": vuln.get("fix_recommendation", ""),
                    "suggestion": vuln.get("fix_recommendation", ""),  # å…¼å®¹ suggestion å­—æ®µ
                    "category": vuln.get("type", ""),  # æ·»åŠ  category
                    "cwe": []  # AI æ¼æ´åˆ†ææ²¡æœ‰ CWE
                }],
                "_meta": {
                    "hunk_id": matched_hunk_id,
                    "file_path": file_path,
                    "risk_score": result.get("risk_score", 0),
                    "feature_id": result.get("feature_id", ""),
                    "analysis_source": "ai_vulnerability_analysis"
                },
                "tool_evidence": {
                    "summary": {
                        "confidence_score": 70,  # AI åˆ†æé»˜è®¤ç½®ä¿¡åº¦
                        "has_ai_evidence": True
                    },
                    "ai_analysis": {
                        "exploit_scenario": vuln.get("exploit_scenario", ""),
                        "code_snippet": vuln.get("code_snippet", ""),
                        "additional_observations": vuln.get("additional_observations", "")
                    }
                }
            }

            if is_security or not is_logic:  # é»˜è®¤å½’ä¸ºå®‰å…¨é—®é¢˜
                security_vulnerabilities.append(converted_issue)
            else:
                logic_vulnerabilities.append(converted_issue)

    final_report = {
        "analysis_summary": {
            "total_features_analyzed": total_features,
            "features_with_vulnerabilities": features_with_vulnerabilities,
            "total_vulnerabilities_found": total_vulnerabilities_found,
            "logic_vulnerabilities_found": len(logic_vulnerabilities),
            "security_vulnerabilities_found": len(security_vulnerabilities),
            "analysis_timestamp": "2025-12-21",
            "parallel_execution": workers > 1,
            "workers_used": workers
        },
        "pr_identification": query_plan.get("pr_identification", {}),
        "feature_analyses": all_results,
        # ğŸ†• è¿”å›åˆ†ç±»åçš„é—®é¢˜,ç”¨äºåˆå¹¶åˆ° logic_review å’Œ security_review
        "categorized_issues": {
            "logic_issues": logic_vulnerabilities,
            "security_issues": security_vulnerabilities
        }
    }

    # æœ€ç»ˆç»Ÿè®¡æ—¥å¿—
    logger.info(f"[Vulnerability Analyzer] æ¼æ´åˆ†æå®Œæˆç»Ÿè®¡:")
    logger.info(f"[Vulnerability Analyzer]   æ€»åŠŸèƒ½æ•°: {total_features}")
    logger.info(f"[Vulnerability Analyzer]   åˆ†ææˆåŠŸ: {success_count}")
    logger.info(f"[Vulnerability Analyzer]   åˆ†æå¤±è´¥: {error_count}")
    logger.info(f"[Vulnerability Analyzer]   ğŸ”’ ç¡¬é—¨æ§è·³è¿‡: {gate_skipped_count} ({gate_skipped_count*100//total_features if total_features > 0 else 0}%)")
    logger.info(f"[Vulnerability Analyzer]   æœ‰æ¼æ´åŠŸèƒ½: {features_with_vulnerabilities}")
    logger.info(f"[Vulnerability Analyzer]   å‘ç°æ¼æ´æ€»æ•°: {total_vulnerabilities_found}")

    # ç¡¬é—¨æ§è¯¦ç»†ç»Ÿè®¡
    if gate_skipped_count > 0:
        logger.info(f"[Vulnerability Analyzer] ç¡¬é—¨æ§åˆ†ç±»ç»Ÿè®¡:")
        for decision, count in gate_stats.items():
            if count > 0:
                logger.info(f"[Vulnerability Analyzer]   - {decision}: {count}")

    # æ¼æ´ä¸¥é‡ç¨‹åº¦ç»Ÿè®¡
    if total_vulnerabilities_found > 0:
        severity_counts = {"critical": 0, "high": 0, "medium": 0, "low": 0, "info": 0}
        type_counts = {}

        for result in all_results:
            for vuln in result.get("vulnerabilities", []):
                severity = vuln.get("severity", "unknown")
                vuln_type = vuln.get("type", "unknown")

                if severity in severity_counts:
                    severity_counts[severity] += 1
                type_counts[vuln_type] = type_counts.get(vuln_type, 0) + 1

        logger.info(f"[Vulnerability Analyzer] æ¼æ´ä¸¥é‡ç¨‹åº¦åˆ†å¸ƒ: {severity_counts}")
        if type_counts:
            logger.info(f"[Vulnerability Analyzer] æ¼æ´ç±»å‹åˆ†å¸ƒ: {dict(list(type_counts.items())[:10])}")  # æœ€å¤šæ˜¾ç¤º10ç§ç±»å‹

    return final_report