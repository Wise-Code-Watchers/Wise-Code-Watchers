"""
æ¼æ´åˆ†ææ¨¡å— - å¯¹åº”6.pyåŠŸèƒ½
åŸºäºAIå’Œé™æ€åˆ†æç»“æœè¿›è¡Œæ¼æ´åˆ†æï¼Œä½¿ç”¨LLMç”Ÿæˆæœ€ç»ˆæŠ¥å‘Šï¼ˆå·²ç§»é™¤CodeQLä¾èµ–ï¼‰
æ³¨æ„ï¼šè™½ç„¶å‡½æ•°åä¸­ä»åŒ…å«"codeql"ï¼Œä½†å®é™…è°ƒç”¨æ—¶ä¼ å…¥ç©ºçš„codeql_resultså­—å…¸å³å¯æ­£å¸¸å·¥ä½œ
"""

import json
import logging
import os
import threading
import traceback
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import Any, Dict, List, Tuple, Optional

from langchain_core.messages import SystemMessage, HumanMessage
from langchain_openai import ChatOpenAI

# é…ç½®æ—¥å¿—
logger = logging.getLogger(__name__)

# Thread-safe printing (ä¿ç•™ç”¨äºå…¼å®¹æ€§)
print_lock = threading.Lock()

def safe_print(*args, **kwargs):
    """Thread-safe print function."""
    with print_lock:
        print(*args, **kwargs)


def read_json(path: str) -> Dict[str, Any]:
    """Read JSON file safely."""
    with open(path, "r", encoding="utf-8") as f:
        return json.load(f)


def write_json(path: str, obj: Any) -> None:
    """Write JSON file safely."""
    os.makedirs(os.path.dirname(path) or ".", exist_ok=True)
    with open(path, "w", encoding="utf-8") as f:
        json.dump(obj, f, ensure_ascii=False, indent=2)


def read_file_content(path: str) -> str:
    """Read file content if exists, return empty string if not."""
    try:
        with open(path, "r", encoding="utf-8") as f:
            return f.read()
    except FileNotFoundError:
        return f"FILE_NOT_FOUND: {path}"
    except Exception as e:
        return f"ERROR_READING_FILE {path}: {str(e)}"


def load_codeql_results(results_dir: str) -> Dict[str, Any]:
    """Load CodeQL query results from results directory."""
    results = {}
    if not os.path.exists(results_dir):
        return results

    manifest_path = os.path.join(results_dir, "results_manifest.json")
    if not os.path.exists(manifest_path):
        return results

    manifest = read_json(manifest_path)

    for result_item in manifest:
        template_id = result_item.get("template_id")
        json_path = result_item.get("json")

        if json_path and os.path.exists(json_path):
            result_data = read_json(json_path)
            results[template_id] = {
                "result_data": result_data,
                "metadata": result_item
            }

    return results


def get_feature_hunks_with_lines(feature: Dict[str, Any], diff_ir: Dict[str, Any]) -> List[Dict[str, Any]]:
    """
    Get detailed hunks information with line numbers for a feature.
    """
    feature_hunks = feature.get("hunks", [])
    detailed_hunks = []

    for feature_hunk in feature_hunks:
        hunk_id = feature_hunk.get("hunk_id")
        file_path = feature_hunk.get("file_path")

        if not hunk_id or not file_path:
            continue

        # Find corresponding hunk in diff_ir
        try:
            file_idx, hunk_idx = map(int, hunk_id.split(":"))
            diff_files = diff_ir.get("files", [])
            if file_idx < len(diff_files):
                diff_file = diff_files[file_idx]
                diff_hunks = diff_file.get("hunks", [])
                if hunk_idx < len(diff_hunks):
                    diff_hunk = diff_hunks[hunk_idx]
                    detailed_hunks.append({
                        "hunk_id": hunk_id,
                        "file_path": file_path,
                        "old_start": diff_hunk.get("old_start"),
                        "old_count": diff_hunk.get("old_count"),
                        "new_start": diff_hunk.get("new_start"),
                        "new_count": diff_hunk.get("new_count"),
                        "header": diff_hunk.get("header"),
                        "lines": diff_hunk.get("lines", []),
                        "functional_change": feature_hunk.get("functional_change"),
                        "risk_score": feature_hunk.get("risk_score"),
                        "severity": feature_hunk.get("severity")
                    })
        except (ValueError, IndexError):
            continue

    return detailed_hunks


def extract_diff_files_for_feature(feature: Dict[str, Any], pr_dir: str) -> Dict[str, Tuple[str, str]]:
    """
    Extract before and after file content for a feature.
    Returns: {file_path: (before_content, after_content)}
    """
    files_processed = {}

    # Find all hunks for this feature
    hunks = feature.get("hunks", [])
    for hunk in hunks:
        file_path = hunk.get("file_path")
        if not file_path:
            continue

        if file_path in files_processed:
            continue  # Already processed this file

        # Try to find the file in the repo snapshots
        # Assuming we have both before and after snapshots in the PR directory
        before_path = os.path.join(pr_dir, "repo_before", file_path)
        after_path = os.path.join(pr_dir, "repo_after", file_path)

        # Fallback: try to find in parent directories
        if not os.path.exists(before_path):
            before_path = os.path.join(pr_dir, "..", "repo_before", file_path)
        if not os.path.exists(after_path):
            after_path = os.path.join(pr_dir, "..", "repo_after", file_path)

        before_content = read_file_content(before_path)
        after_content = read_file_content(after_path)

        files_processed[file_path] = (before_content, after_content)

    return files_processed


def map_queries_to_feature(feature: Dict[str, Any], query_plan: Dict[str, Any]) -> List[Dict[str, Any]]:
    """
    Map CodeQL queries to a specific feature based on relevance.
    """
    feature_hunks = feature.get("hunks", [])
    feature_files = {hunk.get("file_path") for hunk in feature_hunks if hunk.get("file_path")}

    relevant_queries = []
    all_queries = query_plan.get("queries", [])

    for query in all_queries:
        query_params = query.get("params", {})
        query_file = query_params.get("module_path", query_params.get("file_path", ""))

        # Convert module_path to file_path if needed
        if query_file and "." in query_file:
            query_file = query_file.replace(".", "/") + ".py"

        # Check if query relates to files in this feature
        if any(feature_file in query_file or query_file in feature_file
               for feature_file in feature_files if feature_file):
            relevant_queries.append(query)
        elif query.get("template_id") in ["PY_REFERENCES_OF_SYMBOL", "PY_CALLERS_OF_FUNCTION"]:
            # Symbol-based queries might be relevant
            relevant_queries.append(query)

    return relevant_queries


def format_file_with_diff_highlight(
    file_content: str,
    diff_lines: List[Dict[str, Any]],
    new_start: int,
    new_count: int
) -> str:
    """
    Format file content with diff highlighting.
    """
    if not file_content or not diff_lines:
        return file_content

    lines = file_content.split('\n')
    highlighted_lines = []

    # Create a set of modified line numbers
    modified_lines = set()
    for diff_line in diff_lines:
        line_type = diff_line.get("type")
        new_lineno = diff_line.get("new_lineno")
        if line_type in ["add", "del"] and new_lineno is not None:
            modified_lines.add(new_lineno)

    # Highlight modified lines
    for i, line in enumerate(lines, 1):
        if i in modified_lines:
            highlighted_lines.append(f"[MODIFIED] {line}")
        else:
            highlighted_lines.append(line)

    return '\n'.join(highlighted_lines)


def build_vulnerability_analysis_prompt(
    feature: Dict[str, Any],
    files_content: Dict[str, Tuple[str, str]],
    relevant_queries: List[Dict[str, Any]],
    codeql_results: Dict[str, Any],
    detailed_hunks: List[Dict[str, Any]]
) -> str:
    """Build comprehensive LLM prompt for vulnerability analysis."""

    feature_name = feature.get("feature_name", "")
    feature_summary = feature.get("summary", "")
    business_impact = feature.get("business_impact", "")
    risk_overview = feature.get("risk_overview", {})
    key_risks = risk_overview.get("key_risks", [])

    # Build files section with diff details
    files_section = []

    # Group hunks by file_path
    hunks_by_file = {}
    for hunk in detailed_hunks:
        file_path = hunk.get("file_path")
        if file_path not in hunks_by_file:
            hunks_by_file[file_path] = []
        hunks_by_file[file_path].append(hunk)

    for file_path, (before, after) in files_content.items():
        files_section.append(f"## File: {file_path}")

        # Add diff information for this file
        if file_path in hunks_by_file:
            file_hunks = hunks_by_file[file_path]
            files_section.append("### å…·ä½“ä¿®æ”¹ä¿¡æ¯:")
            for hunk in file_hunks:
                hunk_id = hunk.get("hunk_id")
                old_start = hunk.get("old_start")
                old_count = hunk.get("old_count")
                new_start = hunk.get("new_start")
                new_count = hunk.get("new_count")
                functional_change = hunk.get("functional_change", "")
                risk_score = hunk.get("risk_score", 0)
                severity = hunk.get("severity", "")

                files_section.append(f"**Hunk {hunk_id}:**")
                files_section.append(f"- ä¿®æ”¹èŒƒå›´: {old_start}-{old_start + old_count - 1} â†’ {new_start}-{new_start + new_count - 1}")
                files_section.append(f"- åŠŸèƒ½å˜æ›´: {functional_change}")
                files_section.append(f"- é£é™©è¯„åˆ†: {risk_score} ({severity})")

                # Add actual diff lines
                diff_lines = hunk.get("lines", [])
                if diff_lines:
                    files_section.append("- å…·ä½“ä¿®æ”¹å†…å®¹:")
                    for diff_line in diff_lines[:20]:  # Limit to first 20 lines
                        line_type = diff_line.get("type")
                        content = diff_line.get("content", "")
                        old_lineno = diff_line.get("old_lineno")
                        new_lineno = diff_line.get("new_lineno")

                        prefix = ""
                        if line_type == "add":
                            prefix = "+"
                        elif line_type == "del":
                            prefix = "-"
                        else:
                            prefix = " "

                        line_info = f"(old:{old_lineno}, new:{new_lineno})" if old_lineno is not None or new_lineno is not None else ""
                        files_section.append(f"  {prefix} {line_info} {content}")

                    if len(diff_lines) > 20:
                        files_section.append(f"  ... (è¿˜æœ‰ {len(diff_lines) - 20} è¡Œä¿®æ”¹)")

                files_section.append("")

        # Add file content with highlighting
        if file_path in hunks_by_file:
            # Find the relevant hunk for highlighting
            file_hunks = hunks_by_file[file_path]
            if file_hunks:
                hunk = file_hunks[0]  # Use first hunk for highlighting
                highlighted_after = format_file_with_diff_highlight(
                    after, hunk.get("lines", []),
                    hunk.get("new_start", 1), hunk.get("new_count", 0)
                )
                files_section.append("### AFTER (ä¿®æ”¹åï¼Œå¸¦ä¿®æ”¹æ ‡è®°):")
                files_section.append(f"```\n{highlighted_after[:3000]}...\n```" if len(highlighted_after) > 3000 else f"```\n{highlighted_after}\n```")
        else:
            files_section.append("### AFTER (ä¿®æ”¹å):")
            files_section.append(f"```\n{after[:2000]}...\n```" if len(after) > 2000 else f"```\n{after}\n```")

        files_section.append("")

    # Build CodeQL results section
    codeql_section = []
    for query in relevant_queries:
        template_id = query.get("template_id")
        if template_id in codeql_results:
            result = codeql_results[template_id]
            codeql_section.append(f"### CodeQL Query: {template_id}")
            codeql_section.append(f"**Why:** {query.get('why', '')}")
            codeql_section.append(f"**Params:** {json.dumps(query.get('params', {}), ensure_ascii=False)}")

            # Include CodeQL results (limit size)
            result_data = result.get("result_data", [])
            if isinstance(result_data, list) and len(result_data) > 10:
                codeql_section.append(f"**Results (showing first 10 of {len(result_data)}):**")
                codeql_section.append(json.dumps(result_data[:10], ensure_ascii=False, indent=2))
            else:
                codeql_section.append(f"**Results:**")
                codeql_section.append(json.dumps(result_data, ensure_ascii=False, indent=2))
            codeql_section.append("")

    prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä»£ç å®‰å…¨å®¡æŸ¥ä¸“å®¶ã€‚è¯·åˆ†æä»¥ä¸‹PRåŠŸèƒ½å˜æ›´æ˜¯å¦å­˜åœ¨å®‰å…¨æ¼æ´ã€‚

## åŠŸèƒ½åˆ†æç›®æ ‡
- **åŠŸèƒ½åç§°**: {feature_name}
- **åŠŸèƒ½æ‘˜è¦**: {feature_summary}
- **ä¸šåŠ¡å½±å“**: {business_impact}
- **å·²çŸ¥é£é™©**: {', '.join(key_risks)}

## ä»£ç å˜æ›´è¯¦æƒ…

{chr(10).join(files_section)}

## CodeQLæŸ¥è¯¢ç»“æœ

{chr(10).join(codeql_section) if codeql_section else "æ— ç›¸å…³CodeQLæŸ¥è¯¢ç»“æœ"}

## åˆ†æè¦æ±‚

è¯·ä»”ç»†åˆ†æä¸Šè¿°ä»£ç å˜æ›´å’ŒCodeQLæŸ¥è¯¢ç»“æœï¼Œè¯†åˆ«æ˜¯å¦å­˜åœ¨ä»¥ä¸‹ç±»å‹çš„å®‰å…¨é—®é¢˜ï¼š
1. **å¹¶å‘å®‰å…¨é—®é¢˜** - æ•°æ®ç«äº‰ã€æ­»é”ã€æ¡ä»¶ç«äº‰ç­‰
2. **é€»è¾‘é”™è¯¯** - è¾¹ç•Œæ¡ä»¶ã€é”™è¯¯å¤„ç†ã€çŠ¶æ€ç®¡ç†ç­‰
3. **æ³¨å…¥æ¼æ´** - SQLæ³¨å…¥ã€å‘½ä»¤æ³¨å…¥ã€è·¯å¾„éå†ç­‰
4. **æƒé™æ§åˆ¶** - è®¿é—®æ§åˆ¶ã€æˆæƒç»•è¿‡ç­‰
5. **æ•°æ®å®Œæ•´æ€§** - æ•°æ®æ³„éœ²ã€æ•°æ®ç¯¡æ”¹ç­‰
6. **èµ„æºç®¡ç†** - å†…å­˜æ³„æ¼ã€èµ„æºè€—å°½ç­‰

## é‡è¦ï¼šè¡Œå·å®šä½è¯´æ˜

ä¸Šé¢æä¾›äº†å…·ä½“çš„diffä¿¡æ¯ï¼ŒåŒ…å«ï¼š
- **ç²¾ç¡®çš„ä¿®æ”¹è¡Œå·èŒƒå›´** (old_start-old_end â†’ new_start-new_end)
- **é€è¡Œä¿®æ”¹è¯¦æƒ…** (æ˜¾ç¤ºæ¯è¡Œæ˜¯æ·»åŠ "+"ã€åˆ é™¤"-"è¿˜æ˜¯ä¿æŒ" ")
- **æ ‡è®°äº†ä¿®æ”¹çš„ä»£ç ** (ä½¿ç”¨[MODIFIED]æ ‡è®°)

## è¾“å‡ºæ ¼å¼è¦æ±‚

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºåˆ†æç»“æœï¼š

{{
  "vulnerability_found": true/false,
  "vulnerability_summary": "ç®€è¦æ€»ç»“å‘ç°çš„ä¸»è¦é—®é¢˜",
  "vulnerabilities": [
    {{
      "type": "é—®é¢˜ç±»å‹",
      "severity": "critical/high/medium/low/info",
      "confidence": "high/medium/low",
      "file_path": "æ–‡ä»¶è·¯å¾„",
      "line_number": å…·ä½“è¡Œå·æˆ–èŒƒå›´ï¼ˆå¿…é¡»åŸºäºä¸Šé¢æä¾›çš„diffä¿¡æ¯ï¼‰,
      "description": "è¯¦ç»†é—®é¢˜æè¿°",
      "root_cause": "æ ¹æœ¬åŸå› åˆ†æ",
      "exploit_scenario": "å¯èƒ½çš„åˆ©ç”¨åœºæ™¯",
      "fix_recommendation": "ä¿®å¤å»ºè®®",
      "code_snippet": "é—®é¢˜ä»£ç ç‰‡æ®µ",
      "references_codeql": "ç›¸å…³çš„CodeQLæŸ¥è¯¢ç»“æœ"
    }}
  ],
  "overall_risk_assessment": "æ•´ä½“é£é™©è¯„ä¼°",
  "additional_observations": "å…¶ä»–è§‚å¯Ÿ"
}}

## å…³é”®è¦æ±‚
- **å¿…é¡»ä½¿ç”¨æä¾›çš„diffè¡Œå·ä¿¡æ¯**ï¼Œä¸è¦ä½¿ç”¨-1
- line_numberå¿…é¡»æ˜¯å…·ä½“çš„è¡Œå·æˆ–èŒƒå›´ï¼Œå¦‚42æˆ–45-48
- å¦‚æœæ²¡æœ‰å‘ç°æ¼æ´ï¼Œvulnerabilitiesæ•°ç»„åº”ä¸ºç©º
- code_snippetè¯·åŒ…å«å®é™…çš„é—®é¢˜ä»£ç 
- å¿…é¡»è¾“å‡ºä¸¥æ ¼çš„JSONæ ¼å¼ï¼Œä¸è¦åŒ…å«markdownæ ‡è®°æˆ–é¢å¤–è§£é‡Š
"""

    return prompt


def analyze_feature_vulnerability(
    feature: Dict[str, Any],
    files_content: Dict[str, Tuple[str, str]],
    relevant_queries: List[Dict[str, Any]],
    codeql_results: Dict[str, Any],
    llm: ChatOpenAI,
    feature_index: int,
    total_features: int,
    detailed_hunks: List[Dict[str, Any]]
) -> Dict[str, Any]:
    """Analyze a single feature for vulnerabilities using LLM."""

    feature_id = feature.get("feature_id", "unknown")
    feature_name = feature.get("feature_name", "unknown")
    risk_score = feature.get("risk_overview", {}).get("overall_risk_score", 0)

    logger.info(f"[Vulnerability Analyzer] [{feature_index}/{total_features}] å¼€å§‹åˆ†æåŠŸèƒ½: {feature_id} - {feature_name}")
    logger.info(f"[Vulnerability Analyzer] {feature_id}: é£é™©è¯„åˆ†: {risk_score}, æ¶‰åŠæ–‡ä»¶: {len(files_content)} ä¸ª")
    logger.debug(f"[Vulnerability Analyzer] {feature_id}: ç›¸å…³æŸ¥è¯¢: {len(relevant_queries)} ä¸ª, CodeQLç»“æœ: {len(codeql_results)} ä¸ª")

    safe_print(f"[{feature_index}/{total_features}] Starting analysis: {feature_id} - {feature_name}")

    # è®°å½•è¯¦ç»†çš„åˆ†æè¾“å…¥ä¿¡æ¯
    if os.getenv("ENABLE_DETAILED_LOGS", "false").lower() == "true":
        logger.debug(f"[Vulnerability Analyzer] {feature_id}: åŠŸèƒ½è¯¦æƒ…:")
        logger.debug(f"[Vulnerability Analyzer] {feature_id}:   - æ‘˜è¦: {feature.get('summary', 'N/A')}")
        logger.debug(f"[Vulnerability Analyzer] {feature_id}:   - ä¸šåŠ¡å½±å“: {feature.get('business_impact', 'N/A')}")
        logger.debug(f"[Vulnerability Analyzer] {feature_id}:   - è¯¦ç»†hunks: {len(detailed_hunks)} ä¸ª")
        logger.debug(f"[Vulnerability Analyzer] {feature_id}:   - æ–‡ä»¶åˆ—è¡¨: {list(files_content.keys())}")

        if relevant_queries:
            for i, query in enumerate(relevant_queries[:3]):  # åªè®°å½•å‰3ä¸ªæŸ¥è¯¢
                logger.debug(f"[Vulnerability Analyzer] {feature_id}: æŸ¥è¯¢{i+1}: {query.get('template_id', 'unknown')} - {query.get('why', 'N/A')[:100]}")

    try:
        logger.debug(f"[Vulnerability Analyzer] {feature_id}: æ„å»ºåˆ†æprompt...")
        prompt = build_vulnerability_analysis_prompt(feature, files_content, relevant_queries, codeql_results, detailed_hunks)

        # è®°å½•promptå¤§å°ä¿¡æ¯
        if os.getenv("ENABLE_DETAILED_LOGS", "false").lower() == "true":
            logger.debug(f"[Vulnerability Analyzer] {feature_id}: prompté•¿åº¦: {len(prompt)} å­—ç¬¦")
            prompt_preview = prompt[:1500] + "..." if len(prompt) > 1500 else prompt
            logger.debug(f"[Vulnerability Analyzer] {feature_id}: promptå†…å®¹é¢„è§ˆ:\n{prompt_preview}")

        messages = [
            SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä»£ç å®‰å…¨å®¡æŸ¥ä¸“å®¶ï¼Œä¸“æ³¨äºå‘ç°ä»£ç å˜æ›´ä¸­çš„å®‰å…¨æ¼æ´ã€‚"),
            HumanMessage(content=prompt)
        ]

        logger.debug(f"[Vulnerability Analyzer] {feature_id}: å¼€å§‹è°ƒç”¨LLM...")
        
        # Retry logic for LLM calls with null response handling
        max_retries = 3
        response_text = None
        for attempt in range(max_retries):
            try:
                response = llm.invoke(messages)
                response_text = response.content if hasattr(response, "content") else str(response)
                if response_text:
                    break
            except TypeError as e:
                if "null value for `choices`" in str(e):
                    import time
                    logger.warning(f"[Vulnerability Analyzer] {feature_id}: LLMè¿”å›null choicesï¼Œé‡è¯• {attempt + 1}/{max_retries}")
                    time.sleep(1)
                    continue
                raise
            except Exception as e:
                logger.warning(f"[Vulnerability Analyzer] {feature_id}: LLMè°ƒç”¨å¤±è´¥ï¼Œé‡è¯• {attempt + 1}/{max_retries}: {str(e)}")
                import time
                time.sleep(1)
                continue
        
        if not response_text:
            # Fallback when LLM is unavailable
            logger.warning(f"[Vulnerability Analyzer] {feature_id}: LLMè°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨fallbackç»“æœ")
            return {
                "feature_id": feature.get("feature_id"),
                "feature_name": feature.get("feature_name"),
                "vulnerability_found": False,
                "vulnerability_summary": "LLMæœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œæ— æ³•è¿›è¡Œæ¼æ´åˆ†æ",
                "vulnerabilities": [],
                "overall_risk_assessment": "unknown",
                "additional_observations": "ç”±äºLLM APIè¿”å›ç©ºå“åº”ï¼Œæœ¬æ¬¡åˆ†æè¢«è·³è¿‡",
                "llm_fallback": True,
                "analysis_timestamp": "2025-12-24"
            }

        # è®°å½•LLMå“åº”ä¿¡æ¯
        if os.getenv("ENABLE_DETAILED_LOGS", "false").lower() == "true":
            logger.debug(f"[Vulnerability Analyzer] {feature_id}: LLMå“åº”é•¿åº¦: {len(response_text)} å­—ç¬¦")
            response_preview = response_text[:1000] + "..." if len(response_text) > 1000 else response_text
            logger.debug(f"[Vulnerability Analyzer] {feature_id}: LLMå“åº”é¢„è§ˆ:\n{response_preview}")

        # Try to parse JSON response
        logger.debug(f"[Vulnerability Analyzer] {feature_id}: è§£æJSONå“åº”...")
        try:
            # Clean up response if it contains markdown
            json_start = response_text.find("{")
            json_end = response_text.rfind("}") + 1
            if json_start != -1 and json_end > json_start:
                json_text = response_text[json_start:json_end]
                result = json.loads(json_text)
            else:
                result = json.loads(response_text)

            logger.debug(f"[Vulnerability Analyzer] {feature_id}: JSONè§£ææˆåŠŸ")
        except json.JSONDecodeError as e:
            logger.warning(f"[Vulnerability Analyzer] {feature_id}: JSONè§£æå¤±è´¥ - {str(e)}")
            # Fallback if JSON parsing fails
            result = {
                "vulnerability_found": False,
                "vulnerability_summary": "LLMå“åº”è§£æå¤±è´¥",
                "vulnerabilities": [],
                "overall_risk_assessment": "æ— æ³•è¯„ä¼°",
                "additional_observations": f"LLMåŸå§‹å“åº”: {response_text[:500]}...",
                "parsing_error": True
            }

        # Add metadata
        result["feature_id"] = feature.get("feature_id")
        result["feature_name"] = feature.get("feature_name")
        result["analysis_timestamp"] = "2025-12-21"

        # è®°å½•åˆ†æç»“æœ
        vuln_found = result.get("vulnerability_found", False)
        vuln_count = len(result.get("vulnerabilities", []))

        if vuln_found and vuln_count > 0:
            logger.info(f"[Vulnerability Analyzer] {feature_id}: å‘ç°æ¼æ´ - {vuln_count} ä¸ª")

            # è®°å½•æ¼æ´è¯¦æƒ…ï¼ˆè¯¦ç»†æ—¥å¿—æ¨¡å¼ï¼‰
            if os.getenv("ENABLE_DETAILED_LOGS", "false").lower() == "true":
                for i, vuln in enumerate(result.get("vulnerabilities", [])[:5]):  # æœ€å¤šè®°å½•5ä¸ªæ¼æ´
                    vuln_type = vuln.get("type", "unknown")
                    severity = vuln.get("severity", "unknown")
                    confidence = vuln.get("confidence", "unknown")
                    line_number = vuln.get("line_number", "unknown")
                    file_path = vuln.get("file_path", "unknown")

                    logger.info(f"[Vulnerability Analyzer] {feature_id}: æ¼æ´{i+1}: {vuln_type} ({severity}, {confidence})")
                    logger.info(f"[Vulnerability Analyzer] {feature_id}:   ä½ç½®: {file_path}:{line_number}")
                    logger.debug(f"[Vulnerability Analyzer] {feature_id}:   æè¿°: {vuln.get('description', 'N/A')[:200]}")
        else:
            logger.info(f"[Vulnerability Analyzer] {feature_id}: æœªå‘ç°æ¼æ´")

        safe_print(f"[{feature_index}/{total_features}] Completed: {feature_id} - Vulnerabilities: {vuln_found}, Count: {vuln_count}")

        logger.debug(f"[Vulnerability Analyzer] {feature_id}: åˆ†æå®Œæˆ")
        return result

    except Exception as e:
        logger.error(f"[Vulnerability Analyzer] {feature_id}: åˆ†æè¿‡ç¨‹ä¸­å‡ºé”™ - {str(e)}")
        logger.error(f"[Vulnerability Analyzer] {feature_id}: å¼‚å¸¸è¯¦æƒ…: {traceback.format_exc()}")

        error_result = {
            "vulnerability_found": False,
            "vulnerability_summary": f"åˆ†æè¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}",
            "vulnerabilities": [],
            "overall_risk_assessment": "åˆ†æå¤±è´¥",
            "additional_observations": f"é”™è¯¯: {str(e)}",
            "feature_id": feature.get("feature_id"),
            "feature_name": feature.get("feature_name"),
            "analysis_error": True
        }
        safe_print(f"[{feature_index}/{total_features}] ERROR: {feature_id} - {str(e)}")
        return error_result


def analyze_feature_parallel(args: Tuple[Dict[str, Any], str, Dict[str, Any], Dict[str, Any], Dict[str, Any], int, int, Dict[str, Any], List[Dict[str, Any]]]) -> Dict[str, Any]:
    """
    Parallel analysis function that processes a single feature.
    Args: (feature, pr_dir, relevant_queries, codeql_results, llm_config, feature_index, total_features, diff_ir, detailed_hunks)
    """
    feature, pr_dir, relevant_queries, codeql_results, llm_config, feature_index, total_features, diff_ir, detailed_hunks = args

    # Create LLM instance for this thread
    llm = ChatOpenAI(
        model=llm_config["model"],
        temperature=llm_config["temperature"],
        base_url=llm_config["base_url"],
        api_key=llm_config["api_key"],
    )

    # Extract files content for this feature
    files_content = extract_diff_files_for_feature(feature, pr_dir)

    # Analyze with LLM
    result = analyze_feature_vulnerability(
        feature, files_content, relevant_queries, codeql_results, llm, feature_index, total_features, detailed_hunks
    )

    return result


def analyze_vulnerabilities(
    pr_dir: str,
    feature_risk_plan: Dict[str, Any],
    query_plan: Dict[str, Any],
    codeql_results: Dict[str, Any],
    llm: ChatOpenAI,
    workers: int = 1,
    diff_ir: Optional[Dict[str, Any]] = None
) -> Dict[str, Any]:
    """
    æ‰§è¡Œæ¼æ´åˆ†æ

    Args:
        pr_dir: PRç›®å½•
        feature_risk_plan: åŠŸèƒ½é£é™©è®¡åˆ’
        query_plan: æŸ¥è¯¢è®¡åˆ’
        codeql_results: CodeQLç»“æœ
        llm: è¯­è¨€æ¨¡å‹
        workers: å¹¶è¡Œå·¥ä½œçº¿ç¨‹æ•°
        diff_ir: å·®å¼‚ä¿¡æ¯

    Returns:
        æ¼æ´åˆ†æç»“æœ
    """
    logger.info(f"[Vulnerability Analyzer] å¼€å§‹æ¼æ´åˆ†æ")
    logger.info(f"[Vulnerability Analyzer] PRç›®å½•: {pr_dir}")
    logger.info(f"[Vulnerability Analyzer] å¹¶è¡Œå·¥ä½œçº¿ç¨‹æ•°: {workers}")

    # Load diff_ir if not provided
    if not diff_ir:
        logger.debug(f"[Vulnerability Analyzer] åŠ è½½diff_iræ•°æ®...")
        diff_ir_path = os.path.join(pr_dir, "out", "diff_ir.json")
        try:
            diff_ir = read_json(diff_ir_path)
            logger.debug(f"[Vulnerability Analyzer] æˆåŠŸåŠ è½½diff_ir: {len(diff_ir.get('files', []))} ä¸ªæ–‡ä»¶")
        except Exception as e:
            logger.error(f"[Vulnerability Analyzer] åŠ è½½diff_irå¤±è´¥: {str(e)}")
            diff_ir = {"files": []}

    # LLM configuration
    llm_config = {
        "model": llm.model_name,
        "temperature": llm.temperature,
        "base_url": llm.openai_api_base,
        "api_key": llm.openai_api_key,
    }

    logger.info(f"[Vulnerability Analyzer] LLMæ¨¡å‹: {llm_config['model']}")

    # Analyze each feature
    features = feature_risk_plan.get("features", [])
    total_features = len(features)

    logger.info(f"[Vulnerability Analyzer] å¾…åˆ†æåŠŸèƒ½æ•°: {total_features}")

    if total_features == 0:
        logger.warning(f"[Vulnerability Analyzer] æ²¡æœ‰éœ€è¦åˆ†æçš„åŠŸèƒ½")
        return {
            "analysis_summary": {
                "total_features_analyzed": 0,
                "features_with_vulnerabilities": 0,
                "total_vulnerabilities_found": 0,
            },
            "feature_analyses": []
        }

    # Determine worker count
    if workers <= 1:
        workers = 1
    else:
        workers = min(workers, total_features)

    logger.info(f"[Vulnerability Analyzer] å®é™…ä½¿ç”¨å·¥ä½œçº¿ç¨‹æ•°: {workers}")

    # è®°å½•åŠŸèƒ½æ¦‚è§ˆ
    if os.getenv("ENABLE_DETAILED_LOGS", "false").lower() == "true":
        logger.debug(f"[Vulnerability Analyzer] åŠŸèƒ½åˆ—è¡¨:")
        for i, feature in enumerate(features[:10]):  # æœ€å¤šæ˜¾ç¤º10ä¸ª
            feature_id = feature.get("feature_id", "unknown")
            risk_score = feature.get("risk_overview", {}).get("overall_risk_score", 0)
            hunk_count = len(feature.get("hunks", []))
            logger.debug(f"[Vulnerability Analyzer]   åŠŸèƒ½{i+1}: {feature_id} (é£é™©:{risk_score}, hunk:{hunk_count})")

    safe_print(f"[INFO] Starting vulnerability analysis for {total_features} features using {workers} workers...")

    # Prepare analysis tasks
    logger.debug(f"[Vulnerability Analyzer] å‡†å¤‡åˆ†æä»»åŠ¡...")
    analysis_tasks = []
    total_queries = 0
    total_hunks = 0

    for i, feature in enumerate(features, 1):
        # Find relevant queries for this feature
        relevant_queries = map_queries_to_feature(feature, query_plan)
        total_queries += len(relevant_queries)

        # Get detailed hunks with line numbers for this feature
        detailed_hunks = get_feature_hunks_with_lines(feature, diff_ir)
        total_hunks += len(detailed_hunks)

        feature_id = feature.get("feature_id", "unknown")
        logger.debug(f"[Vulnerability Analyzer] åŠŸèƒ½{feature_id}: {len(relevant_queries)} ä¸ªæŸ¥è¯¢, {len(detailed_hunks)} ä¸ªè¯¦ç»†hunks")

        task_args = (
            feature,
            pr_dir,
            relevant_queries,
            codeql_results,
            llm_config,
            i,
            total_features,
            diff_ir,
            detailed_hunks
        )
        analysis_tasks.append(task_args)

    logger.info(f"[Vulnerability Analyzer] åˆ†æç»Ÿè®¡: æ€»æŸ¥è¯¢={total_queries}, æ€»hunks={total_hunks}")

    all_results = []
    success_count = 0
    error_count = 0
    vulnerability_count = 0

    if workers == 1:
        # Sequential execution
        logger.info(f"[Vulnerability Analyzer] å¼€å§‹ä¸²è¡Œåˆ†æ...")
        safe_print("[INFO] Running sequential analysis...")
        for task_args in analysis_tasks:
            try:
                # For sequential execution, we can pass directly without creating LLM instance
                feature, pr_dir, relevant_queries, codeql_results, llm_config, feature_index, total_features, diff_ir, detailed_hunks = task_args

                logger.debug(f"[Vulnerability Analyzer] ä¸ºåŠŸèƒ½åˆ›å»ºLLMå®ä¾‹: {llm_config['model']}")

                # Create LLM instance for sequential execution
                llm = ChatOpenAI(
                    model=llm_config["model"],
                    temperature=llm_config["temperature"],
                    base_url=llm_config["base_url"],
                    api_key=llm_config["api_key"],
                )

                # Extract files content for this feature
                logger.debug(f"[Vulnerability Analyzer] æå–æ–‡ä»¶å†…å®¹...")
                files_content = extract_diff_files_for_feature(feature, pr_dir)

                # Analyze with LLM
                result = analyze_feature_vulnerability(
                    feature, files_content, relevant_queries, codeql_results, llm, feature_index, total_features, detailed_hunks
                )
                all_results.append(result)

                # ç»Ÿè®¡ç»“æœ
                if result.get("analysis_error"):
                    error_count += 1
                else:
                    success_count += 1
                    if result.get("vulnerability_found", False):
                        vulnerability_count += len(result.get("vulnerabilities", []))

            except Exception as e:
                logger.error(f"[Vulnerability Analyzer] ä¸²è¡Œåˆ†æåŠŸèƒ½å¤±è´¥ - {str(e)}")
                feature = task_args[0]
                error_result = {
                    "vulnerability_found": False,
                    "vulnerability_summary": f"ä¸²è¡Œåˆ†æå¤±è´¥: {str(e)}",
                    "vulnerabilities": [],
                    "overall_risk_assessment": "åˆ†æå¤±è´¥",
                    "additional_observations": f"ä¸²è¡Œåˆ†æé”™è¯¯: {str(e)}",
                    "feature_id": feature.get("feature_id"),
                    "feature_name": feature.get("feature_name"),
                    "analysis_error": True,
                    "sequential_error": True
                }
                all_results.append(error_result)
                error_count += 1
                safe_print(f"[ERROR] Feature {feature.get('feature_id', 'unknown')} failed: {str(e)}")
    else:
        # Parallel execution
        logger.info(f"[Vulnerability Analyzer] å¼€å§‹å¹¶è¡Œåˆ†æ ({workers} å·¥ä½œçº¿ç¨‹)...")
        safe_print(f"[INFO] Running parallel analysis with {workers} workers...")
        with ThreadPoolExecutor(max_workers=workers) as executor:
            # Submit all tasks
            future_to_index = {
                executor.submit(analyze_feature_parallel, task_args): i
                for i, task_args in enumerate(analysis_tasks)
            }

            logger.info(f"[Vulnerability Analyzer] å·²æäº¤ {len(analysis_tasks)} ä¸ªå¹¶è¡Œä»»åŠ¡")

            # Collect results as they complete
            completed_count = 0
            for future in as_completed(future_to_index):
                try:
                    result = future.result()
                    all_results.append(result)
                    completed_count += 1
                    logger.debug(f"[Vulnerability Analyzer] å¹¶è¡Œä»»åŠ¡å®Œæˆ: {completed_count}/{total_features}")
                    safe_print(f"[PROGRESS] Completed {completed_count}/{total_features} features")

                    # ç»Ÿè®¡ç»“æœ
                    if result.get("analysis_error"):
                        error_count += 1
                    else:
                        success_count += 1
                        if result.get("vulnerability_found", False):
                            vulnerability_count += len(result.get("vulnerabilities", []))

                except Exception as e:
                    logger.error(f"[Vulnerability Analyzer] å¹¶è¡Œä»»åŠ¡æ‰§è¡Œå¤±è´¥ - {str(e)}")
                    # Handle failed future
                    original_index = future_to_index[future]
                    feature = analysis_tasks[original_index][0]
                    error_result = {
                        "vulnerability_found": False,
                        "vulnerability_summary": f"å¹¶è¡Œæ‰§è¡Œå¤±è´¥: {str(e)}",
                        "vulnerabilities": [],
                        "overall_risk_assessment": "åˆ†æå¤±è´¥",
                        "additional_observations": f"å¹¶è¡Œæ‰§è¡Œé”™è¯¯: {str(e)}",
                        "feature_id": feature.get("feature_id"),
                        "feature_name": feature.get("feature_name"),
                        "analysis_error": True,
                        "parallel_error": True
                    }
                    all_results.append(error_result)
                    error_count += 1
                    safe_print(f"[ERROR] Feature {original_index} failed: {str(e)}")

        # Sort results by original feature order
        logger.debug(f"[Vulnerability Analyzer] æŒ‰åŸå§‹åŠŸèƒ½é¡ºåºæ’åºç»“æœ...")
        all_results.sort(key=lambda x: features.index(next(f for f in features if f.get("feature_id") == x.get("feature_id"))))

    # Generate final report
    logger.info(f"[Vulnerability Analyzer] ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š...")

    features_with_vulnerabilities = sum(1 for r in all_results if r.get("vulnerability_found", False))
    total_vulnerabilities_found = sum(len(r.get("vulnerabilities", [])) for r in all_results)

    # åˆ†ç±»æ¼æ´åˆ° logic å’Œ security
    logic_vulnerabilities = []
    security_vulnerabilities = []

    for result in all_results:
        for vuln in result.get("vulnerabilities", []):
            vuln_type = vuln.get("type", "")

            # æ ¹æ®æ¼æ´ç±»å‹åˆ†ç±»
            security_keywords = [
                "æ³¨å…¥", "injection", "sql", "xss", "ssrf", "csrf",
                "æƒé™", "permission", "è®¤è¯", "auth", "æˆæƒ",
                "æ•æ„Ÿ", "sensitive", "æ³„éœ²", "leak",
                "ååºåˆ—åŒ–", "deserialize", "unmarshal"
            ]

            logic_keywords = [
                "å¹¶å‘", "concurrent", "æ­»é”", "deadlock", "ç«äº‰", "race",
                "è¾¹ç•Œ", "boundary", "ç©ºå€¼", "null", "èµ„æº", "resource",
                "ç®—æ³•", "algorithm", "çŠ¶æ€", "state"
            ]

            is_security = any(keyword in vuln_type.lower() for keyword in security_keywords)
            is_logic = any(keyword in vuln_type.lower() for keyword in logic_keywords)

            # è½¬æ¢ä¸º Agent çš„ issue æ ¼å¼,å…¼å®¹ _convert_issue_to_inline_comment
            # æ ¼å¼: {result: "ISSUE", issues: [...], _meta: {...}, location: {...}}

            line_number = vuln.get("line_number", 0)

            # Parse line ranges - support multiple discontinuous ranges like "46-47,52-53,60-68"
            line_ranges = []

            if isinstance(line_number, list):
                # List format: [46, 47] or [[46, 47], [52, 53]]
                if len(line_number) > 0 and isinstance(line_number[0], list):
                    # List of ranges: [[46, 47], [52, 53]]
                    # Convert to tuples: [(46, 47), (52, 53)]
                    line_ranges = [(int(r[0]), int(r[1]) if len(r) > 1 else int(r[0])) for r in line_number]
                elif len(line_number) >= 2:
                    # Single range as list: [46, 47]
                    start = int(line_number[0])
                    end = int(line_number[1])
                    line_ranges = [(start, end)]
                else:
                    # Single number as list: [46]
                    num = int(line_number[0]) if len(line_number) > 0 else 0
                    line_ranges = [(num, num)]
            elif isinstance(line_number, str):
                # String format: "46-47,52-53,60-68" or "182-184" or "449"
                try:
                    parts = line_number.split(',')
                    for part in parts:
                        part = part.strip()
                        if '-' in part:
                            # Range like "46-47"
                            start_end = part.split('-')
                            start = int(start_end[0].strip())
                            end = int(start_end[1].strip()) if len(start_end) > 1 else start
                            line_ranges.append((start, end))
                        else:
                            # Single number like "449"
                            num = int(part)
                            line_ranges.append((num, num))
                except (ValueError, IndexError) as e:
                    logger.warning(f"Failed to parse line_number '{line_number}': {e}")
                    line_ranges = [(0, 0)]
            else:
                # Integer format: 46
                try:
                    num = int(line_number)
                    line_ranges = [(num, num)]
                except (ValueError, TypeError):
                    logger.warning(f"Invalid line_number format: {line_number} (type: {type(line_number)})")
                    line_ranges = [(0, 0)]

            # ğŸ†• ä½¿ç”¨ hunk_id æ¥å®šä½ï¼Œè€Œä¸æ˜¯ä¾èµ–ä¸å‡†ç¡®çš„è¡Œå·
            # ä¸ Logic Agent å’Œ Security Agent ä¿æŒä¸€è‡´
            file_path = vuln.get("file_path", "")

            # ä» diff_ir ä¸­æŸ¥æ‰¾åŒ¹é…çš„ hunk_idï¼ˆå”¯ä¸€çœŸæºï¼‰
            matched_hunk_id = ""
            if diff_ir:
                # 1. æŒ‰ file_path æ‰¾åˆ° diff_ir ä¸­å¯¹åº”çš„ file
                diff_files = diff_ir.get("files", [])
                target_file = None
                target_file_idx = None
                for idx, df in enumerate(diff_files):
                    if df.get("file_path") == file_path:
                        target_file = df
                        target_file_idx = idx
                        break

                if target_file:
                    # 2. åœ¨è¯¥æ–‡ä»¶çš„ hunks ä¸­æŸ¥æ‰¾ä¸ line_ranges æœ‰é‡å çš„ hunk
                    hunks = target_file.get("hunks", [])
                    for h_idx, hunk in enumerate(hunks):
                        hunk_id = hunk.get("hunk_id", f"{target_file_idx}:{h_idx}")

                        # è·å– hunk çš„è¡Œå·èŒƒå›´ï¼ˆRIGHT sideï¼‰
                        new_start = hunk.get("new_start", 0)
                        new_count = hunk.get("new_count", 0)
                        hunk_line_start = new_start
                        hunk_line_end = new_start + new_count - 1

                        # æ£€æŸ¥æ˜¯å¦æœ‰ä»»æ„ä¸€ä¸ª line_range ä¸ hunk èŒƒå›´é‡å 
                        has_overlap = False
                        for (line_start, line_end) in line_ranges:
                            # åˆ¤æ–­ä¸¤ä¸ªåŒºé—´æ˜¯å¦é‡å 
                            if not (line_end < hunk_line_start or line_start > hunk_line_end):
                                has_overlap = True
                                break

                        if has_overlap:
                            matched_hunk_id = hunk_id
                            logger.debug(
                                f"[Vulnerability Analyzer] åŒ¹é…åˆ° hunk_id: {hunk_id} "
                                f"for {file_path}:{line_ranges} "
                                f"(hunk range: {hunk_line_start}-{hunk_line_end})"
                            )
                            break

                        # Fallback: å¦‚æœä¸Šé¢çš„é‡å æ£€æµ‹å¤±è´¥ï¼Œå°è¯•ç”¨ hunk.lines[*].new_lineno ç²¾ç¡®åŒ¹é…
                        lines = hunk.get("lines", [])
                        for line in lines:
                            new_lineno = line.get("new_lineno")
                            if new_lineno is not None:
                                for (line_start, line_end) in line_ranges:
                                    if line_start <= new_lineno <= line_end:
                                        matched_hunk_id = hunk_id
                                        logger.debug(
                                            f"[Vulnerability Analyzer] é€šè¿‡ lines åŒ¹é…åˆ° hunk_id: {hunk_id} "
                                            f"for {file_path}:{line_ranges} "
                                            f"(matched line: {new_lineno})"
                                        )
                                        break
                                if matched_hunk_id:
                                    break
                        if matched_hunk_id:
                            break

                    if not matched_hunk_id:
                        logger.warning(
                            f"[Vulnerability Analyzer] æœªæ‰¾åˆ°åŒ¹é…çš„ hunk_id "
                            f"for {file_path}:{line_ranges}"
                        )
                else:
                    logger.warning(
                        f"[Vulnerability Analyzer] åœ¨ diff_ir ä¸­æœªæ‰¾åˆ°æ–‡ä»¶: {file_path}"
                    )
            else:
                logger.warning(
                    f"[Vulnerability Analyzer] diff_ir ä¸ºç©ºï¼Œæ— æ³•æŸ¥æ‰¾ hunk_id"
                )

            converted_issue = {
                "result": "ISSUE",
                "issues": [{  # issues æ•°ç»„,æ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªé—®é¢˜å¯¹è±¡
                    "title": vuln.get("type", "æœªçŸ¥é—®é¢˜"),
                    "severity": vuln.get("severity", "medium"),
                    "confidence": vuln.get("confidence", "medium"),
                    "description": vuln.get("description", ""),
                    "root_cause": vuln.get("root_cause", ""),
                    "fix_recommendation": vuln.get("fix_recommendation", ""),
                    "suggestion": vuln.get("fix_recommendation", ""),  # å…¼å®¹ suggestion å­—æ®µ
                    "category": vuln.get("type", ""),  # æ·»åŠ  category
                    "cwe": []  # AI æ¼æ´åˆ†ææ²¡æœ‰ CWE
                }],
                "_meta": {
                    "hunk_id": matched_hunk_id,
                    "file_path": file_path,
                    "risk_score": result.get("risk_score", 0),
                    "feature_id": result.get("feature_id", ""),
                    "analysis_source": "ai_vulnerability_analysis"
                },
                "tool_evidence": {
                    "summary": {
                        "confidence_score": 70,  # AI åˆ†æé»˜è®¤ç½®ä¿¡åº¦
                        "has_ai_evidence": True
                    },
                    "ai_analysis": {
                        "exploit_scenario": vuln.get("exploit_scenario", ""),
                        "code_snippet": vuln.get("code_snippet", ""),
                        "additional_observations": vuln.get("additional_observations", "")
                    }
                }
            }

            if is_security or not is_logic:  # é»˜è®¤å½’ä¸ºå®‰å…¨é—®é¢˜
                security_vulnerabilities.append(converted_issue)
            else:
                logic_vulnerabilities.append(converted_issue)

    final_report = {
        "analysis_summary": {
            "total_features_analyzed": total_features,
            "features_with_vulnerabilities": features_with_vulnerabilities,
            "total_vulnerabilities_found": total_vulnerabilities_found,
            "logic_vulnerabilities_found": len(logic_vulnerabilities),
            "security_vulnerabilities_found": len(security_vulnerabilities),
            "analysis_timestamp": "2025-12-21",
            "parallel_execution": workers > 1,
            "workers_used": workers
        },
        "pr_identification": query_plan.get("pr_identification", {}),
        "feature_analyses": all_results,
        # ğŸ†• è¿”å›åˆ†ç±»åçš„é—®é¢˜,ç”¨äºåˆå¹¶åˆ° logic_review å’Œ security_review
        "categorized_issues": {
            "logic_issues": logic_vulnerabilities,
            "security_issues": security_vulnerabilities
        }
    }

    # æœ€ç»ˆç»Ÿè®¡æ—¥å¿—
    logger.info(f"[Vulnerability Analyzer] æ¼æ´åˆ†æå®Œæˆç»Ÿè®¡:")
    logger.info(f"[Vulnerability Analyzer]   æ€»åŠŸèƒ½æ•°: {total_features}")
    logger.info(f"[Vulnerability Analyzer]   åˆ†ææˆåŠŸ: {success_count}")
    logger.info(f"[Vulnerability Analyzer]   åˆ†æå¤±è´¥: {error_count}")
    logger.info(f"[Vulnerability Analyzer]   æœ‰æ¼æ´åŠŸèƒ½: {features_with_vulnerabilities}")
    logger.info(f"[Vulnerability Analyzer]   å‘ç°æ¼æ´æ€»æ•°: {total_vulnerabilities_found}")

    # æ¼æ´ä¸¥é‡ç¨‹åº¦ç»Ÿè®¡
    if total_vulnerabilities_found > 0:
        severity_counts = {"critical": 0, "high": 0, "medium": 0, "low": 0, "info": 0}
        type_counts = {}

        for result in all_results:
            for vuln in result.get("vulnerabilities", []):
                severity = vuln.get("severity", "unknown")
                vuln_type = vuln.get("type", "unknown")

                if severity in severity_counts:
                    severity_counts[severity] += 1
                type_counts[vuln_type] = type_counts.get(vuln_type, 0) + 1

        logger.info(f"[Vulnerability Analyzer] æ¼æ´ä¸¥é‡ç¨‹åº¦åˆ†å¸ƒ: {severity_counts}")
        if type_counts:
            logger.info(f"[Vulnerability Analyzer] æ¼æ´ç±»å‹åˆ†å¸ƒ: {dict(list(type_counts.items())[:10])}")  # æœ€å¤šæ˜¾ç¤º10ç§ç±»å‹

    return final_report