"""
ä»£ç å·¥å…·é›† - æ›¿æ¢MCPçš„ç›´æ¥importå®ç°
ç”¨äºåœ¨å·¥ä½œæµä¸­è¿›è¡Œä»£ç åˆ†æå’Œå®¡è®¡
"""

import os
import re
import subprocess
import shlex
import json
import glob
import time
from typing import Any, Dict, List, Optional, Tuple
from pathlib import Path
from langchain_core.tools import tool


def load_config() -> dict:
    """åŠ è½½é¡¹ç›®æ ¹ç›®å½•çš„é…ç½®æ–‡ä»¶"""
    config_path = Path(__file__).parent.parent.parent.parent / "config.json"  # ä» src/scripts/core/ å‘ä¸Š4çº§åˆ°é¡¹ç›®æ ¹ç›®å½•

    if not config_path.exists():
        print(f"âš ï¸ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
        return {}

    try:
        with open(config_path, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception as e:
        print(f"âš ï¸ åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {str(e)}")
        return {}


class CodeTools:
    """ä»£ç å·¥å…·é›†åˆ - ç›´æ¥importå®ç°"""

    def __init__(self, base_dirs: List[str], enable_logging: bool = True, remote_repo=None):
        """
        åˆå§‹åŒ–ä»£ç å·¥å…·

        Args:
            base_dirs: åŸºç¡€æœç´¢ç›®å½•åˆ—è¡¨
            enable_logging: æ˜¯å¦å¯ç”¨å·¥å…·è°ƒç”¨æ—¥å¿—
            remote_repo: å¯é€‰çš„è¿œç¨‹ä»“åº“æä¾›è€… (ZReadRepoProvider å®ä¾‹)
        """
        self.base_dirs = [Path(d).resolve() for d in base_dirs if isinstance(d, str)]
        self.enable_logging = enable_logging
        self.remote_repo = remote_repo
        self.tool_call_stats = {
            "total_calls": 0,
            "read_file_calls": 0,
            "search_code_calls": 0,
            "find_function_calls": 0,
            "get_file_structure_calls": 0,
            "analyze_file_changes_calls": 0,
            "calls_by_time": []
        }

        if self.enable_logging:
            print("ğŸ› ï¸ ä»£ç å·¥å…·å·²åˆå§‹åŒ–")
            print(f"ğŸ“ åŸºç¡€ç›®å½•: {[str(p) for p in self.base_dirs]}")
            if self.remote_repo:
                print(f"ğŸŒ è¿œç¨‹ä»“åº“å·²å¯ç”¨: {self.remote_repo.repo_full_name}")
            print("ğŸ“Š å·¥å…·è°ƒç”¨æ—¥å¿—å·²å¯ç”¨")

    def _log_tool_call(self, tool_name: str, args: Dict[str, Any], start_time: float, success: bool, result_info: Dict[str, Any] = None):
        """è®°å½•å·¥å…·è°ƒç”¨æ—¥å¿—"""
        if not self.enable_logging:
            return

        duration = time.time() - start_time
        status = "âœ…" if success else "âŒ"

        self.tool_call_stats["total_calls"] += 1
        self.tool_call_stats[f"{tool_name}_calls"] += 1
        self.tool_call_stats["calls_by_time"].append({
            "tool": tool_name,
            "timestamp": time.time(),
            "duration": duration,
            "success": success,
            "args_summary": {k: str(v)[:50] for k, v in args.items() if k not in ["content", "large_data"]}
        })

        print(f"\n{status} è°ƒç”¨å·¥å…·: {tool_name}")
        print(f"â±ï¸  è€—æ—¶: {duration:.3f}ç§’")
        print(f"ğŸ“ å‚æ•°: {json.dumps({k: str(v)[:50] for k, v in args.items() if k not in ['content', 'large_data']}, ensure_ascii=False)}")

        if result_info:
            print(f"ğŸ“Š ç»“æœ: {json.dumps(result_info, ensure_ascii=False)}")

        # ä¿æŒæœ€è¿‘100æ¡è°ƒç”¨è®°å½•
        if len(self.tool_call_stats["calls_by_time"]) > 100:
            self.tool_call_stats["calls_by_time"] = self.tool_call_stats["calls_by_time"][-100:]

    def get_tool_call_stats(self) -> Dict[str, Any]:
        """è·å–å·¥å…·è°ƒç”¨ç»Ÿè®¡ä¿¡æ¯"""
        return {
            "statistics": self.tool_call_stats.copy(),
            "average_call_time": sum(call["duration"] for call in self.tool_call_stats["calls_by_time"]) / max(1, len(self.tool_call_stats["calls_by_time"])),
            "success_rate": sum(1 for call in self.tool_call_stats["calls_by_time"] if call["success"]) / max(1, len(self.tool_call_stats["calls_by_time"])) * 100
        }

    def print_tool_call_summary(self):
        """æ‰“å°å·¥å…·è°ƒç”¨æ±‡æ€»"""
        if not self.enable_logging:
            return

        stats = self.get_tool_call_stats()

        print(f"\nğŸ“Š ä»£ç å·¥å…·è°ƒç”¨æ±‡æ€»:")
        print(f"  æ€»è°ƒç”¨æ¬¡æ•°: {stats['statistics']['total_calls']}")
        print(f"  å¹³å‡è€—æ—¶: {stats['average_call_time']:.3f}ç§’")
        print(f"  æˆåŠŸç‡: {stats['success_rate']:.1f}%")
        print(f"  read_file: {stats['statistics']['read_file_calls']}æ¬¡")
        print(f"  search_code: {stats['statistics']['search_code_calls']}æ¬¡")
        print(f"  find_function: {stats['statistics']['find_function_calls']}æ¬¡")
        print(f"  get_file_structure: {stats['statistics']['get_file_structure_calls']}æ¬¡")
        print(f"  analyze_file_changes: {stats['statistics']['analyze_file_changes_calls']}æ¬¡")


# åˆ›å»ºlangchainå·¥å…·è£…é¥°å™¨å®ä¾‹
code_tools_instance = None

def initialize_code_tools(base_dirs: List[str], enable_logging: bool = True) -> CodeTools:
    """åˆå§‹åŒ–ä»£ç å·¥å…·å®ä¾‹"""
    global code_tools_instance
    code_tools_instance = CodeTools(base_dirs, enable_logging)
    return code_tools_instance


@tool
def read_file(file_path: str, start_line: Optional[int] = None, end_line: Optional[int] = None) -> Dict[str, Any]:
    """
    è¯»å–æŒ‡å®šæ–‡ä»¶å†…å®¹

    Args:
        file_path: æ–‡ä»¶è·¯å¾„
        start_line: å¼€å§‹è¡Œå·ï¼ˆå¯é€‰ï¼‰
        end_line: ç»“æŸè¡Œå·ï¼ˆå¯é€‰ï¼‰

    Returns:
        åŒ…å«æ–‡ä»¶å†…å®¹å’Œå…ƒæ•°æ®çš„å­—å…¸
    """
    if not code_tools_instance:
        return {"success": False, "error": "ä»£ç å·¥å…·æœªåˆå§‹åŒ–"}

    return code_tools_instance.read_file(file_path, start_line, end_line)


@tool
def search_code(pattern: str, file_pattern: str = "*", case_sensitive: bool = False, max_results: int = 50) -> Dict[str, Any]:
    """
    åœ¨ä»£ç ä¸­æœç´¢æŒ‡å®šæ¨¡å¼

    Args:
        pattern: æœç´¢æ¨¡å¼ï¼ˆæ­£åˆ™è¡¨è¾¾å¼ï¼‰
        file_pattern: æ–‡ä»¶åæ¨¡å¼ï¼ˆå¦‚ "*.py"ï¼‰
        case_sensitive: æ˜¯å¦åŒºåˆ†å¤§å°å†™
        max_results: æœ€å¤§ç»“æœæ•°é‡

    Returns:
        åŒ…å«æœç´¢ç»“æœçš„å­—å…¸
    """
    if not code_tools_instance:
        return {"success": False, "error": "ä»£ç å·¥å…·æœªåˆå§‹åŒ–"}

    return code_tools_instance.search_code(pattern, file_pattern, case_sensitive, max_results)


@tool
def find_function(function_name: str, file_pattern: str = "*.py", include_context: bool = True, context_lines: int = 5) -> Dict[str, Any]:
    """
    æŸ¥æ‰¾æŒ‡å®šå‡½æ•°çš„å®šä¹‰å’Œè°ƒç”¨

    Args:
        function_name: å‡½æ•°å
        file_pattern: æ–‡ä»¶åæ¨¡å¼
        include_context: æ˜¯å¦åŒ…å«ä¸Šä¸‹æ–‡
        context_lines: ä¸Šä¸‹æ–‡è¡Œæ•°

    Returns:
        åŒ…å«å‡½æ•°æŸ¥æ‰¾ç»“æœçš„å­—å…¸
    """
    if not code_tools_instance:
        return {"success": False, "error": "ä»£ç å·¥å…·æœªåˆå§‹åŒ–"}

    return code_tools_instance.find_function(function_name, file_pattern, include_context, context_lines)


@tool
def get_file_structure(directory: str, max_depth: int = 3) -> Dict[str, Any]:
    """
    è·å–ç›®å½•ç»“æ„

    Args:
        directory: ç›®å½•è·¯å¾„
        max_depth: æœ€å¤§æ·±åº¦

    Returns:
        åŒ…å«ç›®å½•ç»“æ„çš„å­—å…¸
    """
    if not code_tools_instance:
        return {"success": False, "error": "ä»£ç å·¥å…·æœªåˆå§‹åŒ–"}

    return code_tools_instance.get_file_structure(directory, max_depth)


@tool
def analyze_file_changes(file_path: str, diff_hunks: List[Dict[str, Any]]) -> Dict[str, Any]:
    """
    åˆ†ææ–‡ä»¶å˜æ›´

    Args:
        file_path: æ–‡ä»¶è·¯å¾„
        diff_hunks: diff hunksåˆ—è¡¨

    Returns:
        åŒ…å«å˜æ›´åˆ†æçš„å­—å…¸
    """
    if not code_tools_instance:
        return {"success": False, "error": "ä»£ç å·¥å…·æœªåˆå§‹åŒ–"}

    return code_tools_instance.analyze_file_changes(file_path, diff_hunks)


@tool
def run_command(command: str, working_dir: Optional[str] = None, timeout: int = 30) -> Dict[str, Any]:
    """
    æ‰§è¡Œshellå‘½ä»¤

    Args:
        command: è¦æ‰§è¡Œçš„å‘½ä»¤
        working_dir: å·¥ä½œç›®å½•ï¼ˆå¯é€‰ï¼‰
        timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰

    Returns:
        åŒ…å«å‘½ä»¤æ‰§è¡Œç»“æœçš„å­—å…¸
    """
    start_time = time.time()

    try:
        # è§£æå‘½ä»¤
        if isinstance(command, str):
            cmd_args = shlex.split(command)
        else:
            cmd_args = command

        # æ‰§è¡Œå‘½ä»¤
        result = subprocess.run(
            cmd_args,
            cwd=working_dir,
            capture_output=True,
            text=True,
            timeout=timeout,
            shell=False
        )

        duration = time.time() - start_time

        return {
            "success": result.returncode == 0,
            "return_code": result.returncode,
            "stdout": result.stdout,
            "stderr": result.stderr,
            "duration": duration,
            "command": command,
            "working_dir": working_dir
        }

    except subprocess.TimeoutExpired:
        return {
            "success": False,
            "error": f"å‘½ä»¤æ‰§è¡Œè¶…æ—¶ ({timeout}ç§’)",
            "command": command,
            "working_dir": working_dir,
            "timeout": True
        }
    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "command": command,
            "working_dir": working_dir
        }


@tool
def grep_files(pattern: str, file_paths: List[str], case_sensitive: bool = False, context_lines: int = 0) -> Dict[str, Any]:
    """
    åœ¨æŒ‡å®šæ–‡ä»¶åˆ—è¡¨ä¸­æœç´¢æ¨¡å¼

    Args:
        pattern: æœç´¢æ¨¡å¼
        file_paths: æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        case_sensitive: æ˜¯å¦åŒºåˆ†å¤§å°å†™
        context_lines: ä¸Šä¸‹æ–‡è¡Œæ•°

    Returns:
        åŒ…å«æœç´¢ç»“æœçš„å­—å…¸
    """
    start_time = time.time()
    results = []
    flags = 0 if case_sensitive else re.IGNORECASE

    try:
        for file_path in file_paths:
            if not os.path.exists(file_path):
                continue

            try:
                with open(file_path, 'r', encoding='utf-8', errors='replace') as f:
                    lines = f.readlines()

                file_matches = []
                for line_num, line in enumerate(lines, 1):
                    if re.search(pattern, line, flags):
                        match_info = {
                            "line_number": line_num,
                            "content": line.strip(),
                            "match": re.search(pattern, line, flags).group()
                        }

                        # æ·»åŠ ä¸Šä¸‹æ–‡
                        if context_lines > 0:
                            context_start = max(1, line_num - context_lines)
                            context_end = min(len(lines), line_num + context_lines)
                            match_info["context"] = {
                                "before": [lines[i-1].strip() for i in range(context_start, line_num)],
                                "after": [lines[i-1].strip() for i in range(line_num + 1, context_end + 1)]
                            }

                        file_matches.append(match_info)

                if file_matches:
                    results.append({
                        "file_path": file_path,
                        "matches": file_matches,
                        "total_matches": len(file_matches)
                    })

            except Exception as e:
                results.append({
                    "file_path": file_path,
                    "error": str(e),
                    "matches": []
                })

        duration = time.time() - start_time

        return {
            "success": True,
            "pattern": pattern,
            "files_searched": len(file_paths),
            "total_matches": sum(r.get("total_matches", 0) for r in results),
            "duration": duration,
            "results": results
        }

    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "pattern": pattern,
            "results": []
        }


# å°†CodeToolsæ–¹æ³•æ·»åŠ åˆ°ç±»ä¸­
def _add_methods_to_code_tools():
    """å°†å·¥å…·å‡½æ•°æ·»åŠ åˆ°CodeToolsç±»ä¸­"""

    def read_file(self, file_path: str, start_line: Optional[int] = None,
                  end_line: Optional[int] = None) -> Dict[str, Any]:
        start_time = time.time()
        args = {"file_path": file_path, "start_line": start_line, "end_line": end_line}

        try:
            # å°è¯•åœ¨åŸºç¡€ç›®å½•ä¸­æŸ¥æ‰¾æ–‡ä»¶
            full_path = None
            for base_dir in self.base_dirs:
                candidate_path = base_dir / file_path
                if candidate_path.exists():
                    full_path = candidate_path
                    break

            if not full_path:
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ï¼Œå°è¯•ç»å¯¹è·¯å¾„
                candidate_path = Path(file_path)
                if candidate_path.exists():
                    full_path = candidate_path

            if not full_path:
                # ğŸ†• å¦‚æœé…ç½®äº†è¿œç¨‹ä»“åº“ï¼Œå°è¯•ä»è¿œç¨‹è¯»å–
                if self.remote_repo:
                    try:
                        remote_result = self.remote_repo.read_file(file_path)
                        if remote_result.get("success"):
                            self._log_tool_call("read_file", args, start_time, True, {
                                "file_found": True,
                                "source": "remote",
                                "content_lines": remote_result.get("total_lines", 0)
                            })
                            return remote_result
                    except Exception as e:
                        print(f"âš ï¸ è¿œç¨‹è¯»å–å¤±è´¥: {str(e)}")

                return {
                    "success": False,
                    "error": f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}",
                    "content": ""
                }

            with open(full_path, 'r', encoding='utf-8', errors='replace') as f:
                lines = f.readlines()

            # å¤„ç†è¡Œå·èŒƒå›´
            if start_line is not None or end_line is not None:
                start = max(1, start_line or 1)
                end = min(len(lines), end_line or len(lines))
                lines = lines[start-1:end]

            content = ''.join(lines)

            result = {
                "success": True,
                "file_path": str(full_path),
                "content": content,
                "total_lines": len(open(full_path, 'r', encoding='utf-8').readlines()),
                "showed_lines": len(lines),
                "start_line": start_line or 1,
                "end_line": end_line or len(lines),
                "file_size": os.path.getsize(full_path)
            }

            result_info = {
                "file_found": True,
                "content_lines": result["showed_lines"],
                "file_size_kb": round(result["file_size"] / 1024, 2)
            }

            self._log_tool_call("read_file", args, start_time, True, result_info)
            return result

        except Exception as e:
            result = {
                "success": False,
                "error": f"è¯»å–æ–‡ä»¶å¤±è´¥: {str(e)}",
                "content": ""
            }
            self._log_tool_call("read_file", args, start_time, False, {"error": str(e)})
            return result

    def search_code(self, pattern: str, file_pattern: str = "*",
                   case_sensitive: bool = False, max_results: int = 50) -> Dict[str, Any]:
        start_time = time.time()
        args = {"pattern": pattern, "file_pattern": file_pattern, "case_sensitive": case_sensitive, "max_results": max_results}

        try:
            results = []
            flags = 0 if case_sensitive else re.IGNORECASE

            for base_dir in self.base_dirs:
                # æŸ¥æ‰¾åŒ¹é…çš„æ–‡ä»¶
                file_pattern_path = base_dir / "**" / file_pattern
                files = glob.glob(str(file_pattern_path), recursive=True)

                for file_path in files[:max_results // 2]:  # é™åˆ¶æ¯ä¸ªç›®å½•çš„æ–‡ä»¶æ•°
                    try:
                        with open(file_path, 'r', encoding='utf-8', errors='replace') as f:
                            lines = f.readlines()

                        file_results = []
                        for line_num, line in enumerate(lines, 1):
                            if re.search(pattern, line, flags):
                                file_results.append({
                                    "line_number": line_num,
                                    "content": line.strip(),
                                    "match": re.search(pattern, line, flags).group()
                                })

                        if file_results:
                            results.append({
                                "file_path": os.path.relpath(file_path, base_dir),
                                "absolute_path": file_path,
                                "matches": file_results,
                                "total_matches": len(file_results)
                            })

                    except Exception:
                        continue

            # æŒ‰åŒ¹é…æ•°é‡æ’åº
            results.sort(key=lambda x: x["total_matches"], reverse=True)

            result = {
                "success": True,
                "pattern": pattern,
                "file_pattern": file_pattern,
                "total_files_searched": len(results),
                "total_matches": sum(r["total_matches"] for r in results),
                "results": results[:max_results]
            }

            result_info = {
                "files_searched": result["total_files_searched"],
                "total_matches": result["total_matches"],
                "results_returned": len(result["results"])
            }

            self._log_tool_call("search_code", args, start_time, True, result_info)
            return result

        except Exception as e:
            result = {
                "success": False,
                "error": f"æœç´¢å¤±è´¥: {str(e)}",
                "results": []
            }
            self._log_tool_call("search_code", args, start_time, False, {"error": str(e)})
            return result

    def find_function(self, function_name: str, file_pattern: str = "*.py",
                     include_context: bool = True, context_lines: int = 5) -> Dict[str, Any]:
        start_time = time.time()
        args = {"function_name": function_name, "file_pattern": file_pattern, "include_context": include_context, "context_lines": context_lines}

        results = {
            "definitions": [],
            "calls": [],
            "function_name": function_name
        }

        try:
            # æœç´¢å‡½æ•°å®šä¹‰
            definition_pattern = rf"def\s+{re.escape(function_name)}\s*\("
            search_result = self.search_code(
                definition_pattern, file_pattern, case_sensitive=True
            )

            if search_result["success"]:
                for file_result in search_result["results"]:
                    for match in file_result["matches"]:
                        # è·å–å‡½æ•°å®šä¹‰çš„å®Œæ•´å†…å®¹
                        if include_context:
                            file_content = self.read_file(
                                file_result["file_path"],
                                start_line=max(1, match["line_number"] - context_lines),
                                end_line=match["line_number"] + context_lines
                            )

                            if file_content["success"]:
                                results["definitions"].append({
                                    "file_path": file_result["file_path"],
                                    "line_number": match["line_number"],
                                    "content": match["content"],
                                    "context": file_content["content"]
                                })
                        else:
                            results["definitions"].append({
                                "file_path": file_result["file_path"],
                                "line_number": match["line_number"],
                                "content": match["content"]
                            })

            # æœç´¢å‡½æ•°è°ƒç”¨
            call_pattern = rf"{re.escape(function_name)}\s*\("
            search_result = self.search_code(
                call_pattern, file_pattern, case_sensitive=True
            )

            if search_result["success"]:
                for file_result in search_result["results"]:
                    for match in file_result["matches"]:
                        # æ’é™¤å‡½æ•°å®šä¹‰æœ¬èº«
                        is_definition = any(
                            d["file_path"] == file_result["file_path"] and
                            d["line_number"] == match["line_number"]
                            for d in results["definitions"]
                        )

                        if not is_definition:
                            if include_context:
                                file_content = self.read_file(
                                    file_result["file_path"],
                                    start_line=max(1, match["line_number"] - 2),
                                    end_line=match["line_number"] + 2
                                )

                                if file_content["success"]:
                                    results["calls"].append({
                                        "file_path": file_result["file_path"],
                                        "line_number": match["line_number"],
                                        "content": match["content"],
                                        "context": file_content["content"]
                                    })
                            else:
                                results["calls"].append({
                                    "file_path": file_result["file_path"],
                                    "line_number": match["line_number"],
                                    "content": match["content"]
                                })

            result = {
                "success": True,
                "function_name": function_name,
                "definitions_found": len(results["definitions"]),
                "calls_found": len(results["calls"]),
                **results
            }

            result_info = {
                "definitions_found": result["definitions_found"],
                "calls_found": result["calls_found"],
                "function_name": function_name
            }

            self._log_tool_call("find_function", args, start_time, True, result_info)
            return result

        except Exception as e:
            result = {
                "success": False,
                "error": f"æŸ¥æ‰¾å‡½æ•°å¤±è´¥: {str(e)}",
                "function_name": function_name,
                "definitions": [],
                "calls": []
            }
            self._log_tool_call("find_function", args, start_time, False, {"error": str(e)})
            return result

    def get_file_structure(self, directory: str, max_depth: int = 3) -> Dict[str, Any]:
        start_time = time.time()
        args = {"directory": directory, "max_depth": max_depth}

        try:
            target_dir = None
            for base_dir in self.base_dirs:
                candidate_path = base_dir / directory
                if candidate_path.exists() and candidate_path.is_dir():
                    target_dir = candidate_path
                    break

            if not target_dir:
                candidate_path = Path(directory)
                if candidate_path.exists() and candidate_path.is_dir():
                    target_dir = candidate_path

            if not target_dir:
                # ğŸ†• å¦‚æœé…ç½®äº†è¿œç¨‹ä»“åº“ï¼Œå°è¯•ä»è¿œç¨‹è·å–
                if self.remote_repo:
                    try:
                        remote_result = self.remote_repo.get_repo_structure(directory)
                        if remote_result.get("success"):
                            self._log_tool_call("get_file_structure", args, start_time, True, {
                                "directory_found": True,
                                "source": "remote",
                                "directory": directory
                            })
                            return remote_result
                    except Exception as e:
                        print(f"âš ï¸ è¿œç¨‹è·å–ç»“æ„å¤±è´¥: {str(e)}")

                return {
                    "success": False,
                    "error": f"ç›®å½•ä¸å­˜åœ¨: {directory}",
                    "structure": {}
                }

            def build_structure(path: Path, current_depth: int = 0) -> Dict[str, Any]:
                if current_depth > max_depth:
                    return {"type": "directory", "name": path.name, "children": "truncated"}

                structure = {
                    "type": "directory" if path.is_dir() else "file",
                    "name": path.name,
                    "path": str(path.relative_to(target_dir))
                }

                if path.is_dir():
                    try:
                        children = []
                        for item in sorted(path.iterdir()):
                            if not item.name.startswith('.'):  # éšè—æ–‡ä»¶
                                child_structure = build_structure(item, current_depth + 1)
                                children.append(child_structure)

                        if children:
                            structure["children"] = children
                    except PermissionError:
                        structure["children"] = "permission_denied"

                if path.is_file():
                    try:
                        structure["size"] = path.stat().st_size
                        structure["extension"] = path.suffix
                    except:
                        pass

                return structure

            result = {
                "success": True,
                "directory": str(target_dir),
                "structure": build_structure(target_dir),
                "max_depth": max_depth
            }

            result_info = {
                "directory_found": True,
                "max_depth": max_depth,
                "directory": str(target_dir)
            }

            self._log_tool_call("get_file_structure", args, start_time, True, result_info)
            return result

        except Exception as e:
            result = {
                "success": False,
                "error": f"è·å–ç›®å½•ç»“æ„å¤±è´¥: {str(e)}",
                "structure": {}
            }
            self._log_tool_call("get_file_structure", args, start_time, False, {"error": str(e)})
            return result

    def analyze_file_changes(self, file_path: str, diff_hunks: List[Dict[str, Any]]) -> Dict[str, Any]:
        start_time = time.time()
        args = {"file_path": file_path, "diff_hunks_count": len(diff_hunks)}

        try:
            # è¯»å–å½“å‰æ–‡ä»¶å†…å®¹
            current_file = self.read_file(file_path)

            if not current_file["success"]:
                result = {
                    "success": False,
                    "error": f"æ— æ³•è¯»å–æ–‡ä»¶: {file_path}",
                    "analysis": {}
                }
                self._log_tool_call("analyze_file_changes", args, start_time, False, {"error": str(result["error"])})
                return result

            current_lines = current_file["content"].split('\n')

            analysis = {
                "file_path": file_path,
                "total_lines": len(current_lines),
                "hunks_analyzed": len(diff_hunks),
                "changes": []
            }

            for hunk in diff_hunks:
                hunk_analysis = {
                    "hunk_id": hunk.get("hunk_id"),
                    "old_range": f"{hunk.get('old_start', 0)}-{hunk.get('old_start', 0) + hunk.get('old_count', 0) - 1}",
                    "new_range": f"{hunk.get('new_start', 0)}-{hunk.get('new_start', 0) + hunk.get('new_count', 0) - 1}",
                    "changes_in_file": []
                }

                # æŸ¥æ‰¾å½“å‰æ–‡ä»¶ä¸­å¯¹åº”çš„å˜æ›´è¡Œ
                new_start = hunk.get("new_start", 0)
                new_count = hunk.get("new_count", 0)

                if new_start > 0 and new_count > 0:
                    end_line = min(new_start + new_count - 1, len(current_lines))
                    for line_num in range(new_start, end_line + 1):
                        if line_num <= len(current_lines):
                            line_content = current_lines[line_num - 1].strip()
                            hunk_analysis["changes_in_file"].append({
                                "line_number": line_num,
                                "content": line_content
                            })

                analysis["changes"].append(hunk_analysis)

            result = {
                "success": True,
                "analysis": analysis
            }

            result_info = {
                "analysis_completed": True,
                "hunks_analyzed": len(diff_hunks),
                "changes_found": len(analysis["changes"])
            }

            self._log_tool_call("analyze_file_changes", args, start_time, True, result_info)
            return result

        except Exception as e:
            result = {
                "success": False,
                "error": f"åˆ†ææ–‡ä»¶å˜æ›´å¤±è´¥: {str(e)}",
                "analysis": {}
            }
            self._log_tool_call("analyze_file_changes", args, start_time, False, {"error": str(e)})
            return result

    # å°†æ–¹æ³•æ·»åŠ åˆ°ç±»ä¸­
    CodeTools.read_file = read_file
    CodeTools.search_code = search_code
    CodeTools.find_function = find_function
    CodeTools.get_file_structure = get_file_structure
    CodeTools.analyze_file_changes = analyze_file_changes


_add_methods_to_code_tools()


def create_code_tools_for_workflow(
    pr_dir: str,
    metadata: Optional[Dict[str, Any]] = None,
    codebase_path: Optional[str] = None
) -> CodeTools:
    """
    ä¸ºå·¥ä½œæµåˆ›å»ºä»£ç å·¥å…·å®ä¾‹

    Args:
        pr_dir: PRç›®å½•è·¯å¾„
        metadata: PRå…ƒæ•°æ®ï¼ŒåŒ…å«base_branchå’Œbase_shaä¿¡æ¯
        codebase_path: å…‹éš†çš„æºä»£ç è·¯å¾„ï¼ˆä¼˜å…ˆä½¿ç”¨ï¼‰

    Returns:
        CodeToolså®ä¾‹
    """
    base_dirs = []
    remote_repo = None

    # ğŸ†• å°è¯•åˆå§‹åŒ–è¿œç¨‹ä»“åº“æä¾›è€…
    repo_full_name = None

    # ä¼˜å…ˆä»ç¯å¢ƒå˜é‡è¯»å–
    if os.getenv("ZREAD_MCP_ENABLED", "false").lower() == "true":
        repo_full_name = os.getenv("ZREAD_REPO_FULL_NAME")

    # å¦‚æœç¯å¢ƒå˜é‡æ²¡æœ‰ï¼Œå°è¯•ä» metadata æ¨æ–­
    if not repo_full_name and metadata:
        # ç›´æ¥ä» metadata è·å– repo_full_name
        repo_full_name = metadata.get("repo_full_name")

        # å°è¯•ä» owner/repo ç»„åˆ
        if not repo_full_name:
            owner = metadata.get("owner")
            repo = metadata.get("repo")
            if owner and repo:
                repo_full_name = f"{owner}/{repo}"

        # å°è¯•ä» clone_url è§£æ
        if not repo_full_name:
            clone_url = metadata.get("clone_url")
            if clone_url:
                # è§£æ GitHub URL: https://github.com/owner/repo.git
                if "github.com/" in clone_url:
                    parts = clone_url.split("github.com/")[-1].rstrip("/")
                    repo_full_name = parts.replace(".git", "")

    # å¦‚æœè·å–åˆ°äº† repo_full_nameï¼Œåˆ›å»ºè¿œç¨‹ä»“åº“æä¾›è€…
    if repo_full_name:
        try:
            from .zread_mcp import create_zread_provider
            remote_repo = create_zread_provider(repo_full_name)
            if remote_repo:
                print(f"ğŸŒ è¿œç¨‹ä»“åº“å·²å¯ç”¨: {repo_full_name}")
        except ImportError as e:
            print(f"âš ï¸ æ— æ³•å¯¼å…¥ ZRead MCP: {str(e)}")
        except Exception as e:
            print(f"âš ï¸ åˆå§‹åŒ–è¿œç¨‹ä»“åº“å¤±è´¥: {str(e)}")

    # ğŸ†• ä¼˜å…ˆä½¿ç”¨app.pyä¼ é€’çš„codebase_path
    if codebase_path:
        codebase = Path(codebase_path).resolve()
        if codebase.exists() and codebase.is_dir():
            base_dirs = [str(codebase)]
            print(f"ğŸ“ ä½¿ç”¨app.pyä¼ é€’çš„å…‹éš†è·¯å¾„ä½œä¸ºæœç´¢æ ¹ç›®å½•: {codebase}")
            return CodeTools(base_dirs, remote_repo=remote_repo)
        else:
            print(f"âš ï¸ codebase_pathä¸å­˜åœ¨ï¼Œä½¿ç”¨fallbacké€»è¾‘: {codebase}")

    # ç›´æ¥ä½¿ç”¨branchç›®å½•ä½œä¸ºå”¯ä¸€çš„æœç´¢æ ¹ç›®å½•
    if metadata and metadata.get("base_branch"):
        base_branch = metadata.get("base_branch")
        base_sha = metadata.get("base_sha")

        # ä»é…ç½®æ–‡ä»¶è¯»å–å¿«ç…§åŸºç¡€è·¯å¾„
        config = load_config()
        repository_config = config.get("repository", {})
        base_branches_path = repository_config.get("base_branches_path")

        if not base_branches_path:
            # Fallback to PR directory if config not found
            print("âš ï¸ é…ç½®æ–‡ä»¶ä¸­æœªæ‰¾åˆ°base_branches_pathé…ç½®ï¼Œä½¿ç”¨PRç›®å½•ä½œä¸ºfallback")
            base_dirs = [str(Path(pr_dir).resolve())]
        else:
            # æ„å»ºbranchç›®å½•è·¯å¾„
            branch_path = Path(base_branches_path) / base_branch

            if branch_path.exists() and branch_path.is_dir():
                base_dirs = [str(branch_path)]  # åªä½¿ç”¨branchç›®å½•ä½œä¸ºæœç´¢æ ¹ç›®å½•
                print(f"ğŸ“ ä½¿ç”¨åˆ†æ”¯ç›®å½•ä½œä¸ºæœç´¢æ ¹ç›®å½•: {branch_path}")
                print(f"ğŸ”— åˆ†æ”¯: {base_branch} (SHA: {base_sha[:8] if base_sha else 'unknown'})")
            else:
                print(f"âŒ åˆ†æ”¯ç›®å½•ä¸å­˜åœ¨: {branch_path}")
                # å¦‚æœbranchç›®å½•ä¸å­˜åœ¨ï¼Œä½¿ç”¨PRç›®å½•ä½œä¸ºfallback
                base_dirs = [str(Path(pr_dir).resolve())]
                print(f"ğŸ“ Fallbackåˆ°PRç›®å½•: {pr_dir}")
    else:
        print("âš ï¸ æœªæ‰¾åˆ°base_branchä¿¡æ¯ï¼Œä½¿ç”¨PRç›®å½•")
        base_dirs = [str(Path(pr_dir).resolve())]

    return CodeTools(base_dirs, remote_repo=remote_repo)