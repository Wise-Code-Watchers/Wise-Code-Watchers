"""
Security Agent (Enhanced) - å·¥å…·å¢å¼ºç‰ˆå®‰å…¨æ¼æ´å®¡è®¡ä¸“ç”¨Agent
åŸºäºå·¥å…·æ”¶é›†çš„è¯æ®è¿›è¡Œå®‰å…¨åˆ†æï¼Œå¤§å¹…é™ä½è¯¯æŠ¥ç‡
"""

import json
import logging
import os
import traceback
from typing import Any, Dict, List, Optional

from langchain_core.messages import SystemMessage, HumanMessage
from langchain_openai import ChatOpenAI

from ..prompts.prompt import SECURITY_AGENT_SYSTEM_V2, format_security_agent_prompt_v2
from ..scripts.scanning.security_tooling import create_security_tooling
from ..analysis.hunk_index import build_hunk_index, select_security_targets, build_audit_unit_from_hunk
from ..analysis.security_validator import validate_security_issues_batch

logger = logging.getLogger(__name__)


def _safe_json_loads(text: str) -> Dict[str, Any]:
    """å®‰å…¨åœ°ä»æ¨¡å‹è¾“å‡ºä¸­æå–JSON"""
    text = text.strip()
    if text.startswith("```json"):
        start = text.find('{')
        end = text.rfind('}')
        if start != -1 and end != -1 and end > start:
            return json.loads(text[start:end+1])
    elif text.startswith("{") and text.endswith("}"):
        return json.loads(text)
    else:
        l = text.find("{")
        r = text.rfind("}")
        if l != -1 and r != -1 and r > l:
            return json.loads(text[l:r+1])
    raise json.JSONDecodeError("no json object", text, 0)


def _match_semgrep_findings_to_unit(audit_unit: Dict[str, Any],
                                    template_findings: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """
    æŒ‰åŠŸèƒ½å—åŒ¹é… Semgrep è¯æ®åˆ°å®¡è®¡å•å…ƒ

    åŒ¹é…è§„åˆ™:
    1. ç›¸åŒæ–‡ä»¶è·¯å¾„ (file_path)
    2. è¡Œå·èŒƒå›´é‡å  (modified_lines ä¸ Semgrep findings çš„ line_start/line_end)
    3. å¯é€‰: ç›¸åŒåŠŸèƒ½å (feature_name)

    Args:
        audit_unit: å®¡è®¡å•å…ƒ
        template_findings: Semgrep æ‰«æå‘ç°åˆ—è¡¨

    Returns:
        åŒ¹é…çš„ Semgrep å‘ç°åˆ—è¡¨
    """
    unit_file = audit_unit.get("file_path", "")
    unit_feature = audit_unit.get("feature_name", "")

    # è·å–ä¿®æ”¹çš„è¡Œå·èŒƒå›´
    modified_lines = audit_unit.get("code_context", {}).get("modified_lines", [])
    if not modified_lines:
        return []

    unit_line_min = min(modified_lines)
    unit_line_max = max(modified_lines)

    matched_findings = []

    for finding in template_findings:
        finding_file = finding.get("file_path", "")

        # è§„åˆ™1: æ–‡ä»¶è·¯å¾„å¿…é¡»åŒ¹é…
        if finding_file != unit_file:
            continue

        # è§„åˆ™2: è¡Œå·èŒƒå›´å¿…é¡»é‡å 
        finding_line_start = finding.get("line_start", 0)
        finding_line_end = finding.get("line_end", finding_line_start)

        # æ£€æŸ¥æ˜¯å¦æœ‰é‡å 
        if not (finding_line_end < unit_line_min or finding_line_start > unit_line_max):
            # æœ‰é‡å ,åŒ¹é…æˆåŠŸ
            matched_findings.append(finding)

    logger.debug(f"[_match_semgrep] å•å…ƒ {audit_unit.get('hunk_id')}: "
                f"æ–‡ä»¶={unit_file}, è¡Œ={unit_line_min}-{unit_line_max}, "
                f"åŒ¹é…={len(matched_findings)}/{len(template_findings)}")

    return matched_findings


def _looks_like_security_surface(diff_text: str) -> bool:
    """
    åˆå§‹åŒ–/é¢„è¿‡æ»¤ï¼šå°½é‡åªæŒ‘å¯èƒ½æ¶‰åŠå®‰å…¨é¢çš„æ”¹åŠ¨ï¼Œå‡å°‘è€—æ—¶ä¸è¯¯æŠ¥ã€‚
    """
    s = (diff_text or "").lower()
    keywords = [
        "auth", "jwt", "token", "session", "cookie", "bearer",
        "permission", "rbac", "acl", "role", "admin",
        "sql", "query", "where", "select", "insert", "update", "delete",
        "exec", "eval", "system(", "popen", "runtime.exec", "subprocess",
        "deserialize", "pickle", "yaml.load", "unmarshal", "marshal",
        "http://", "https://", "url", "redirect", "callback",
        "ssrf", "upload", "multipart", "filename", "path", "../",
        "template", "render", "jinja", "freemarker", "thymeleaf",
        "secret", "apikey", "password", "credential", "private_key",
        "cors", "csrf", "xss"
    ]
    return any(k in s for k in keywords)


def _build_enhanced_security_audit_units(feature_risk_plan: Dict[str, Any],
                                        diff_ir: Dict[str, Any],
                                        pr_dir: str,
                                        risk_threshold: int = 55,
                                        max_units: int = 10,
                                        codebase_path: Optional[str] = None) -> List[Dict[str, Any]]:
    """
    ä½¿ç”¨æ–°çš„hunkç´¢å¼•ç³»ç»Ÿæ„å»ºå·¥å…·å¢å¼ºå®‰å…¨å®¡è®¡å•å…ƒã€‚
    è§£å†³å­—æ®µä¸åŒ¹é…é—®é¢˜ï¼Œç¡®ä¿Agentèƒ½æ‰¾åˆ°å®¡è®¡å•å…ƒã€‚
    """
    logger.info(f"[Enhanced Security Agent] å¼€å§‹æ„å»ºå·¥å…·å¢å¼ºå®‰å…¨å®¡è®¡å•å…ƒï¼Œé£é™©é˜ˆå€¼: {risk_threshold}, æœ€å¤§å•å…ƒæ•°: {max_units}")

    # åˆ›å»ºå®‰å…¨å·¥å…·å®ä¾‹ï¼ˆä¼ é€’codebase_pathï¼‰
    security_tooling = create_security_tooling(pr_dir, feature_risk_plan, codebase_path)

    # æ„å»ºhunkç´¢å¼• - å»ºç«‹feature_risk_planä¸diff_irä¹‹é—´çš„æ˜ å°„
    logger.info("[Enhanced Security Agent] æ„å»ºhunkç´¢å¼•æ˜ å°„")
    hunk_index = build_hunk_index(diff_ir)
    logger.info(f"[Enhanced Security Agent] ç´¢å¼•æ„å»ºå®Œæˆï¼Œå…± {len(hunk_index)} ä¸ªhunks")

    # é€‰æ‹©Security Agentçš„ç›®æ ‡hunks
    logger.info("[Enhanced Security Agent] é€‰æ‹©Security Agentç›®æ ‡hunks")
    security_targets = select_security_targets(
        feature_risk_plan=feature_risk_plan,
        risk_threshold=risk_threshold,
        max_units=max_units
    )

    logger.info(f"[Enhanced Security Agent] é€‰æ‹©äº† {len(security_targets)} ä¸ªå®‰å…¨ç›®æ ‡hunks")

    if not security_targets:
        logger.warning("[Enhanced Security Agent] æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„å®‰å…¨ç›®æ ‡hunks")
        return []

    units: List[Dict[str, Any]] = []
    total_targets = len(security_targets)
    processed_targets = 0
    skipped_targets = 0

    for target_info in security_targets:
        hunk_id = target_info.get("hunk_id")
        if not hunk_id:
            skipped_targets += 1
            logger.debug("[Enhanced Security Agent] è·³è¿‡target: æ— hunk_id")
            continue

        # ä»ç´¢å¼•ä¸­è·å–hunkè¯¦æƒ…
        hunk_detail = hunk_index.get(hunk_id)
        if not hunk_detail:
            skipped_targets += 1
            logger.warning(f"[Enhanced Security Agent] hunk_id {hunk_id} åœ¨ç´¢å¼•ä¸­ä¸å­˜åœ¨")
            continue

        processed_targets += 1
        file_path = hunk_detail.get("file_path")
        risk_score = target_info.get("risk_score", 0)
        selection_reason = target_info.get("reason", "unknown")

        logger.debug(f"[Enhanced Security Agent] å¤„ç†ç›®æ ‡ {processed_targets}/{total_targets}: {hunk_id} "
                    f"(æ–‡ä»¶: {file_path}, åˆ†æ•°: {risk_score}, åŸå› : {selection_reason})")

        try:
            # ä½¿ç”¨hunk_indexä¸­çš„å‡½æ•°æ„å»ºå®¡è®¡å•å…ƒ
            audit_unit = build_audit_unit_from_hunk(
                hunk_id=hunk_id,
                hunk=hunk_detail,
                code_tools=security_tooling.code_tools,
                target_info=target_info
            )

            # å¢åŠ å®‰å…¨ç›¸å…³çš„éªŒè¯
            hunk_text = audit_unit.get("diff_hunk", "")
            if not _looks_like_security_surface(hunk_text):
                logger.debug(f"[Enhanced Security Agent] {hunk_id}: æœªå‘½ä¸­å®‰å…¨å…³é”®å­—ï¼Œä½†ç»§ç»­å¤„ç†ï¼ˆåŸºäºé£é™©åˆ†æé€‰æ‹©ï¼‰")

            units.append(audit_unit)
            logger.info(f"[{len(units)}/{max_units}] å·²åˆ›å»ºå·¥å…·å¢å¼ºå®‰å…¨å®¡è®¡å•å…ƒ: {hunk_id} "
                       f"(é£é™©åˆ†æ•°: {risk_score}, é€‰æ‹©åŸå› : {selection_reason})")

            if len(units) >= max_units:
                logger.info(f"[Enhanced Security Agent] è¾¾åˆ°æœ€å¤§å•å…ƒæ•°é™åˆ¶: {max_units}")
                break

        except Exception as e:
            skipped_targets += 1
            logger.error(f"[Enhanced Security Agent] æ„å»ºå®¡è®¡å•å…ƒå¤±è´¥ {hunk_id}: {str(e)}")
            continue

    logger.info(f"[Enhanced Security Agent] å·¥å…·å¢å¼ºå®‰å…¨å®¡è®¡å•å…ƒæ„å»ºå®Œæˆ")
    logger.info(f"[Enhanced Security Agent] æ€»ç›®æ ‡: {total_targets}, å¤„ç†æˆåŠŸ: {processed_targets}, è·³è¿‡: {skipped_targets}")
    logger.info(f"[Enhanced Security Agent] æœ€ç»ˆç”Ÿæˆå•å…ƒ: {len(units)}")

    return units


def run_enhanced_security_agent_for_pr(pr_dir: str,
                                      diff_ir: Dict[str, Any],
                                      feature_risk_plan: Dict[str, Any],
                                      llm: ChatOpenAI,
                                      risk_threshold: int = 55,
                                      max_units: int = 10,
                                      template_findings: List[Dict[str, Any]] = None,
                                      codebase_path: Optional[str] = None) -> Dict[str, Any]:
    """
    PR çº§å·¥å…·å¢å¼ºå®‰å…¨å®¡è®¡å…¥å£ï¼šæŒ‘é€‰å®‰å…¨ç›¸å…³ hunks -> å·¥å…·é¢„æ”¶é›†è¯æ® -> LLMåˆ†æ -> æ±‡æ€»ç»“æœ

    Args:
        template_findings: Semgrep æ‰«æå‘ç°åˆ—è¡¨ (æŒ‰åŠŸèƒ½å—åˆ†ç»„)
        codebase_path: å…‹éš†çš„æºä»£ç è·¯å¾„ï¼ˆä¼˜å…ˆä½¿ç”¨ï¼‰
    """
    logger.info(f"[Enhanced Security Agent] å¼€å§‹PRçº§å·¥å…·å¢å¼ºå®‰å…¨æ¼æ´å®¡è®¡")
    logger.info(f"[Enhanced Security Agent] å‚æ•°: é£é™©é˜ˆå€¼={risk_threshold}, æœ€å¤§å•å…ƒ={max_units}")

    # ğŸ†• è®°å½• Semgrep è¯æ®
    if template_findings:
        logger.info(f"[Enhanced Security Agent] æ”¶åˆ° {len(template_findings)} ä¸ª Semgrep å‘ç°")
    else:
        logger.info(f"[Enhanced Security Agent] æ—  Semgrep è¯æ®")

    audit_units = _build_enhanced_security_audit_units(
        feature_risk_plan=feature_risk_plan,
        diff_ir=diff_ir,
        pr_dir=pr_dir,
        risk_threshold=risk_threshold,
        max_units=max_units,
        codebase_path=codebase_path
    )

    if not audit_units:
        logger.info("[Enhanced Security Agent] æ²¡æœ‰éœ€è¦åˆ†æçš„å®‰å…¨å®¡è®¡å•å…ƒ")
        return {
            "success": True,
            "units_analyzed": 0,
            "issues_found": 0,
            "issues": [],
            "raw_results": [],
            "errors": [],
            "tool_evidence_summary": {
                "total_units": 0,
                "with_entrypoint": 0,
                "with_call_chain": 0,
                "with_framework_routes": 0,
                "with_context": 0
            }
        }

    logger.info(f"[Enhanced Security Agent] å¼€å§‹é€ä¸ªåˆ†æ {len(audit_units)} ä¸ªå·¥å…·å¢å¼ºå®‰å…¨å®¡è®¡å•å…ƒ")

    # åˆ›å»ºå®‰å…¨å·¥å…·å®ä¾‹ï¼ˆä¼ é€’codebase_pathï¼‰
    security_tooling = create_security_tooling(pr_dir, feature_risk_plan, codebase_path)

    results: List[Dict[str, Any]] = []
    errors: List[str] = []
    success_count = 0
    no_issue_count = 0
    issue_count = 0
    downgraded_count = 0  # è¯æ®ä¸å®Œæ•´è¢«é™çº§çš„æ•°é‡

    # å·¥å…·è¯æ®ç»Ÿè®¡
    tool_evidence_stats = {
        "total_units": len(audit_units),
        "with_entrypoint": 0,
        "with_call_chain": 0,
        "with_framework_routes": 0,
        "with_context": 0
    }

    for i, unit in enumerate(audit_units, 1):
        hunk_id = unit.get("hunk_id", "unknown")
        file_path = unit.get("file_path", "unknown")
        risk_score = unit.get("risk_score", 0)
        symbol_name = unit.get("symbol_name", "")
        modified_lines = unit.get("code_context", {}).get("modified_lines", [])
        feature_name = unit.get("feature_name", "")  # ğŸ†• è·å–åŠŸèƒ½å

        logger.info(f"[Enhanced Security Agent] [{i}/{len(audit_units)}] åˆ†æhunk: {hunk_id} (æ–‡ä»¶: {file_path}, åˆ†æ•°: {risk_score}, ç¬¦å·: {symbol_name})")

        # ğŸ†• æŒ‰åŠŸèƒ½å—åŒ¹é… Semgrep è¯æ®
        unit_semgrep_findings = []
        if template_findings:
            unit_semgrep_findings = _match_semgrep_findings_to_unit(
                unit, template_findings
            )
            if unit_semgrep_findings:
                logger.info(f"[Enhanced Security Agent] {hunk_id}: åŒ¹é…åˆ° {len(unit_semgrep_findings)} ä¸ª Semgrep å‘ç°")

        try:
            # ğŸ”§ ç¬¬ä¸€æ­¥ï¼šå·¥å…·é¢„æ”¶é›†è¯æ®
            tool_evidence = security_tooling.system_collect_evidence(
                file_path=file_path,
                symbol_name=symbol_name,
                modified_lines=modified_lines
            )

            # æ›´æ–°å·¥å…·è¯æ®ç»Ÿè®¡
            if tool_evidence.get("summary", {}).get("has_entrypoint"):
                tool_evidence_stats["with_entrypoint"] += 1
            if tool_evidence.get("summary", {}).get("has_call_chain"):
                tool_evidence_stats["with_call_chain"] += 1
            if tool_evidence.get("summary", {}).get("has_framework_routes"):
                tool_evidence_stats["with_framework_routes"] += 1
            if tool_evidence.get("summary", {}).get("related_context"):
                tool_evidence_stats["with_context"] += 1

            # è®°å½•å·¥å…·æ”¶é›†çš„è¯æ®ï¼ˆä»…åœ¨è¯¦ç»†æ—¥å¿—æ¨¡å¼ï¼‰
            if os.getenv("ENABLE_DETAILED_LOGS", "false").lower() == "true":
                logger.debug(f"[Enhanced Security Agent] {hunk_id}: å·¥å…·è¯æ®ç½®ä¿¡åº¦: {tool_evidence.get('summary', {}).get('confidence_score', 0)}/100")
                logger.debug(f"[Enhanced Security Agent] {hunk_id}: å…¥å£ç‚¹è¯æ®: {len(tool_evidence.get('entrypoint_evidence', []))}")
                logger.debug(f"[Enhanced Security Agent] {hunk_id}: è°ƒç”¨é“¾è¯æ®: {tool_evidence.get('call_chain_evidence', {}).get('has_chain', False)}")
                logger.debug(f"[Enhanced Security Agent] {hunk_id}: æ¡†æ¶è·¯ç”±è¯æ®: {len(tool_evidence.get('framework_evidence', []))}")
                logger.debug(f"[Enhanced Security Agent] {hunk_id}: ä¸Šä¸‹æ–‡è¯æ®: {len(tool_evidence.get('context_evidence', []))}")

            # ğŸ”§ ç¬¬äºŒæ­¥ï¼šåŸºäºå·¥å…·è¯æ®è¿›è¡ŒLLMåˆ†æ
            # ğŸ†• æ³¨å…¥ Semgrep è¯æ®
            prompt = format_security_agent_prompt_v2(
                unit, tool_evidence, semgrep_findings=unit_semgrep_findings
            )
            messages = [
                SystemMessage(content=SECURITY_AGENT_SYSTEM_V2),
                HumanMessage(content=prompt)
            ]

            # åªåœ¨å¯ç”¨è¯¦ç»†æ—¥å¿—æ—¶è®°å½•LLMäº¤äº’
            if os.getenv("ENABLE_DETAILED_LOGS", "false").lower() == "true":
                logger.debug(f"[Enhanced Security Agent] {hunk_id}: å¼€å§‹å·¥å…·å¢å¼ºLLMè°ƒç”¨")
                logger.debug(f"[Enhanced Security Agent] {hunk_id}: è¾“å…¥prompté•¿åº¦: {len(prompt)} å­—ç¬¦")

                # è®°å½•å®Œæ•´çš„è¾“å…¥ï¼ˆæˆªæ–­è¿‡é•¿å†…å®¹ï¼‰
                prompt_preview = prompt[:1000] + "..." if len(prompt) > 1000 else prompt
                logger.debug(f"[Enhanced Security Agent] {hunk_id}: LLMè¾“å…¥:\n{prompt_preview}")

            # Retry logic for LLM calls with null response handling
            max_retries = 3
            text = None
            for attempt in range(max_retries):
                try:
                    resp = llm.invoke(messages)
                    text = resp.content if hasattr(resp, "content") else str(resp)
                    if text:
                        break
                except TypeError as e:
                    if "null value for `choices`" in str(e):
                        import time
                        logger.warning(f"[Enhanced Security Agent] {hunk_id}: LLMè¿”å›null choicesï¼Œé‡è¯• {attempt + 1}/{max_retries}")
                        time.sleep(1)
                        continue
                    raise
                except Exception as e:
                    logger.warning(f"[Enhanced Security Agent] {hunk_id}: LLMè°ƒç”¨å¤±è´¥ï¼Œé‡è¯• {attempt + 1}/{max_retries}: {str(e)}")
                    import time
                    time.sleep(1)
                    continue
            
            if not text:
                # Fallback when LLM is unavailable
                logger.warning(f"[Enhanced Security Agent] {hunk_id}: LLMè°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨fallbackç»“æœ")
                success_count += 1
                no_issue_count += 1
                continue

            # åªåœ¨å¯ç”¨è¯¦ç»†æ—¥å¿—æ—¶è®°å½•LLMè¾“å‡º
            if os.getenv("ENABLE_DETAILED_LOGS", "false").lower() == "true":
                logger.debug(f"[Enhanced Security Agent] {hunk_id}: LLMè¾“å‡ºé•¿åº¦: {len(text)} å­—ç¬¦")

                # è®°å½•å®Œæ•´çš„è¾“å‡ºï¼ˆæˆªæ–­è¿‡é•¿å†…å®¹ï¼‰
                output_preview = text[:2000] + "..." if len(text) > 2000 else text
                logger.debug(f"[Enhanced Security Agent] {hunk_id}: LLMè¾“å‡º:\n{output_preview}")

            obj = _safe_json_loads(text)

            # è½»é‡æ ¡éªŒï¼šå¿…é¡»æœ‰ result å­—æ®µ
            if obj.get("result") not in ("NO_ISSUE", "ISSUE"):
                logger.warning(f"[Enhanced Security Agent] {hunk_id}: è¾“å‡ºæ ¼å¼æ— æ•ˆï¼Œè®¾ç½®ä¸ºNO_ISSUE")
                logger.warning(f"[Enhanced Security Agent] {hunk_id}: æ— æ•ˆè¾“å‡ºå†…å®¹: {obj}")
                obj = {"result": "NO_ISSUE", "issue": None, "need_context": ["model_output_schema_invalid"]}
                success_count += 1
                no_issue_count += 1

            # å¦‚æœæ¨¡å‹æŠ¥ ISSUEï¼Œä½†å·¥å…·è¯æ®ä¸è¶³æˆ–ç¼ºå°‘å¿…è¦å­—æ®µï¼Œé™çº§ä¸º NO_ISSUE
            elif obj.get("result") == "ISSUE":
                issue = obj.get("issue") or {}
                required_fields = ["entrypoint", "data_flow", "impact", "sink", "evidence"]
                missing_fields = [field for field in required_fields if not issue.get(field)]

                # ğŸ”§ æ–°å¢ï¼šå·¥å…·è¯æ®å……åˆ†æ€§æ£€æŸ¥
                tool_evidence_summary = tool_evidence.get("summary", {})
                has_sufficient_evidence = (
                    tool_evidence_summary.get("has_entrypoint", False) and
                    tool_evidence_summary.get("has_call_chain", False) and
                    tool_evidence_summary.get("confidence_score", 0) >= 50  # ç½®ä¿¡åº¦é˜ˆå€¼
                )

                if missing_fields or not has_sufficient_evidence:
                    reason = []
                    if missing_fields:
                        reason.append(f"ç¼ºå°‘å­—æ®µ: {missing_fields}")
                    if not has_sufficient_evidence:
                        reason.append(f"å·¥å…·è¯æ®ä¸è¶³ (ç½®ä¿¡åº¦: {tool_evidence_summary.get('confidence_score', 0)})")

                    logger.warning(f"[Enhanced Security Agent] {hunk_id}: è¯æ®ä¸å……åˆ†ï¼Œé™çº§ä¸ºNO_ISSUE - {', '.join(reason)}")
                    if os.getenv("ENABLE_DETAILED_LOGS", "false").lower() == "true":
                        logger.debug(f"[Enhanced Security Agent] {hunk_id}: è¯æ®å……åˆ†æ€§æ£€æŸ¥å¤±è´¥:\n" + json.dumps({
                            "missing_fields": missing_fields,
                            "tool_evidence_summary": tool_evidence_summary,
                            "has_sufficient_evidence": has_sufficient_evidence,
                            "issue": issue
                        }, indent=2, ensure_ascii=False))

                    obj = {
                        "result": "NO_ISSUE",
                        "issue": None,
                        "need_context": [f"insufficient_evidence: {', '.join(reason)}"]
                    }
                    success_count += 1
                    no_issue_count += 1
                    downgraded_count += 1
                else:
                    issue_title = issue.get("title", "æœªçŸ¥å®‰å…¨æ¼æ´")
                    issue_severity = issue.get("severity", "unknown")
                    issue_cwe = issue.get("cwe", [])
                    confidence_score = tool_evidence_summary.get("confidence_score", 0)
                    logger.info(f"[Enhanced Security Agent] {hunk_id}: å‘ç°å®‰å…¨æ¼æ´ - {issue_title} ({issue_severity}, CWE: {issue_cwe}, å·¥å…·è¯æ®ç½®ä¿¡åº¦: {confidence_score})")

                    # è¯¦ç»†è®°å½•å‘ç°çš„æ¼æ´
                    if os.getenv("ENABLE_DETAILED_LOGS", "false").lower() == "true":
                        logger.debug(f"[Enhanced Security Agent] {hunk_id}: æ¼æ´è¯¦æƒ…:\n" + json.dumps(issue, indent=2, ensure_ascii=False))

                        # è®°å½•å¢å¼ºçš„è¯æ®ä¸‰è¦ç´ 
                        entrypoint = issue.get("entrypoint", "")
                        data_flow = issue.get("data_flow", "")
                        impact = issue.get("impact", "")
                        sink = issue.get("sink", "")
                        rationale = issue.get("analysis", {}).get("rationale", "")

                        logger.debug(f"[Enhanced Security Agent] {hunk_id}: å¢å¼ºè¯æ®ä¸‰è¦ç´ :")
                        logger.debug(f"[Enhanced Security Agent] {hunk_id}:   æ”»å‡»å…¥å£: {entrypoint}")
                        logger.debug(f"[Enhanced Security Agent] {hunk_id}:   æ•°æ®æµå‘: {data_flow}")
                        logger.debug(f"[Enhanced Security Agent] {hunk_id}:   å®‰å…¨å½±å“: {impact}")
                        logger.debug(f"[Enhanced Security Agent] {hunk_id}:   å±é™©ç‚¹: {sink}")
                        logger.debug(f"[Enhanced Security Agent] {hunk_id}:   åˆ†æä¾æ®: {rationale}")

                    success_count += 1
                    issue_count += 1
            else:
                logger.debug(f"[Enhanced Security Agent] {hunk_id}: æ— å®‰å…¨é—®é¢˜")
                need_context = obj.get("need_context", [])
                if need_context and os.getenv("ENABLE_DETAILED_LOGS", "false").lower() == "true":
                    logger.debug(f"[Enhanced Security Agent] {hunk_id}: éœ€è¦æ›´å¤šä¸Šä¸‹æ–‡: {need_context}")
                success_count += 1
                no_issue_count += 1

            # æŒ‚ä¸Šå®šä½ä¿¡æ¯å’Œå·¥å…·è¯æ®ï¼Œæ–¹ä¾¿æœ€ç»ˆæŠ¥å‘Šå‘ˆç°
            obj["_meta"] = {
                "hunk_id": hunk_id,
                "file_path": file_path,
                "risk_score": risk_score,
                "symbol_name": symbol_name
            }
            obj["tool_evidence"] = tool_evidence  # ğŸš€ é™„åŠ å®Œæ•´å·¥å…·è¯æ®
            results.append(obj)

        except Exception as e:
            error_msg = f"hunk_id={hunk_id} error={str(e)}"
            logger.error(f"[Enhanced Security Agent] {hunk_id}: åˆ†æå¤±è´¥ - {str(e)}")
            logger.error(f"[Enhanced Security Agent] {hunk_id}: å¼‚å¸¸è¯¦æƒ…: {traceback.format_exc()}")
            errors.append(error_msg)

    issues = [r for r in results if r.get("result") == "ISSUE"]
    raw_issues = [r.get("issue", {}) for r in issues]

    # ğŸ”§ æ–°å¢ï¼šä½¿ç”¨ä¸¥æ ¼æ ¡éªŒå™¨è¿‡æ»¤issues
    logger.info(f"[Enhanced Security Agent] å¼€å§‹æ ¡éªŒ {len(raw_issues)} ä¸ªå®‰å…¨issueçš„è¯æ®é“¾å®Œæ•´æ€§")

    # æ„å»ºhunkç´¢å¼•ç”¨äºæ ¡éªŒ
    hunk_index = build_hunk_index(diff_ir)

    # æ‰§è¡Œæ‰¹é‡æ ¡éªŒ
    validation_result = validate_security_issues_batch(
        issues=raw_issues,
        hunk_index=hunk_index
    )

    valid_issues = validation_result["valid_issues"]
    rejected_issues = validation_result["rejected_issues"]
    validation_summary = validation_result["validation_summary"]

    # è®°å½•æ ¡éªŒç»“æœ
    logger.info(f"[Enhanced Security Agent] æ ¡éªŒå®Œæˆ:")
    logger.info(f"[Enhanced Security Agent]   è¾“å…¥issues: {validation_summary['total_input']}")
    logger.info(f"[Enhanced Security Agent]   é€šè¿‡æ ¡éªŒ: {validation_summary['valid_count']}")
    logger.info(f"[Enhanced Security Agent]   è¢«æ‹’ç»: {validation_summary['rejected_count']}")
    logger.info(f"[Enhanced Security Agent]   æ‹’ç»ç‡: {validation_summary['rejection_rate']:.1f}%")

    # è®°å½•æ‹’ç»åŸå› ç»Ÿè®¡
    if validation_summary["rejection_reasons_count"]:
        logger.info("[Enhanced Security Agent] ä¸»è¦æ‹’ç»åŸå› :")
        for reason, count in sorted(validation_summary["rejection_reasons_count"].items(), key=lambda x: x[1], reverse=True)[:5]:
            logger.info(f"[Enhanced Security Agent]   {reason}: {count}æ¬¡")

    # è¯¦ç»†è®°å½•è¢«æ‹’ç»çš„issuesï¼ˆä»…åœ¨è¯¦ç»†æ—¥å¿—æ¨¡å¼ï¼‰
    if os.getenv("ENABLE_DETAILED_LOGS", "false").lower() == "true" and rejected_issues:
        logger.debug("[Enhanced Security Agent] è¢«æ‹’ç»çš„issuesè¯¦æƒ…:")
        for rejected in rejected_issues[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
            reasons = rejected.get("reasons", [])
            logger.debug(f"[Enhanced Security Agent]   Issue {rejected.get('index')}: {', '.join(reasons)}")

    # å°†é€šè¿‡æ ¡éªŒçš„issuesé‡æ–°æ ¼å¼åŒ–ä¸ºåŸå§‹æ ¼å¼
    final_issues = []
    for valid_issue in valid_issues:
        # æ‰¾åˆ°å¯¹åº”çš„åŸå§‹ç»“æœ
        original_result = None
        for i, result in enumerate(results):
            if result.get("result") == "ISSUE" and result.get("issue"):
                # ç®€å•åŒ¹é…ï¼šä½¿ç”¨hunk_idæˆ–file_path
                original_hunk_id = result.get("_meta", {}).get("hunk_id")
                valid_hunk_id = valid_issue.get("diff_anchor", {}).get("hunk_id")
                if original_hunk_id == valid_hunk_id:
                    original_result = result
                    break

        if original_result:
            # æ›´æ–°åŸå§‹ç»“æœä¸­çš„issueä¸ºæ ¡éªŒåçš„æ ‡å‡†åŒ–issue
            original_result["issue"] = valid_issue
            original_result["passed_validation"] = True
            final_issues.append(original_result)

    # æœ€ç»ˆç»Ÿè®¡
    final_issue_count = len(final_issues)
    final_no_issue_count = len(results) - final_issue_count

    logger.info(f"[Enhanced Security Agent] å·¥å…·å¢å¼ºåˆ†æå®Œæˆç»Ÿè®¡:")
    logger.info(f"[Enhanced Security Agent] æˆåŠŸ: {success_count}/{len(audit_units)}")
    logger.info(f"[Enhanced Security Agent] æ¨¡å‹è¾“å‡ºå®‰å…¨æ¼æ´: {issue_count}")
    logger.info(f"[Enhanced Security Agent] é€šè¿‡æ ¡éªŒæœ€ç»ˆç¡®è®¤: {final_issue_count}")
    logger.info(f"[Enhanced Security Agent] æ ¡éªŒè¿‡æ»¤æ‰: {issue_count - final_issue_count}")
    logger.info(f"[Enhanced Security Agent] æ— å®‰å…¨é—®é¢˜: {final_no_issue_count}")
    logger.info(f"[Enhanced Security Agent] è¯æ®ä¸å……åˆ†é™çº§: {downgraded_count}")
    logger.info(f"[Enhanced Security Agent] æ‰§è¡Œé”™è¯¯: {len(errors)}")

    # å·¥å…·è¯æ®ç»Ÿè®¡
    logger.info(f"[Enhanced Security Agent] å·¥å…·è¯æ®ç»Ÿè®¡:")
    logger.info(f"[Enhanced Security Agent]   æ€»å•å…ƒ: {tool_evidence_stats['total_units']}")
    logger.info(f"[Enhanced Security Agent]   æœ‰å…¥å£ç‚¹: {tool_evidence_stats['with_entrypoint']}")
    logger.info(f"[Enhanced Security Agent]   æœ‰è°ƒç”¨é“¾: {tool_evidence_stats['with_call_chain']}")
    logger.info(f"[Enhanced Security Agent]   æœ‰æ¡†æ¶è·¯ç”±: {tool_evidence_stats['with_framework_routes']}")
    logger.info(f"[Enhanced Security Agent]   æœ‰ä¸Šä¸‹æ–‡: {tool_evidence_stats['with_context']}")

    # æŒ‰ä¸¥é‡ç¨‹åº¦ç»Ÿè®¡ï¼ˆä»…ç»Ÿè®¡é€šè¿‡æ ¡éªŒçš„ï¼‰
    if final_issues:
        severity_counts = {}
        cwe_counts = {}
        confidence_scores = []

        for issue in final_issues:
            issue_data = issue.get("issue", {})
            severity = issue_data.get("severity", "unknown")
            cwe_list = issue_data.get("cwe", [])
            tool_evidence = issue.get("tool_evidence", {})
            confidence = tool_evidence.get("summary", {}).get("confidence_score", 0)

            severity_counts[severity] = severity_counts.get(severity, 0) + 1
            confidence_scores.append(confidence)

            for cwe in cwe_list:
                cwe_counts[cwe] = cwe_counts.get(cwe, 0) + 1

        if severity_counts:
            logger.info(f"[Enhanced Security Agent] æœ€ç»ˆç¡®è®¤å®‰å…¨æ¼æ´ä¸¥é‡ç¨‹åº¦åˆ†å¸ƒ: {severity_counts}")
        if cwe_counts:
            logger.info(f"[Enhanced Security Agent] æœ€ç»ˆç¡®è®¤CWEç±»å‹åˆ†å¸ƒ: {cwe_counts}")
        if confidence_scores:
            avg_confidence = sum(confidence_scores) / len(confidence_scores)
            logger.info(f"[Enhanced Security Agent] æœ€ç»ˆç¡®è®¤å¹³å‡å·¥å…·è¯æ®ç½®ä¿¡åº¦: {avg_confidence:.1f}/100")

    return {
        "success": True,
        "units_analyzed": len(audit_units),
        "issues_found": final_issue_count,
        "issues": final_issues,
        "raw_results": results,
        "errors": errors,
        "tool_evidence_summary": tool_evidence_stats,
        # æ–°å¢æ ¡éªŒç›¸å…³ç»Ÿè®¡
        "validation_summary": {
            "model_output_issues": issue_count,
            "validated_issues": final_issue_count,
            "rejected_by_validation": issue_count - final_issue_count,
            "rejection_rate": validation_summary["rejection_rate"],
            "rejection_reasons": validation_summary["rejection_reasons_count"]
        },
        # è°ƒè¯•ç”¨ï¼šåŒ…å«è¢«æ‹’ç»çš„issues
        "debug_rejected_issues": rejected_issues if os.getenv("ENABLE_DETAILED_LOGS", "false").lower() == "true" else []
    }

# ä¸ºäº†å‘åå…¼å®¹ï¼Œä¿ç•™æ—§å‡½æ•°åä½œä¸ºåˆ«å
run_security_agent_for_pr = run_enhanced_security_agent_for_pr
